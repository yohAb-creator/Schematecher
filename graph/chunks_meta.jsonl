{"node_id": "tdanotes:1", "pdf_id": "tdanotes", "section_id": "1", "chunk_id": "1-0", "text": "Chapter 1 Introduction In many applications in data science, the data is given to us as a point cloud in some (potentially high-dimensional) space. Interesting data about which we can actually make statements using tools from data analysis usually has some underlying shape, and this shape conveys information: think about points sampled from a sphere or a torus. In both cases the point cloud will \u201clook like\u201d a 2-dimensional object, but the objects look different. In order to describe and compare different shapes, in particular in higher dimensions, we need some mathematical language. Luckily this language has already been developed under the name of topology. In topological data analysis we use the classical tools and language from topology to detect and describe the notion of \u201cshape\u201d in data sets. The main tool we use for this is homology, which can be regarded as \u201ccounting holes\u201d. Let us illustrate this with some toy examples. Figure 1.1: A circle (left) and a Figure-8 (right) Consider the two shapes in Figure 1.1. On the left, you see a circle, on the right a Figure-8, both in R2. If you had to count how many \u201choles\u201d these shapes have, you would probably argue along the following lines: the circle has one hole, as removing it from R2 we are left with one bounded connected component. Similarly, the Figure-8 has two holes. In particular, you would say that the two shapes are \u201cdifferent\u201d, as they have a different number of holes. This type of intuition is indeed correct, and topology provides us with the language to make this mathematically precise. 6 Introduction to TDA Figure 1.2: Points sampled from a circle (left) and a Figure-8 (right). Let us now look at the 2-dimensional data sets in Figure 1.2. For a human, it is immediately visible that the data sets are (noisy) samples of the shapes of Figure 1.1. How do we get a computer to \u201csee\u201d this? Note that we cannot count the number of holes as we did above: as we are just given finitely many points, there are no holes in both data sets. However, by squinting our eyes a bit, we clearly see the different shapes from which we sampled. A mathematical analogue of squinting one\u2019s eyes could be to enlarge the points to disks with some small radius. This is depicted in Figure 1.3. Figure 1.3: Enlarging the points to disks shows the shape. Indeed, choosing a large enough radius, by considering the union of the disks we again get shapes that look like the two shapes we sampled from. In particular, on the left we again have one hole whereas on the right we have two holes. Unfortunately, it is not at all clear what radius we should choose. Indeed, by choosing a radius that is too small, we might not create all the holes of the original shape. On the other hand, by 7 Chapter 1. Introduction Introduction to TDA choosing a radius that is too large, we might fill in some of the holes1. This is depicted in Figure 1.4. Figure 1.4: Enlarging the disks too much, we lose the shapes again. Of course we could now try to somehow estimate a good radius. However, this is quite a difficult task in general. The key idea of persistent homology is to continuously grow the disks and keep track of the number of holes and how long they live. During this process of growing the disks, many holes will be created. However, many of them are filled in shortly after they are created, see Figure 1.5 for an example."}
{"node_id": "tdanotes:1", "pdf_id": "tdanotes", "section_id": "1", "chunk_id": "1-1", "text": "a difficult task in general. The key idea of persistent homology is to continuously grow the disks and keep track of the number of holes and how long they live. During this process of growing the disks, many holes will be created. However, many of them are filled in shortly after they are created, see Figure 1.5 for an example. In persistent homology, we keep track of all holes created in the process, together with timestamps of when they are created and when they are filled in. This gives a lifetime for each hole. The intuition behind this is that holes with a short lifetime are just a result of the process, whereas holes with a long lifetime convey information about the shape of the underlying data. Let us consider yet another point cloud, this time sampled from two nested circles, see Figure 1.6. Two circles give us two holes, so in the process of growing disks we expect to see two holes with a long lifetime. One way to visualize the lifetimes of holes is through barcodes: for each hole, we draw an interval whose startpoint and endpoint correspond to the time of creation of the hole, and when it got filled in. Doing this for the point cloud in Figure 1.6, we get the barcodes depicted in Figure 1.7. Indeed, while there are many intervals, only two of them are long, implying that there are two holes inherent to the underlying data, which agrees with the fact that the points were sampled from two circles. 1The same is true for squinting your eyes: if you squint them too much, you close them and do not see anything... 8 Introduction to TDA Figure 1.5: In the growing disks process, many holes get filled in shortly after they are created. Figure 1.6: Points sampled from two nested circles. The main work we will do in these lecture notes is to formalize this process of grow- ing disks and keeping track of holes, as we sketched above. For this we first introduce some essential background of homology theory in Chapter 3. This requires some mathe- matical background that goes above linear algebra. This background will be introduced in Chapter 2. The growing disks process is modeled via nested simplicial complexes, and there are several different such complexes that can be defined. Some of these are discussed in Chapter 5. Keeping track of holes created and filled in is done via the the- ory of persistent homology, which we introduce in Chapter 4. In this chapter we also discuss algorithms to compute persistent homology. Once we have computed persistent 9 Chapter 1. Introduction Introduction to TDA Figure 1.7: The barcodes from two nested circles. homology and have the output, for example in the form of barcodes, we might want to compare different such outputs with each other. For this, there are several distance measures, which we discuss in Chapter 6. There we also mathematically prove stability results stating that if the data is perturbed only a little, then also the output cannot change too much. Persistent homology is not the only application of topology to the analysis of data. Another widely used tool in topological data analysis is Mapper, which we discuss in Chapter 7. Finally, we discuss the computational problem of finding nice representatives of holes in Chapter 8 as well as persistence over multiple parameters in Chapter 9. These lecture notes focus a lot on the mathematical theory behind topological data analysis. Topological data analysis has however seen many successful applications in recent years. We highlight some of them in"}
{"node_id": "tdanotes:1", "pdf_id": "tdanotes", "section_id": "1", "chunk_id": "1-2", "text": "in Chapter 7. Finally, we discuss the computational problem of finding nice representatives of holes in Chapter 8 as well as persistence over multiple parameters in Chapter 9. These lecture notes focus a lot on the mathematical theory behind topological data analysis. Topological data analysis has however seen many successful applications in recent years. We highlight some of them in Chapter 10. There are also powerful pro- gramming libraries available that implement many of the concepts discussed in these lecture notes. For the coding aspects of the topics in these lecture notes there are inter- active notebooks on the course webpage. 10"}
{"node_id": "tdanotes:2.1", "pdf_id": "tdanotes", "section_id": "2.1", "chunk_id": "2.1-0", "text": "Chapter 2 Mathematical Foundations 2.1 Topological Spaces Topology, sometimes also called \u201crubber-sheet geometry\u201d, stems from the Greek words t\u00f3pos, which means place or locality, and l\u00f3gos, which means study. So, it can be roughly translated as the study of places and shapes. Indeed, as the name rubber-sheet geometry suggests, topology studies similar objects as geometry, but in a setting where properties are preserved under continuous deformations like stretching and twisting. In particular, these properties should be independent of metrics, but we would still like to have ways to describe proximity between points. We do this by looking at open neighborhoods of points. The core objects in topology are topological spaces, whose definition captures the system of open neighborhoods of the points in the space. Definition 2.1. A topological space (X,T) is a set of points X, with a system T of subsets of X (called the topology on X), such that 1. \u2205 \u2208 T, X \u2208 T. (cid:83) 2. For every S \u2286 T, S \u2208 T. (cid:84) 3. For every finite S \u2286 T, S \u2208 T. The sets in T are called the open sets of X. For example, setting X = R2 and T to be the collection of open subsets (in the geometric/calculus sense) of R2, we can check that (X,T) is a topological space. A further example of a topological space is (X,2X), where 2X denotes the family of all subsets of X. This is called a discrete topology. Another example is the Euclidean space X = Rd, where the open sets T are defined as we know from calculus. This example also shows why we restrict the third condition of the definition above only to finite intersections of open sets: If we allowed infinite intersections in Condition 3, a set {p} consisting of a single point p \u2208 Rd (which by the 11 Chapter 2. Mathematical Foundations Introduction to TDA calculus definition is not an open set) would have to be considered to be open; it is the intersection of the infinite series of open balls of radius 1/n centered at p, for n \u2208 N . In most applications in these lecture notes, we work with subspaces of this Euclidean space Rd. In that context we not only know the notion of open sets from calculus, but also notions such as closed sets, closure, interior and boundary. These terms can also be defined for abstract topological spaces: Definition 2.2. A set Q \u2286 X is called closed, if its complement X \\ Q is open. The closure clQ is the smallest closed set containing Q. The interior intQ is the union of all open subsets of Q. The boundary bndQ is the set minus its interior: bndQ = Q\\intQ. Note that sets can be open and closed simultaneously: in every topological space (X,T), \u2205 and X are such examples. In a discrete topology, every subset S \u2286 X is both open and closed. Exercise 2.3. Show that a finite union of closed sets is closed. So far we have only seen two topological spaces: Euclidean space, and the (rather boring) discrete topology on any set X. In order to see the value in the abstractions we are doing, we would like to have more examples of topological spaces. In particular, it would be great if we had a way to get new topological spaces from known ones. In the following we discuss some ways to do this, starting with taking intersections. Lemma2.4. Let (X,T) be some topological space, and Y \u2286 X. Then, U := {A\u2229Y | A \u2208 T} is a"}
{"node_id": "tdanotes:2.1", "pdf_id": "tdanotes", "section_id": "2.1", "chunk_id": "2.1-1", "text": "have more examples of topological spaces. In particular, it would be great if we had a way to get new topological spaces from known ones. In the following we discuss some ways to do this, starting with taking intersections. Lemma2.4. Let (X,T) be some topological space, and Y \u2286 X. Then, U := {A\u2229Y | A \u2208 T} is a topology on Y. We call this a subspace topology. Proof. We check the three conditions of a topology: 1. \u2205 = \u2205\u2229Y, therefore \u2205 \u2208 U. Similarly, Y = X\u2229Y, and thus Y \u2208 U. 2. (cid:83) (A \u2229Y) = ( (cid:83) A )\u2229Y, and thus (cid:83) (A \u2229Y) \u2208 U. i\u2208I i i\u2208I i i\u2208I i 3. (cid:84)n (A \u2229Y) = ( (cid:84)n A )\u2229Y, and thus (cid:84)n (A \u2229Y) \u2208 U. i=1 i i=1 i i=1 i Since we have seen a natural topology on Rd, this already gives us a natural topology for all subsets of Rd. Another way to get topological spaces is as a product of spaces. We will not discuss the details of this here, and refer the interested reader to any textbook on topology, such as the excellent book by Munkres [2]. Fact 2.5. Let (X,T ),(Y,T ) be two topological spaces. Then there exists a topology X Y on X\u00d7Y, called the product topology. Finally, we can also get a topological space by taking the union of two disjoint topo- logical spaces. If a space can be obtained as such a union, we call it disconnected: 12"}
{"node_id": "tdanotes:2.2", "pdf_id": "tdanotes", "section_id": "2.2", "chunk_id": "2.2-0", "text": "Introduction to TDA 2.2. Metric Spaces Definition 2.6. A topological space (X,T) is disconnected, if there are two disjoint non- empty open sets U,V \u2208 T, such that X = U\u222aV. A topological space is connected, if it is not disconnected. Exercise 2.7. In this exercise, we will use topology to prove that the set of primes is infinite. We define the sets S(a,b) as follows: S(a,b) := {an+b | n \u2208 Z}, \u2200a \u2208 Z\\{0},b \u2208 Z We then say that a set U \u2286 Z is open, if and only if for all x \u2208 U, there exists a \u2208 Z such that S(a,x) \u2286 U. This is equivalent to saying that every open set U is a union of zero or more (including infinitely many) sets S(a,b). (a) Show that this defines a topology on Z. (b) Let A \u2282 Z be finite and non-empty. Show that Z\\A cannot be closed. (c) Show that S(a,b) is both open and closed. (d) Show that (cid:91) S(p,0) = Z\\{\u22121,1} p prime (e) Conclude that there are infinitely many primes. 2.2 Metric Spaces Recall that topological spaces should capture neighborhoods of points without requiring the notion of a distance. However, if we do have distances, we should still be able to use the framework of topological spaces. In other words, topological spaces should be a generalization of spaces with distances. Definition 2.8. A metric space (X,d) is a set X of points and a distance function d : X\u00d7X \u2192 R satisfying 1. d(p,q) = 0 if and only if p = q. 2. d(p,q) = d(q,p), \u2200p,q \u2208 X. (Symmetry) 3. d(p,q) \u2a7d d(p,s)+d(s,q), \u2200p,q,s \u2208 X. (Triangle inequality) Note that these three conditions imply that d(p,q) \u2a7e 0 for all p,q \u2208 X: If some distance d(p,q) would be negative, we would have 0 = d(p,p) \u2a7d d(p,q) + d(q,p) = 2\u00b7d(p,q) < 0, a contradiction. Fact 2.9. Every metric space has a topology (the metric space topology) given by the open metric balls B(c,r) = {p \u2208 X | d(p,c) < r} and their unions. 13"}
{"node_id": "tdanotes:2.3", "pdf_id": "tdanotes", "section_id": "2.3", "chunk_id": "2.3-0", "text": "Chapter 2. Mathematical Foundations Introduction to TDA 2.3 Maps Between Topological Spaces In most areas of mathematics, there are two things that are at the core of every theory: objects, and mappings between them. For example, in linear algebra we study vector spaces and the linear maps between then. Now that we have defined the objects of study \u2014 topological spaces \u2014 we want to look at the mappings between them. Definition 2.10. A function f : X \u2192 Y is continuous if for every open set U \u2286 Y, its pre-image f\u22121(U) \u2286 X (the set of all elements x \u2208 X such that f(x) \u2208 U) is open. Continuous functions are also called maps. If f is an injective map, it is called an embedding. Let us give some examples: \u2022 For X \u2286 Y, we write X (cid:44)\u2192 Y for the function f(x) = x,\u2200x \u2208 X. This function, which is also called the inclusion map, is continuous: f\u22121(U) = U\u2229X, which is open in the subspace topology on X. \u2022 For a function f : R \u2192 R , continuity agrees with the \u201c\u03f5-\u03b4\u201d definition of continuity from calculus. Exercise 2.11. A topological space (X,T) is called path-connected if any two points x,y \u2208 X can be joined by a path, i.e., there exists a map f : [0,1] \u2192 X of the segment [0,1] \u2282 R onto X such that f(0) = x and f(1) = y. Prove that a path-connected space is connected. An important question we have to answer is when we want to consider two topological spaces to be \u201cthe same\u201d. In the rest of this section we develop some notions of equivalence of topological spaces, each based on the existence of some continuous function(s). Definition 2.12. A homeomorphism is a bijective map f : X \u2192 Y whose inverse is also continuous. Two topological spaces are homeomorphic, if there is a homeomorphism between them. We also write X \u2243 Y to say that X,Y are homeomorphic. To make sure that homeomorphism is a reasonable notion of equivalence, we should check that it is indeed an equivalence relation. Exercise 2.13. Show that the relation of being homeomorphic is an equivalence rela- tion, that is, show that every space is homeomorphic to itself, show that the relation is symmetric (X \u2243 Y iff Y \u2243 X), and show that \u2243 is transitive (if X \u2243 Y and Y \u2243 Z, then X \u2243 Z). Let us apply our definition to some examples, to see whether it captures our intuition: \u2022 The boundary of a tetrahedron is homeomorphic to the sphere S2 (with both spaces considered as a subspace of R3). A homeomorphism can be found by taking a point c in the interior of the tetrahedron, and sending each point p of the boundary to the point f(p) on the ray from c through p such that d(c,f(p)) = 1. 14 Introduction to TDA 2.3. Maps Between Topological Spaces \u2022 The open interval I := (\u22121,1) is homeomorphic to R . The following map f is a homeomorphism: f : I \u2192 R , x (cid:55)\u2192 x . Its inverse is f\u22121 : R \u2192 I, y (cid:55)\u2192 y . 1\u2212|x| 1+|y| \u2022 All knots (a knot is the image of an embedding of the circle into R3) are homeo- morphic. Thus, we cannot distinguish between knots using only homeomorphism. (cid:39) Figure 2.1: Two knots. Exercise 2.14. Give an example of a map f : X \u2192 Y that is bijective but not a homeo- morphism. Exercise 2.15. Consider a grid of 2"}
{"node_id": "tdanotes:2.3", "pdf_id": "tdanotes", "section_id": "2.3", "chunk_id": "2.3-1", "text": "All knots (a knot is the image of an embedding of the circle into R3) are homeo- morphic. Thus, we cannot distinguish between knots using only homeomorphism. (cid:39) Figure 2.1: Two knots. Exercise 2.14. Give an example of a map f : X \u2192 Y that is bijective but not a homeo- morphism. Exercise 2.15. Consider a grid of 2 vertical line segments and k + 2 horizontal seg- ments, for some k \u2a7e 0. For k = 1, this looks as follows: Now, we consider the problem of placing a point on each of the k + 2 horizontal line segments, such that each of the k+4 total line segments contains at least one point. (a) How could one define a topology on the set of all such point placements? (b) Convince yourself that this space is homeomorphic to Sk. The example of the knots shows that in certain cases, homeomorphism does not capture all the information we can use to distinguish two spaces. In this example, this distinguishing information is not really stored in the topological spaces themselves, but in the way they are embedded in the \u201cambient\u201d space (in this example R3). In such a case, where the two spaces we consider are both embedded into the same ambient space, we can not only look at maps between the two spaces themselves, but we can also consider whether one of them can be continuously deformed into the other: Definition2.16([1, Def. 1.18]). An isotopy connecting X \u2286 A and Y \u2286 A is a continuous map \u03d5 : X\u00d7[0,1] \u2192 A, such that \u03d5(X,0) = X, \u03d5(X,1) = Y, and \u2200t \u2208 [0,1], \u03d5(\u00b7,t) is a homeomorphism between X and its image. Two spaces are called isotopic, if there is an isotopy connecting them. Exercise 2.17. Show that the relation of being isotopic is an equivalence relation. Let us check isotopy on a few examples, starting with the knots from above: 15 Chapter 2. Mathematical Foundations Introduction to TDA \u2022 The two knots from Figure 2.1 above (embedded in A = R3) are homeomorphic but not isotopic. Isotopy thus captures our intuition more accurately than home- omorphism in this case. \u2022 Let X \u2282 R be the union of {0}, and [1,2], and let Y \u2282 R be the union of [0,1] and {2}. These spaces are homeomorphic (X \u2243 Y), but not isotopic. Just as with the knots, the difference between these spaces does not lie in their topology, but in the way they are embedded into the ambient space . R \u2022 Consider the two spaces in Figure 2.2, which are considered to be embedded in the ambient space A consisting of R3 minus the grey infinitely long pole in the middle. Do you think the spaces are isotopic? Most people would probably ar- gue that they are not, as in the left space both loops of the handcuff are locked around pole while in the right space one loop is free. However, it turns out that the spaces are in fact isotopic. An isotopy is illustrated by the following video: https://www.youtube.com/watch?v=wDZx9B4TAXo Figure 2.2: Left: Both loops of the handcuffs are wrapped around an infinite pole. Right: Only one loop of the handcuffs is wrapped around the infinite pole. These spaces are isotopic. Using isotopy we have now managed to distinguish between two spaces (embeddings) that homeomorphism could not distinguish. On the other hand, homeomorphism is also very restrictive: For example, any two-dimensional space X (such as the mantle of a cylinder) cannot be homeomorphic to any one-dimensional space Y (such as a circle), simply due"}
{"node_id": "tdanotes:2.3", "pdf_id": "tdanotes", "section_id": "2.3", "chunk_id": "2.3-2", "text": "the infinite pole. These spaces are isotopic. Using isotopy we have now managed to distinguish between two spaces (embeddings) that homeomorphism could not distinguish. On the other hand, homeomorphism is also very restrictive: For example, any two-dimensional space X (such as the mantle of a cylinder) cannot be homeomorphic to any one-dimensional space Y (such as a circle), simply due to the difference in dimension of X and Y. We thus also want to develop a weaker notion of equivalence than homeomorphism. 16 Introduction to TDA 2.3. Maps Between Topological Spaces To do this, we take the idea of continuous deformations from isotopy, but instead of applying it to deform spaces into each other, we deform maps into each other: Definition 2.18. Let g,h be maps X \u2192 Y. A homotopy connecting g and h is a map H : X \u00d7 [0,1] \u2192 Y such that H(\u00b7,0) = g and H(\u00b7,1) = h. In this case g and h are called homotopic. Before we use homotopies to define an equivalence on topological spaces, let us again consider some examples: \u2022 The inclusion map g : B3 (cid:44)\u2192 R3 (where B3 is the unit ball in R3), and the constant map h : B3 \u2192 R3 which sends every point to the origin, are homotopic, as shown by the homotopy H(x,t) = (1\u2212t)g(x). \u2022 The identity map g : S1 \u2192 S1, and the constant map h : S1 \u2192 S1 which sends everything to a single point p \u2208 S1, are not homotopic. The notion of homotopy now allows us to define our desired equivalence relation on topological spaces that is weaker than homeomorphism. Intuitively, this relation says that two spaces are the same if they can be continuously transformed into each other not only by bending, twisting and stretching, but also by shrinking or blowing up parts of different dimensions. However, note that unlike with isotopy, we do not need to consider the two spaces to be embedded in any ambient space. Definition 2.19. Two spaces X,Y are homotopy equivalent if there exist maps g : X \u2192 Y and h : Y \u2192 X such that: \u2022 h\u25e6g is homotopic to id (the identity map x (cid:55)\u2192 x), and X \u2022 g\u25e6h is homotopic to id . Y Exercise 2.20. Show that the relation of being homotopy equivalent is an equivalence relation. Let us consider some examples: \u2022 The circle S1 and R2 \\ {0} are homotopy equivalent: We pick g as the inclusion map S1 (cid:44)\u2192 R2 \\ {0}, and h(x) := x . We see that h \u25e6 g(x) = x, i.e., h \u25e6 g = id . |x| S1 Furthermore, g\u25e6h(x) = h(x). Finally, g\u25e6h and id are homotopic as certified R2\\{0} by the homotopy H(x,t) := tx+(1\u2212t)h(x). \u2022 The cylinder mantle and the circle are homotopy equivalent, but not homeomor- phic. \u2022 Any ball Bd is homotopy equivalent to the single point. We call such spaces contractible. 17 Chapter 2. Mathematical Foundations Introduction to TDA The next lemma shows that homotopy equivalence is a strictly weaker notion than homeomorphism: Lemma 2.21. If X and Y are homeomorphic, they are also homotopy equivalent. Proof. Let g : X \u2192 Y be the homeomorphism, and h := g\u22121 its inverse. Then g\u25e6h = id Y and h\u25e6g = id , and id is homotopic to itself. X With the need for two maps and a proof that they are homotopic, proving homotopy equivalence directly can be quite tedious. The following notion of deformation retracts gives an easy way of proving homotopy equivalence in some cases."}
{"node_id": "tdanotes:2.3", "pdf_id": "tdanotes", "section_id": "2.3", "chunk_id": "2.3-3", "text": "h := g\u22121 its inverse. Then g\u25e6h = id Y and h\u25e6g = id , and id is homotopic to itself. X With the need for two maps and a proof that they are homotopic, proving homotopy equivalence directly can be quite tedious. The following notion of deformation retracts gives an easy way of proving homotopy equivalence in some cases. Definition2.22. Let A \u2286 X. A deformationretract of X onto A is a map R : X\u00d7[0,1] \u2192 X, such that \u2022 R(\u00b7,0) = id X \u2022 R(x,1) \u2208 A,\u2200x \u2208 X \u2022 R(a,t) = a,\u2200a \u2208 A,t \u2208 [0,1] If such a deformation retract of X onto A exists, we also say that A is a deformation retract of X. The intuition behind a deformation retract is that the map R continuously shrinks X to A, while leaving A fixed. Note that unlike homeomorphism, isotopy and homotopy equivalence, deformation retracts are inherently asymmetric. Fact 2.23. If A is a deformation retract of X, then A and X are homotopy equivalent. Let us use this to prove homotopy equivalence of some examples: \u2022 The circle S1 is a deformation retract of R2 \\{0}: R(x,t) = (1\u2212t)x+t\u00b7 x . Note |x| how much easier this is to prove without needing to use the two maps h and g as above. \u2022 A punctured torus can be deformation retracted onto the symbol 8 where one of the two circles is rotated by 90\u25e6, as seen by the following video: https://www.youtube.com/watch?v=tz3QWrfPQj4 One may think that deformation retracts are only useful for proving homotopy equiv- alence when one space is a subspace of the other. However, the following fact shows that deformation retracts can prove homotopy equivalence of any pair of spaces: Fact 2.24. X,Y are homotopy equivalent if and only if there exists a space Z such that X and Y are deformation retracts of Z. An example of this fact can be found in Figure 2.3. 18 Introduction to TDA 2.3. Maps Between Topological Spaces Figure 2.3: The top space deformation retracts to both spaces below, showing that they are homotopy equivalent. Exercise2.25. Sort the letters of the alphabet into equivalence classes under homotopy equivalence. Exercise 2.26. Show that both a cylinder and a M\u00f6bius strip are homotopy equivalent to a circle. Exercise 2.27. Let X be S2 where the north pole and the south pole have been glued together, see Figure 2.4a. Let Y be S2 with an S1 attached at the north pole, see Figure 2.4b. (a) The space X. (b) The space Y. Figure 2.4: The spaces from Exercise 2.27. Give an informal argument that X and Y are homotopy equivalent. Bonus ques- tion: Are they also homeomorphic? We note that in general showing existence of a map with certain properties (e.g., a homeomorphism, isotopy, homotopy) is easy: just give a map and show that it satisfies therequiredproperties. Ontheotherhand, showingthatsuchamapcannotexistishard, as there are usually infinitely many candidate maps. The idea of algebraic topology is to identify invariant properties preserved by these maps. Then, we know that no map can exist between spaces on which these invariants differ. An example of such an invariant is the number of \u201choles\u201d a space has, which we will formalize when we introduce the notion of homology. 19"}
{"node_id": "tdanotes:2.3", "pdf_id": "tdanotes", "section_id": "2.3", "chunk_id": "2.3-4", "text": "notion of homology. 19"}
{"node_id": "tdanotes:2.4", "pdf_id": "tdanotes", "section_id": "2.4", "chunk_id": "2.4-0", "text": "Chapter 2. Mathematical Foundations Introduction to TDA 2.4 Algebra In this section we recap the necessary background in algebra that is needed for the basics of homology theory. Just as in the previous sections, we first introduce the objects of study, followed by the maps between them. Definition 2.28. A group (G,+) is a set G together with a binary operation \u201c+\u201d such that 1. \u2200a,b \u2208 G: a+b \u2208 G 2. \u2200a,b,c \u2208 G: (a+b)+c = a+(b+c) (Associativity) 3. \u22030 \u2208 G: a+0 = 0+a = a \u2200a \u2208 G 4. \u2200a \u2208 G\u2203\u2212a \u2208 G: a+(\u2212a) = 0 (G,+) is abelian1 if we also have 5. \u2200a,b \u2208 G: a+b = b+a (Commutativity) Let us point out some examples: \u2022 (Z,+) is a group (even an abelian one), but (N,+) is not, since any non-zero number does not have an inverse element. \u2022 Consider the (very large) set of all sequences of moves of a Rubik\u2019s cube that do not contain a subsequence equivalent to doing nothing. This set forms a group (with the \u201c+\u201d operation being concatenation), but not an abelian one: let L denote moving the left face clockwise, and let U denote moving the upper face clockwise. Replacing \u201cclockwise\u201d by counter-clockwise we get \u2212L and \u2212U, respectively. Now, ifthegroupwasabelian, thenL+U\u2212L\u2212Ushouldgivethesameconfigurationagain, but if you do these moves on a Rubik\u2019s cube, you will see that the configuration has changed. As groups can be very large, even infinitely large, it can be useful to have a concise way of writing them: Definition 2.29. Let (G,+) be a group. A subset A \u2286 G is a generator if every element of G can be written as a finite sum of elements of A and their inverses. A subset B \u2286 G is a basis if every element of G can be uniquely written as a finite sum of elements of B and their inverses (ignoring trivial cancellations, i.e., a+c+(\u2212c)+(\u2212b) = a+(\u2212b)). An abelian group that has a basis is called free. 1Notethatunlikeothermathematicalconceptsnamedafteraperson,abelian isusuallynotcapitalized. 20 Introduction to TDA 2.4. Algebra Examples: \u2022 The six standard moves of the Rubik\u2019s cube (rotating the top, bottom, front, back, left, or right layer clockwise by 90\u25e6) are a generator for the Rubik\u2019s cube move sequences. \u2022 {1} is a basis of (Z,+). Exercise 2.30. A cyclic group is a group G that contains an element g \u2208 G such that {g} is a generator of G. Show that every cyclic group is abelian (commutative). Exercise 2.31. Consider a Rubik\u2019s cube. Prove that no sequence X of elementary moves exists such that every Rubik\u2019s cube can be solved by repeatedly applying X. Definition 2.32. For some group (G,+), H \u2286 G is a subgroup, if (H,+) is also a group. For example, the even integers (including 0) are a subgroup of (Z,+). Subgroups are important in group theory, as they can be used to partition a group into several parts: Definition 2.33. Let H \u2286 G be a subgroup of (G,+), and a \u2208 G. The left coset a+H is the set a+H := {a+b | b \u2208 H}, and the right coset H+a := {b+a | b \u2208 H}. If G is abelian, a+H = H+a, and they are simply called the coset. For G abelian, the quotient group of G by H, denoted by G/H, is the group on the set of cosets {a+H,a \u2208 G} with the operation \u2295 defined as (a+H)\u2295(b+H) = (a+b)+H, \u2200a,b \u2208 G. Examples: \u2022 Let G = (Z,+) and H = nZ = {n \u00b7 a | a \u2208 Z}. Then, G/H = {0 +"}
{"node_id": "tdanotes:2.4", "pdf_id": "tdanotes", "section_id": "2.4", "chunk_id": "2.4-1", "text": "coset. For G abelian, the quotient group of G by H, denoted by G/H, is the group on the set of cosets {a+H,a \u2208 G} with the operation \u2295 defined as (a+H)\u2295(b+H) = (a+b)+H, \u2200a,b \u2208 G. Examples: \u2022 Let G = (Z,+) and H = nZ = {n \u00b7 a | a \u2208 Z}. Then, G/H = {0 + nZ,1 + nZ,...,(n\u22121)+nZ} is the group usually referred to as Z , the group of modular n arithmetic modulo n. \u2022 R/Zisthecirclegroup(themultiplicativegroupofallcomplexnumbersofabsolute value 1). Try and convince yourself of this! In order to compare groups with each other, we again want a notion of maps between groups, that behave well with the group structures: Definition 2.34. A map h : G \u2192 H between abelian groups (G,+) and (H,\u22c6) is a homomorphism if h(a+b) = h(a)\u22c6h(b), \u2200a,b \u2208 G. \u223c A bijective homomorphism is called an isomorphism, and then we write G = H and say that G and H are isomorphic. kernel kerh := {a \u2208 G | h(a) = 0} image imh := {b \u2208 H | \u2203a \u2208 G with h(a) = b} cokernel cokerh := H/imh 21 Chapter 2. Mathematical Foundations Introduction to TDA Note that we are assuming something in our definition of the cokernel: for the defi- nition of a quotient group to apply, we need the divisor group to be a subgroup of the dividend group. Luckily, the following lemma says that imh is always a subgroup of H. Lemma 2.35. kerh and imh are subgroups of (G,+) and (H,\u22c6), respectively. Proof. We first prove this for kerh. 1. a,b \u2208 kerh \u21d2 h(a) = h(b) = 0. By definition of homomorphism, h(a + b) = h(a)\u22c6h(b) = 0\u22c60 = 0, and thus by definition of kerh, a+b \u2208 kerh. We conclude that kerh is closed under +. 2. Associativity follows from associativity of + in G, since kerh \u2286 G. 3. \u2200a \u2208 G : h(0)\u22c6h(a) = h(0+a) = h(a), and thus h(0) = 0, from which 0 \u2208 kerh follows. 4. Let a \u2208 kerh. Then, 0 = h(0) = h(a\u2212a) = h(a)\u22c6h(\u2212a) = 0\u22c6h(\u2212a) = h(\u2212a), and thus \u2212a \u2208 kerh. The proof for imh is left as an exercise. Exercise 2.36. Show that imh is a subgroup of H. Exercise 2.37. For two abelian groups (G,\u22c6) and (H,+), let the set of all homomor- phisms f : G \u2192 H be denoted by Hom(G,H). (a) Show that (Hom(G,H),\u2295), where the operation \u2295 is defined as (f\u2295g)(x) = f(x)+g(x),\u2200x \u2208 G, is also a group. \u223c (b) Show that Hom(Z2,Z ) = Z2. 2 2 2 As the example of the integers shows, a big motivation for the study of groups comes from number theory. However, in number theory we do not only have addition but also multiplication. This motivates the following definition: Definition 2.38. (R,+,\u00b7) is a ring, if 1. (R,+) is an abelian group. 2. \u2200a,b,c \u2208 R: (a\u00b7b)\u00b7c = a\u00b7(b\u00b7c) and (Associativity of \u00b7) a\u00b7(b+c) = a\u00b7b+a\u00b7c, (b+c)\u00b7a = b\u00b7a+c\u00b7a (Distributivity) 22 Introduction to TDA 2.4. Algebra 3. \u22031 \u2208 R, such that a\u00b71 = 1\u00b7a = a \u2200a \u2208 R. (Multiplicative identity) If \u00b7 is commutative, we say that R is commutative. Definition 2.39. A commutative ring in which every non-zero element has a multi- plicative inverse (i.e., \u2200a \u2208 R\\{0},\u2203b \u2208 R : a\u00b7b = 1) is called a field. Another important area of algebra, which you already know, is linear algebra. Here, vectors can be added and subtracted. Further the field of real numbers are called scalars and they can be multiplied with vectors."}
{"node_id": "tdanotes:2.4", "pdf_id": "tdanotes", "section_id": "2.4", "chunk_id": "2.4-2", "text": "ring in which every non-zero element has a multi- plicative inverse (i.e., \u2200a \u2208 R\\{0},\u2203b \u2208 R : a\u00b7b = 1) is called a field. Another important area of algebra, which you already know, is linear algebra. Here, vectors can be added and subtracted. Further the field of real numbers are called scalars and they can be multiplied with vectors. So, we have very similar operations at hand. This motivates the following generalization of the concept of vector spaces. Definition 2.40. Given a ring (R,+,\u00b7) with multiplicative identity 1, an R-module M is an abelian group (M,\u2295) with an operation \u2297 : R\u00d7M \u2192 M such that for all r,r\u2032 \u2208 R and x,y \u2208 M, we have 1. r\u2297(x\u2295y) = (r\u2297x)\u2295(r\u2297y) 2. (r+r\u2032)\u2297x = (r\u2297x)\u2295(r\u2032 \u2297x) 3. 1\u2297x = x 4. (r\u00b7r\u2032)\u2297x = r\u2297(r\u2032 \u2297x) If R is a field, the R-module is called a vector space. In the literature, often the same symbol (\u00b7) is used for both operations \u00b7 and \u2297, and + for both + in R and \u2295 in M. For a vector space, this should feel quite normal, since for the vector space Rn (which is an R -module), we also write \u00b7 for multiplying scalars to both scalars and vectors, and + for addition of both scalars and vectors. Modules appear all over the place in homology theory. In some cases, in particular in all the cases we discuss in these lecture notes, the modules happen to be vector spaces. Thus, most of what we discuss in the following chapters could be phrased using only language from linear algebra. However, to be consistent with most of the existing literature, we will phrase most results in a slightly more general language. 23 Chapter 2. Mathematical Foundations Introduction to TDA Questions 1. What is a topological space? Give the formal definition and some examples. 2. What is a continuous map between topological spaces? What is a homeomor- phism? State the definitions and give examples. 3. What is a homotopy? What is a homotopy equivalence? Give the formal definitions. Further, definedeformationretractsandusethemtogiveanalternative definition of homotopy equivalence. 4. What are groups and the maps between them? State the definitions and prove that the image and kernel are subgroups. References [1] Tamal Krishna Dey and Yusu Wang, Computational topology for data analysis, Cambridge University Press, 2022. [2] J.R. Munkres, Topology, Prentice Hall, Incorporated, 2000. 24"}
{"node_id": "tdanotes:3.1", "pdf_id": "tdanotes", "section_id": "3.1", "chunk_id": "3.1-0", "text": "Chapter 3 Homology In this chapter, we introduce homology, a fundamental concept in algebraic topology and, as the name suggests, a crucial element of the persistent homology pipeline in topological data analysis. Very informally, homology can be used to count the number of \u201choles\u201d of a topological space, where holes can have any dimension. While you might have an intuition of what a 2-dimensional hole in a subspace of R2 might be, it is not at all clear what a 4-dimensional hole in some 7-dimensional space should be. The main idea of homology is to use algebra to talk about holes in an abstract setting. As we have already hinted at in the previous chapter, homology is an invariant of topological spaces preserved under homeomorphism and homotopy equivalence. We will manage to make this formal in Section 3.2.8. 3.1 Simplicial Complexes In order to define homology, we restrict our attention (for now) to special types of topo- logical spaces, namely simplicial complexes. We will see that this covers most natural spaces. Furthermore, homology for simplicial complexes is sufficient for all classical ap- plications in topological data analysis. We will briefly outline a more general definition later in the chapter. While simplicial complexes can be regarded as completely abstract objects, it is more intuitive to think of them in a geometric setting. The basic objects in a geometric simplicial complex are simplices: Definition3.1. A k-simplex in Rd is the convex hull of k+1 affinely independent points in Rd. A face of a simplex is the convex hull of a subset of its vertices. In particular, every face of a simplex is also a simplex. The empty set \u2205 is also a face. The (k\u22121)-faces of a k-simplex are called facets. We say the dimension of a k-simplex is k. Definition 3.2. A geometric simplicial complex is a family K of simplices such that 25 Chapter 3. Homology Introduction to TDA \u2022 if \u03c4 \u2208 K and \u03c3 is a face of \u03c4, then \u03c3 \u2208 K, and \u2022 for \u03c3,\u03c4 \u2208 K, their intersection \u03c3\u2229\u03c4 is a face of both. Figure 3.1: Some examples of simplices: a point (0-dimensional), a line segment (1-dimensional), a triangle (2-dimensional) and a (filled) tetrahedron (3-dimensional). Figure 3.2: The left is a simplicial complex. The right is not, as the intersection of the two triangles is not a face of both of them. We say the dimension of a simplicial complex is the maximum dimension of any simplex. In these lecture notes, and for applications in topological data analysis in general, we may assume that all simplicial complexes are finite, that is, consisting of finitely many simplices. The way we defined them, simplicial complexes are geometric objects. To arrive at a purely combinatorial description, we can simply forget about the points in space spanning our simplices. Definition 3.3. An abstract simplicial complex K is a family of subsets of a vertex set V(K) such that if \u03c4 \u2208 K and \u03c3 \u2286 \u03c4, then \u03c3 \u2208 K. A k-simplex here is a subset of k+1 elements, and thus again called k-dimensional. Note that 1-dimensional abstract simplicial complexes are exactly graphs: they are de- fined by a vertex set V and a system of two-element subsets of V, called edges. 26 Introduction to TDA 3.1. Simplicial Complexes From every geometric simplicial complex we get an abstract simplicial complex by simply taking the set of points as the vertex set and adding the correct subset for every simplex. For the inverse direction, we have to talk about geometric realizations: Definition 3.4. A geometric simplicial complex K is a"}
{"node_id": "tdanotes:3.1", "pdf_id": "tdanotes", "section_id": "3.1", "chunk_id": "3.1-1", "text": "V, called edges. 26 Introduction to TDA 3.1. Simplicial Complexes From every geometric simplicial complex we get an abstract simplicial complex by simply taking the set of points as the vertex set and adding the correct subset for every simplex. For the inverse direction, we have to talk about geometric realizations: Definition 3.4. A geometric simplicial complex K is a geometric realization of some abstract simplicial complex K\u2032, if there is an embedding e : V(K\u2032) \u2192 Rd that takes every (abstract) k-simplex {v ,...,v } in K\u2032 to the (geometric) k-simplex that is the 0 k convex hull of e(v ),...,e(v ). 0 k Does every abstract simplicial complex have a geometric realization? Let us only consider 1-dimensional complexes (graphs) for now. We know that not all graphs admit a straight-line embedding in the plane, as only planar graphs admit any embedding, i.e., crossing-free drawing, in the plane. However, by placing the vertices in R3 in such a way that no four vertices lie on a common plane, we see that we can always find a geometric realization of a graph in R3. This generalizes to the following realization theorem: Theorem 3.5. Every k-dimensional simplicial complex has a geometric realization in R2k+1. Proof. Place the vertices as distinct points on the moment curve in R2k+1, which is the curve given by f(t) = (t,t2,...,t2k+1). This way, any 2k+2 of the placed points are affinely independent. Thus, any two faces with disjoint vertex sets will not intersect in the realization, showing that the realization is indeed an embedding. Sincewenowknowthatabstractandgeometricsimplicialcomplexescanbetranslated into one another, we will not make the distinction between them again and just use the word simplicial complex for both objects in the following. As a subset of Euclidean space, a simplicial complex thus also inherits the subspace topology from Rd, which allows us to view simplicial complexes as topological spaces. We usually write K for the simplicial complex as a family of sets, and |K| for the underlying topological space. Ontheotherhand,mosttopologicalspacesarenotsimplicialcomplexes. Forexample, the 2-sphere S2 is not a simplicial complex, as it is not defined by a vertex set and faces. However, the boundary of a tetrahedron is a simplicial complex, and it is homeomorphic to S2. Considering that we want to consider properties invariant under homeomorphism, we thus might as well work with the boundary of a tetrahedron instead of with S2. This motivates the following definition. Definition 3.6. A simplicial complex K is a triangulation of a topological space X, if |K| is homeomorphic to X. We say that a topological space X is triangulable if it has a triangulation. Triangulable spaces are nice for us, as we can replace them by simplicial complexes without any loss of topological information. Unfortunately, not all topological spaces are triangulable, but in this course we will not deal with such spaces. 27 Chapter 3. Homology Introduction to TDA While triangulations give us simplicial complexes from (triangulable) topological spaces, we would like to mention that one can also go the other way: many combi- natorial structures naturally give rise to (abstract) simplicial complexes, which can in turn be interpreted as topological spaces. Thus, we can use the machinery of topological methods for gaining insights into many combinatorial problems. This gives rise to a sub- field of combinatorics called topological combinatorics, where the topology of simplicial complexes associated to combinatorial objects is studied. Let us give some examples of such simplicial complexes. \u2022 As we have already discussed, graphs are equivalent to 1-dimensional simplicial complexes. \u2022 Given a graph G = (V,E), we can define a simplicial complex on V by including"}
{"node_id": "tdanotes:3.1", "pdf_id": "tdanotes", "section_id": "3.1", "chunk_id": "3.1-2", "text": "to a sub- field of combinatorics called topological combinatorics, where the topology of simplicial complexes associated to combinatorial objects is studied. Let us give some examples of such simplicial complexes. \u2022 As we have already discussed, graphs are equivalent to 1-dimensional simplicial complexes. \u2022 Given a graph G = (V,E), we can define a simplicial complex on V by including a face {v ,...,v } whenever these vertices form a clique in G. This is called the 1 k clique complex of G. \u2022 For a poset (P,\u2a7d), the set of all chains of P forms a simplicial complex, giving rise to the order topology. In topological data analysis, a highly relevant example is the nerve, which records the intersection pattern of a collection of sets: Definition 3.7. For a finite collection U of sets, its nerve N(U) is a simplicial complex on the vertex set U that contains u ,...,u as a k-simplex iff u \u2229...\u2229u \u0338= \u2205. 0 k 0 k While the nerve can be seen as a purely combinatorial object describing the inter- section pattern of U, it is also interesting to study its topology. If the considered sets in U are subsets of some topological space X, there is a very strong characterization of the topology of N(U), if the intersections of sets in U are \u201cwell-behaved\u201d. Definition 3.8. Let X be a topological space, and U a finite family of closed subsets of X. We call U a good cover, if every non-empty intersection of sets in U is contractible. Under these conditions on the sets we get the following, very powerful theorem, which allows us to relate complex spaces (unions of sets) with a much simpler simplicial complex, namely the nerve of these sets. For a proof of this we refer to any textbook on algebraic topology, for example the one by Hatcher [2]. Theorem3.9(Nerve theorem). If U is a good cover, then |N(U)| is homotopy equivalent (cid:83) to U. The nerve theorem also holds if all the sets in U are open with contractible intersec- tions, but it may fail if some sets in U are closed, and some open: We can have an open and a closed set which do not intersect, but whose union is connected. Now that we have defined simplicial complexes and considered some examples, we once again want to study maps between them. The study of simplicial complexes and the maps between them, as we will define them, is called combinatorial topology. 28 Introduction to TDA 3.1. Simplicial Complexes Definition 3.10. A vertex map f : V(K ) \u2192 V(K ) maps vertices in K to vertices in K . 1 2 1 2 Definition 3.11. A map f : K \u2192 K is called simplicial if it can be described by a 1 2 vertex map g : V(K ) \u2192 V(K ) such that for every simplex {v ,...,v } we have 1 2 0 k f({v ,...,v }) = {g(v ),...,g(v )}. Since f maps to K we must have that f({v ,...,v }) 0 k 0 k 2 0 k is a simplex in K . A simplicial map can also be seen as a map on the underlying 2 spaces f : |K | \u2192 |K |. 1 2 Note that for a map to be simplicial, we do not require that {f(v ),...,f(v )} is also 0 k a k-dimensional simplex, we merely require that it is a simplex of K . It is thus possible 2 that distinct vertices of K are mapped to the same vertex of K ."}
{"node_id": "tdanotes:3.1", "pdf_id": "tdanotes", "section_id": "3.1", "chunk_id": "3.1-3", "text": "|K | \u2192 |K |. 1 2 Note that for a map to be simplicial, we do not require that {f(v ),...,f(v )} is also 0 k a k-dimensional simplex, we merely require that it is a simplex of K . It is thus possible 2 that distinct vertices of K are mapped to the same vertex of K . 1 2 Recall that simplicial complexes are topological spaces, so there is also the notion of continuous maps between them. It can be shown that every simplicial map is continuous. Exercise 3.12. Let f : |K | \u2192 |K | be a simplicial map. Show that f is continuous. 1 2 On the other hand, continuous maps in general do not need to map vertices to vertices, and are thus not simplicial. Simplicial maps are therefore more restrictive than continuous maps. However, the difference of the two concepts is smaller than one might think at first glance. Fact 3.13. Every continuous map f : |K | \u2192 |K | can be approximated arbitrarily 1 2 closely by simplicial maps on appropriate subdivisions of K and K . 1 2 This shows that we can consider simplicial maps to be the analogue of continu- ous maps in the world of simplicial complexes. This begs the question whether other definitions from topology, such as homotopies or deformation retracts, have simplicial analogues. As we will see in the next few definitions, they do. Definition 3.14. Two simplicial maps f ,f : K \u2192 K are contiguous if for every 1 2 1 2 simplex \u03c3 \u2208 K we have that f (\u03c3)\u222af (\u03c3) is a simplex in K . 1 1 2 2 This is the simplicial analogue of two continuous maps being homotopic. We can thus show two simplicial complexes to be homotopy equivalent by providing two simplicial maps f : K \u2192 K and g : K \u2192 K such that g\u25e6f is contiguous with the identity map 1 2 2 1 on K and f\u25e6g is contiguous with the identity map on K . 1 2 Definition 3.15. A face of a simplicial complex is called free, if it is non-maximal (not inclusion-maximal) and contained in a unique maximal face. Note that every face that is a superset of a free face is either a maximal face or also free. Definition 3.16. A collapse is the operation of removing all faces \u03b3 that are a superset of some fixed free face \u03c4 (including \u03c4 itself). A simplicial complex is collapsible if there is a sequence of collapses leading to a single point. 29 Chapter 3. Homology Introduction to TDA A collapse can be written as a deformation retract. Thus, a simplicial complex that is collapsible is contractible, and we consider collapses to be the simplicial analogue of deformation retracts. You might wonder whether every contractible simplicial complex is also collapsi- ble. We will see that this not hold: A good counterexample for this is Bing\u2019s house with two rooms, see Figure 3.3. In any triangulation of it, there are no free faces: As a 2-dimensional space, there are only vertices, edges and triangles. We only have to check edges, since triangles are maximal, and vertices are part of edges which are never maximal. Every edge is incident to at least two triangles (there are no edges on the \u201cboundary\u201d), and thus they are not free. Since we have no free faces, it is not collapsible. Figure 3.3: Bing\u2019s house with two rooms. Image taken from [2]. On the other hand, Bing\u2019s house is contractible: both Bing\u2019s house and a point"}
{"node_id": "tdanotes:3.1", "pdf_id": "tdanotes", "section_id": "3.1", "chunk_id": "3.1-4", "text": "are never maximal. Every edge is incident to at least two triangles (there are no edges on the \u201cboundary\u201d), and thus they are not free. Since we have no free faces, it is not collapsible. Figure 3.3: Bing\u2019s house with two rooms. Image taken from [2]. On the other hand, Bing\u2019s house is contractible: both Bing\u2019s house and a point are deformation retracts of a 3-dimensional ball, and thus by Fact 2.24 they are homotopy equivalent. For a visual sketch of the deformation retract from a 3-dimensional ball to Bing\u2019s house, see Figure 3.4. To summarize, the connection between simplicial complexes and topological spaces is that every simplicial complex defines a topological space, since we can consider a geomet- ricembedding, andtheunderlyingspaceoftheembeddinginheritsthesubspacetopology from Rd. On the other hand, some topological spaces (the triangulable ones) can be ex- pressed by simplicial complexes. As for maps, every simplicial map is continuous. On the other hand, continuous maps between simplicial complexes can be approximated by simplicial maps between subdivisions of the simplicial complexes. A similar property holds between homotopic maps and contiguous maps, as well as between deformation retracts and collapses. In general, we can say that the terms in combinatorial topol- ogy are special cases of their \u201ccontinuous\u201d counterparts, and if we consider triangulable spaces, the continuous terms can be approximated in some way by their combinatorial counterparts. The terms can thus be considered to be equivalent. Table 3.1 summarizes the equivalent words in \u201ccontinuous topology\u201d on triangulable spaces and in combinatorial topology on simplicial complexes. 30"}
{"node_id": "tdanotes:3.2", "pdf_id": "tdanotes", "section_id": "3.2", "chunk_id": "3.2-0", "text": "Introduction to TDA 3.2. Homology Figure 3.4: A visual representation of the deformation retract from a 3-dimensional ball to Bing\u2019s house. Images taken from the blog Sketches of topology [1]. \u201ccontinuous\u201d topology combinatorial topology topological spaces simplicial complexes continuous maps simplicial maps homotopic maps contiguous maps deformation retracts collapses Table 3.1: Equivalent notions in \u201ccontinuous\u201d and combinatorial topology 3.2 Homology Recall that homology is intended as a tool to count holes in objects, and recall that this hole count is intended as an invariant of topological spaces under homotopy equiv- alence. We have introduced simplicial complexes, which allow us to consider concrete combinatorial descriptions instead of abstract topological spaces. Let us begin with some basic intuition for holes in simplicial complexes, before diving into the more technical definitions. Consider the two simplicial complexes shown in Figure 3.5. How many (and what kind of) holes should these complexes intuitively have? 31 Chapter 3. Homology Introduction to TDA d d c c a b a b K K 1 2 Figure 3.5: Two simplicial complexes. K contains all four triangles 1 {a,b,c},{a,b,d},{a,c,d},{b,c,d} as well as their subsets, while K 2 only contains the three triangles {a,b,c},{a,c,d},{b,c,d} and their sub- sets. As can be seen, K is the boundary of a tetrahedron. It is a triangulation of the 1 2-dimensional (hollow) sphere, so we would like to say that it has a hole, or cavity. In particular, because this cavity is of the same dimension as the cavity in the 2-dimensional sphere, we want to call this cavity a 2-dimensional hole. On the other hand, K can be viewed as a triangulation of four points in the plane, 2 wherethepointaliesinsidetheconvexhulloftheotherthreepoints. Itishomeomorphic to a 2-dimensional disk. Intuitively we would like to say that the complex K does not 2 have any holes. As a 2-dimensional disk, K has a boundary, consisting of the edges {a,b}, {b,d} 2 and {a,d}. On the other hand, K has no boundary, just as a sphere has no boundary. 1 We will later define a notion of boundary capturing this intuition, at least for pure simplicial complexes, that is, simplicial complexes whose maximal faces all have the same dimension. For example, a 1-dimensional pure simplicial complex is just a graph with no isolated vertices. In such a graph, the boundary will contain all the leaves (vertices of degree 1). Some complexes, like K , will have an empty boundary, and in analogy 1 to graphs without leaves we call such complexes cycles1. Under this viewpoint, our d- dimensional holes of a simplicial complex K should be d-dimensional pure subcomplexes that are cycles. On the other hand, clearly not all cycles should be holes, as can be seen with the boundary of K . This boundary (the three edges {a,b}, {b,d} and {a,d}) itself 2 does not have a boundary, and is thus a 1-dimensional cycle. However we do not want to consider this cycle as a 1-dimensional hole of K since it is \u201cfilled up\u201d, it is the boundary 2 of the three filled in triangles. Summed up, our intuition is that holes are subcomplexes that have no boundary (cycles) and that are not themselves boundaries of another subcomplex which would be filling in the hole. In the following we will make this intuition precise by defining the types of subcomplexes we consider, the notions of boundaries and cycles, and how to mathematically describe the cycles that are not boundaries. 1Note that technically graphs without leaves are not necessarily just cycles, but can also consist of multiple cycles glued together at vertices and edges. 32"}
{"node_id": "tdanotes:3.2", "pdf_id": "tdanotes", "section_id": "3.2", "chunk_id": "3.2-1", "text": "we will make this intuition precise by defining the types of subcomplexes we consider, the notions of boundaries and cycles, and how to mathematically describe the cycles that are not boundaries. 1Note that technically graphs without leaves are not necessarily just cycles, but can also consist of multiple cycles glued together at vertices and edges. 32"}
{"node_id": "tdanotes:3.2.1", "pdf_id": "tdanotes", "section_id": "3.2.1", "chunk_id": "3.2.1-0", "text": "Introduction to TDA 3.2. Homology 3.2.1 Chains In the following we let K be a simplicial complex, and we use m to denote the number p of p-simplices in K. We first want to define p-chains, which are simply an algebraic way of formalizing and generalizing subsets of p-simplices. Definition 3.17. A p-chain c (in K) is a formal sum of p-simplices added with some coefficients from some ring R. A p-chain c can thus be written as (cid:88)mp c = \u03b1 \u03c3 , i i i=1 where \u03b1 \u2208 R and \u03c3 \u2208 K are p-simplices. i i All we are doing in this formal sum is giving a coefficient from R to each p-simplex of K. A formal sum is only a sum in a syntactic sense (i.e., we use the symbols + (cid:80) and ), but there is no semantic meaning behind this operation; there is no other way to represent a chain other than the sum it is defined by. Using the addition operation of the ring R however, we can now also add two p-chains (cid:80) (cid:80) c = \u03b1 \u03c3 and c\u2032 = \u03b1\u2032\u03c3 (both in K). Since the chains are both just formal sums, i i i i we can simply do this addition \u201ccomponent-wise\u201d, using addition in R on the coefficients: (cid:88)mp c+c\u2032 := (\u03b1 +\u03b1\u2032)\u03c3 i i i i=1 We therefore have an addition operation on the set C (K) of all p-chains in K. We p show next that C (K) endowed with this operation forms a group, and we call it the p p-th chain group (of K). Observation 3.18. (C (K),+) is an abelian group, it is free, and the p-simplices form p a basis. Proof. To show that it is a group we observe that: 1. C (K) is closed under addition, since \u2200c ,c \u2208 C (K) we have c +c \u2208 C (K). p 1 2 p 1 2 p 2. The operation + is associative: \u2200c ,c ,c \u2208 C (K), (cid:80) 1 (cid:80)2 3 p (cid:80) (c +c )+c = (\u03b1(1) +\u03b1(2))\u03c3 + \u03b1(3)\u03c3 = (\u03b1(1) +\u03b1(2) +\u03b1(3))\u03c3 = (cid:80)1 2 (cid:80)3 i i i i i i i i i \u03b1(1)\u03c3 + (\u03b1(2) +\u03b1(3))\u03c3 = c +(c +c ). i i i i i 1 2 3 (cid:80) 3. We have a neutral element 0 = 0\u03c3 \u2208 C (K). i p (cid:80) 4. Every element has an inverse: \u2200c \u2208 C (K) we have \u2212c = (\u2212\u03b1 \u03c3 ) \u2208 C (K) and (cid:80) p i i p c+(\u2212c) = (\u03b1 \u2212\u03b1 )\u03c3 = 0. i i i 33"}
{"node_id": "tdanotes:3.2.2", "pdf_id": "tdanotes", "section_id": "3.2.2", "chunk_id": "3.2.2-0", "text": "Chapter 3. Homology Introduction to TDA Commutativity follows from + in R being commutative (recall that for any ring (R,+,\u00b7), (R,+)isanabeliangroup), thusthegroupisabelian. Finally, thep-simplicesclearlyform a basis since the set of chains is defined as the set of formal sums of these p-simplices. We can further turn C (K) into an R-module: p Observation3.19. Equipped with the appropriate function \u00b7 : R\u00d7C (K) \u2192 C (K), C (K) p p p is an R-module. Proof (sketch). We can define r\u00b7c by simply using the multiplication \u00b7 of R component- (cid:80) (cid:80) wise on each coefficient of c, i.e., r\u00b7 mp \u03b1 \u03c3 = mp (r\u00b7\u03b1 )\u03c3 . We leave the proof of i=1 i i i=1 i i the necessary properties as an exercise. From now on we will always work with one of the simplest possible rings, the ring R = Z . In particular this allows us to simply view chains as sets of p-simplices, the sum 2 of chains being their symmetric differences, and we get the nice identity c+c = 0. With R = Z , we will define homology over Z , often also just called Z -homology. Using 2 2 2 some slightly more abstract definitions, all of the following can be extended to define homology over any ring R. For more on this, we refer to any textbook on algebraic topology, e.g., the one by Hatcher [2]. 3.2.2 Boundary Maps Now that we can talk algebraically about sets of p-simplices, we can now formalize the notion of the boundary. It should be intuitively clear what the boundary of a single p-simplex should be: just take the (p\u22121)-chain formed by its facets. More formally, let \u03c3 = {v ,...,v } be a p-simplex. Then, \u03b4 (\u03c3) is defined by 0 p p (cid:88)p {v ,...,v }+{v ,v ,...,v }+...+{v ,...,v } = {v ,...,v\u02c6,...,v } 1 p 0 2 p 0 p\u22121 0 i p i=0 In the above notation, v\u02c6 denotes that the element v is omitted from the set. Note that i i \u03b4 (\u03c3) is indeed a (p\u22121)-chain. For some examples, see Figure 3.6. p 3 3 \u03b4 ( ) = + + \u2248 2 1 2 1 2 \u03b4 ( ) = 0 0 Figure 3.6: The boundary chains of two different simplices. We have seen that \u03b4 is a map that sends a p-simplex to a (p \u2212 1)-chain. Thanks p to the group structure of the chain group, we can now immediately extend this to any 34 Introduction to TDA 3.2. Homology chain. After this extension, \u03b4 defines a map from C (K) to C (K): p p p\u22121 \u03b4 : C (K) \u2192 C (K) p(cid:88)p p\u22121 (cid:88) c = \u03b1 \u03c3 (cid:55)\u2192 \u03b4 (c) = \u03b1 (\u03b4 (\u03c3 )) i i p i p i It is easy to prove that \u03b4 is a group homomorphism, and we call it the boundary operator homomorphism. Let us apply this definition to the following example. In a slight abuse of notation in favor of legibility, we denote faces {a,b,c} by abc. d b a e c \u03b4 (abc+bcd) = \u03b4 (abc)+\u03b4 (bcd) 2 2 2 = (ab+bc+ac)+(bc+cd+bd) = ab+ac+cd+bd \u03b4 (abc+bcd+bce) = (ab+bc+ac)+(bc+cd+bd)+(bc+ce+be) 2 = ab+bc+ac+cd+bd+ce+be We can see that an edge is in the boundary of a chain of triangles exactly if it is contained in an odd number of triangles of the chain, thanks to the fact that we use addition in Z . 2 We have already seen that cycles can be boundaries. On the flipside we have also seen that the boundary of a simplex"}
{"node_id": "tdanotes:3.2.2", "pdf_id": "tdanotes", "section_id": "3.2.2", "chunk_id": "3.2.2-1", "text": "that an edge is in the boundary of a chain of triangles exactly if it is contained in an odd number of triangles of the chain, thanks to the fact that we use addition in Z . 2 We have already seen that cycles can be boundaries. On the flipside we have also seen that the boundary of a simplex should have no boundary (i.e., it should be a cycle), where the interior of the simplex fills up the cavity given by its boundary. The following lemma generalizes this to boundaries of any chain: It states that the boundary of any boundary is empty. Lemma 3.20. For p > 0, \u03b4 \u25e6\u03b4 (c) = 0, for any p-chain c. p\u22121 p In the example above, \u03b4 (\u03b4 (abc+bcd)) = (a+b)+(a+c)+(c+d)+(b+d) = 0. 1 2 (cid:80) Proof. It is enough to show this for simplices, as \u03b4 \u25e6\u03b4 (c) = \u03b4 ( \u03b1 (\u03b4 (\u03c3 ))) = (cid:80) p\u22121 p p\u22121 i p i \u03b1 (\u03b4 \u25e6\u03b4 (\u03c3 )). For a p-simplex \u03c3, every (p\u22122)-face of \u03c3 is contained in exactly 2 i p\u22121 p i (p\u22121)-faces of \u03c3, and does thus not appear in \u03b4 \u25e6\u03b4 (\u03c3). p\u22121 p 35"}
{"node_id": "tdanotes:3.2.3", "pdf_id": "tdanotes", "section_id": "3.2.3", "chunk_id": "3.2.3-0", "text": "Chapter 3. Homology Introduction to TDA The notions of homology we will introduce below actually generalize to any sequence of group homomorphisms \u03b4 that fulfill Lemma 3.20 above. Each such sequence of ho- i momorphisms defines a so-called chain complex: 0 = C (K) \u2212 \u03b4 k\u2192+1 C (K) \u2212 \u03b4 \u2192k C (K)\u00b7\u00b7\u00b7C (K) \u2212 \u03b4 \u21922 C (K) \u2212 \u03b4 \u21921 C (K) \u2212 \u03b4 \u21920 C = 0 k+1 k k\u22121 2 1 0 \u22121 0 C (K) C (K) C (K) p p\u22121 p\u22122 Figure 3.7: A schematic illustration of a part of a chain complex. 3.2.3 Cycle and Boundary Groups As we already established intuitively, chains without boundaries are called cycles. These are the objects potentially giving rise to holes or cavities. Definition 3.21. A p-chain c is a p-cycle if \u03b4(c) = 0. Z (K) is the p-th cycle group, p consisting of all p-cycles of K. Lemma 3.22. Z (K) is a group. p Proof. Z (K) = ker\u03b4 . (Recall that the kernel of a homomorphism is a subgroup of its p p domain.) So far we have only formally defined a boundary operator, but have not specified which chains we call boundaries. Of course, as already used implicitly before, the bound- aries are the chains that are the result of applying the boundary operator. Definition 3.23. A p-chain c is a p-boundary if \u2203c\u2032 \u2208 C (K) such that \u03b4(c\u2032) = c. p+1 B (K) is the p-th boundary group, consisting of all p-boundaries of K. p Lemma 3.24. B (K) is a group. p Proof. B (K) = im\u03b4 . p p+1 In the following, we will often drop the \u201c(K)\u201d of C (K),Z (K), and B (K) when it is p p p clear which simplicial complex we are speaking about. Fact 3.25. B \u2286 Z \u2286 C , and all of them are abelian and free. p p p We will not prove this statement here, but to see that B \u2286 Z , recall that by p p Lemma 3.20 the boundary of a boundary is empty. 36"}
{"node_id": "tdanotes:3.2.4", "pdf_id": "tdanotes", "section_id": "3.2.4", "chunk_id": "3.2.4-0", "text": "Introduction to TDA 3.2. Homology 3.2.4 Homology Groups We are now ready to formalize the notion of holes or cavities. Recall that intuitively, a hole is a cycle that is not a boundary, that is, not filled by something higher-dimensional. Using that all objects defined so far form abelian groups, we can phrase this in algebraic terms using quotient groups. Definition 3.26. The p-th homology group H (K) is the quotient group Z (K)/B (K). p p p Often in the literature we write H (K;R) for homology over some ring R. Since we p only work with homology over Z in these lecture notes, we just write H (K) to mean 2 p H (K;Z ). p 2 Remember that the elements of a quotient group are cosets. In essence, each element of the homology group is a coset called a homology class which contains cycles that differ only by boundaries. The coset [c] = c+B is the homology class of c. We say that p c and c\u2032 are homologous, if [c] = [c\u2032], which is equivalent to the statements c \u2208 c\u2032 +B p and c+c\u2032 \u2208 B . See Figure 3.8 for an example of homologous cycles, and Figure 3.9 for p an example of the first homology group of a small complex. c c(cid:48) Figure 3.8: c\u2032 and c are homologous cycles. 3 K : 4 H (K) : {0,123,234,1234} \u223c = Z2 1 1 2 2 Figure 3.9: The first homology group of a small complex. Exercise 3.27. Visualize the following simplicial complex K: 0-faces {a,b,c,d,e}, 1- faces {ab,ac,ad,bc,bd,cd,ce,de} and 2-faces {abc,abd,acd,bcd}. For the dimen- sions 1 & 2, what are the cycle, boundary, and homology groups of K? Note: You can express the groups by their generators. You do not need to write out all the elements. 37 Chapter 3. Homology Introduction to TDA Figure 3.10: A torus. Exercise 3.28. Give an informal derivation for the homology groups of a torus (see Figure 3.10). Can you find a space with isomorphic homology that is not homeo- morphic to the torus? Exercise 3.29. For a simplicial complex K, its cone CK is the complex with the same set of vertices plus one additional vertex z, and such that for all simplices in K we have {a,b,c,...} \u2208 K =\u21d2 {a,b,c,...,z} \u2208 CK (a) Visualize a cone operation. What does it intuitively do to a complex? (b) Show that the homology of the cone CK is 0 in all dimensions d > 0, for any K. (c) Bonus: What would happen (intuitively and to the homology) if we extended K in the same way as before, but with two points? (this is called the suspension of K) Here are some nice properties of homology groups, that will be beneficial for us, but that we will not prove here. Fact 3.30. \u2022 H is abelian and free. p \u2022 H is a Z -vector space. p 2 Remark 3.31. If we consider homology defined over other rings, e.g. over Z instead of Z , the homology groups might not be free. 2 38"}
{"node_id": "tdanotes:3.2.5", "pdf_id": "tdanotes", "section_id": "3.2.5", "chunk_id": "3.2.5-0", "text": "Introduction to TDA 3.2. Homology Recallthatouroriginalmotivationforintroducinghomologywastocountthenumber of holes. With homology as we defined it, we have the algebraic structure of a vector space where we can add holes together. The number of distinct holes is now just the dimension of this vector space. Definition 3.32. \u03b2 := dimH = dimZ \u2212dimB is the p-th Betti number. p p p p In the definition above, dim denotes the dimension of a vector space as you know it from linear algebra, i.e., dimH is the number of elements in a basis of H . p p Exercise 3.33. The Euler characteristic of a simplicial complex K is defined as \u03c7 = k \u2212k +k \u2212... 0 1 2 with k denoting the number of i-dimensional simplices in K. Convince yourself that i this is an invariant property for all triangulations of the same topological space X. Hint: Show instead that \u03c7 = \u03b2 (K)\u2212\u03b2 (K)+.... The statement then follows by 0 1 the fact that homeomorphic spaces have the same homology. Exercise 3.34. Take any vector v = (a ,...,a ) \u2208 Nd+1 with a > 0. Show that there 0 d 0 exists a simplicial complex K with that vector as its Betti numbers. v 3.2.5 Singular Homology With our definition of homology for simplicial complexes, we get for free a notion of homology for many topological spaces, namely the triangulable ones: we can simply triangulate them and take the homology of the triangulation. But, a topological space may have many triangulations, and it seems like the structure of the homology groups might differ depending on the choice of triangulation. The aim of this section is to sketch the tools that show that the homology of a triangulable space is independent of the chosen triangulation. The idea of singular homology is to remove the need for a fixed triangulation by looking at all possible simplices at once. Let X be a topological space, and let \u2206p be the standard p-simplex in Rp+1. We want to consider all possible occurrences of this simplex in X. Definition 3.35. A singular p-simplex is a map \u03c3 : \u2206p \u2192 X. Note that in this definition we do not require \u03c3 to be injective, thus it would even be possible to map the simplex to a single point. We now define C (X) the same way as before, but now on the family of all singular p p-simplices, which in general makes the group uncountably infinite. We also define \u03b4 p as before, defining Z (X) and B (X), which are now also uncountably infinite. Finally, p p we again define H (X) = Z (X)/B (X). Surprisingly, this definition agrees with the p p p simplicial definition of homology on any triangulation of X. 39"}
{"node_id": "tdanotes:3.2.7", "pdf_id": "tdanotes", "section_id": "3.2.7", "chunk_id": "3.2.7-0", "text": "Chapter 3. Homology Introduction to TDA Theorem 3.36. Let X be a topological space, K a triangulation of X. Then we have \u223c H (X) = H (K) for all p \u2a7e 0. p p As isomorphisms for vector spaces are an equivalence relation, we also get the desired independence of the triangulation. \u223c Corollary 3.37. Let K ,K be two distinct triangulations of X. Then, H (K ) = H (K ) 1 2 p 1 p 2 for all p \u2a7e 0, that is, homology is independent of the chosen triangulation. For the remainder of these lecture notes we will only work with simplicial homol- ogy, but we often talk about the homology of a triangulable space without specifying a triangulation. The above corollary gives us the right to do this. 3.2.6 The 0-th homology group The homology group that is easiest to understand is the 0-th one. Recall that the 0- simplices of a simplicial complex K are simply its vertices. Since vertices do not have any boundaries, every vertex is a 0-cycle. The boundary of a 1-simplex simply consists of the two vertices which are connected by the edge. We can thus see that two vertices v and v are homologous if there is a path from v to v , and the homology class [v ] is 1 2 1 2 1 simply the connected component containing v . 1 Observation 3.38. \u03b2 (K) is the number of connected components of K. 0 As a consequence, the 0-homology classes are all the formal sums of connected com- ponents. 3.2.7 Homology of Spheres One of the main intuitions for us when we introduced homology was that a d-sphere should have a single d-hole and no other holes. We will now check whether our definition captured this intuition correctly. Since we have seen in Section 3.2.5 that homology is independent from the chosen triangulation, let us fix some triangulation of the sphere Sd. A good candidate (due to its simplicity) is the boundary of a simplex, that is, Sd \u2243 \u03b4(\u2206d+1), with the vertex set V = {v ,...,v }. 0 d+1 H (Sd): Let us first investigate H (Sd). Since all vertices are connected, all vertices are 0 0 \u223c homologous, and H (Sd) = \u27e8[v]\u27e9 = Z . 0 2 H (Sd): Next, let us check H (Sd). We first compute Z : The d-simplices are exactly d d d the sets \u03c3 = {v ,...,v\u02c6,...,v }. Note that every (d\u22121)-simplex occurs as the bound- i 0 i d+1 ary of exactly two such d-simplices. Thus, both the zero element (empty chain) as well as the chain c consisting of all d-simplices are part of Z . On the other hand, no chain d c\u2032 \u0338\u2208 {0,c} can be a cycle, since for such a chain there must be some d-simplex \u03c3 \u2208 c\u2032 40"}
{"node_id": "tdanotes:3.2.8", "pdf_id": "tdanotes", "section_id": "3.2.8", "chunk_id": "3.2.8-0", "text": "Introduction to TDA 3.2. Homology neighboring some d-simplex \u03c3\u2032 \u0338\u2208 c\u2032. The (d\u22121)-simplex that is a boundary of both \u03c3 and \u03c3\u2032 would then be part of \u03b4 (c\u2032). We conclude that Z (Sd) = \u27e8c\u27e9. p d Since \u03b4(\u2206d+1) is a d-dimensional simplicial complex, and thus does not contain any (d+1)-simplices, no non-empty d-chain can be a boundary. We thus get that B (Sd) is d the group containing only 0. \u223c We finally get H (Sd) = Z /B = Z = Z . d d d d 2 (cid:80) H (Sd): Finally, let us go to H (Sd), for 0 < p < d: Let c = \u03b1 \u03c3 be a p-cycle. We p p i i aim to show that c is homologous to the 0-chain, i.e., that [c] = [0]. Equivalently, we show that c must be a boundary. Let \u03c3 = (v ,...,v ) be any p-simplex in c which does not include v . We will m 0 mp 0 keep replacing such simplices by simplices which do contain v , until we have no more 0 simplices not containing v . 0 Let b be the (p+1)-simplex (v ,v ,...,v ). Note that b \u2208 \u03b4(\u2206d+1) and thus \u03b4(b) 0 m 0 mp is a p-boundary. Also note that \u03c3 is in \u03b4(b). Furthermore, \u03c3 is the only p-simplex in \u03b4(b) which does not contain v . We now add \u03b4(b) to c, to get c\u2032 := c+\u03b4(b). Since we 0 added a boundary, [c] = [c\u2032] (i.e., c and c\u2032 are homologous). Furthermore, c\u2032 contains one fewer p-simplex not containing v , when compared to c. 0 We repeat this process until we reach a cycle c\u2217 in which every p-simplex contains v . We now claim that c\u2217 must be the trivial cycle: Assume c\u2217 contains some p-simplex 0 a = (v ,v ,...,v ). Then, the (p\u22121)-simplex a\u2032 = (v ,...,v ) is part of \u03b4(a). But, 0 a 1 ap a 1 ap a\u2032 cannot be part of the boundary of any other p-simplex in c\u2217, since the only p-simplex containing a\u2032 as a face while also containing v is a. Thus, to have an empty boundary, 0 we have c\u2217 = 0. By construction, [c] = [c\u2217], therefore [c] = 0 as we aimed to prove. We have proven that every cycle is homologous to 0, and we can conclude that for all 0 < p < d, H (Sd) = 0. p Since Sd is d-dimensional, we do not have any simplices of dimensions p > d, and thus H (Sd) = 0 for p > d. Combining all these arguments we conclude the following p theorem: Theorem 3.39. For any d > 0, we have (cid:14) Z p \u2208 {0,d} H (Sd) = 2 p 0 else. (cid:14) 1 p \u2208 {0,d} \u03b2 (Sd) = p 0 else. 3.2.8 Induced Homology As usual, now that we have defined some mathematical objects (homology groups) we are also interested in the maps between them. For simplicial complexes we have defined 41 Chapter 3. Homology Introduction to TDA simplicial maps, and we now want to study the effect that simplicial maps have on the homology of a space. We first extend simplicial maps to the chain groups. Definition 3.40. Let f : K \u2192 K be a simplicial map. This induces a chain map 1 2 f : C (K ) \u2192 C (K ) # p 1 p 2 (cid:14) (cid:88) (cid:88) f(\u03c3 ) if f(\u03c3 ) is p-simplex in K i i 2 c = \u03b1"}
{"node_id": "tdanotes:3.2.8", "pdf_id": "tdanotes", "section_id": "3.2.8", "chunk_id": "3.2.8-1", "text": "We first extend simplicial maps to the chain groups. Definition 3.40. Let f : K \u2192 K be a simplicial map. This induces a chain map 1 2 f : C (K ) \u2192 C (K ) # p 1 p 2 (cid:14) (cid:88) (cid:88) f(\u03c3 ) if f(\u03c3 ) is p-simplex in K i i 2 c = \u03b1 \u03c3 (cid:55)\u2192 f (c) := \u03b1 \u03c4 , where \u03c4 = i i # i i i 0 otherwise Note that f(\u03c3 ) is always a simplex in K since f is a simplicial map, but it could be a i 2 simplex of smaller dimension. This is why we need the condition in the above definition of \u03c4 . i The following can be shown with a bit of work: \u2022 f \u25e6\u03b4 = \u03b4\u25e6f # # \u2022 f (B (K )) \u2286 f (Z (K )) # p 1 # p 1 \u2022 f (Z (K )) \u2286 Z (K ), f (B (K )) \u2286 B (K ) # p 1 p 2 # p 1 p 2 From this chain map f , we now get a well-defined induced homomorphism between # the homology groups of K and K . 1 2 Definition 3.41. Let f be a simplicial map and f its induced chain map. This induces # a homomorphism f : H (K ) \u2192 H (K ) \u2217 p 1 p 2 [c] = c+B (cid:55)\u2192 f (c)+B (K ) = [f (c)]. p # p 2 # Fact 3.42. If H (K ) and H (K ) are vector spaces (as they are in e.g. Z -homology, p 1 p 2 2 which is what we are using), then f is a linear map. \u2217 We also get the following functorial property, which we will not prove. Fact 3.43. For two simplicial maps f : X \u2192 Y, g : Y \u2192 Z, we have (g\u25e6f) = g \u25e6f . \u2217 \u2217 \u2217 Let us compute the induced homomorphism of a small example: b b a d a d K K 1 2 c c We consider the inclusion map f : K (cid:44)\u2192 K . 1 2 \u223c H (K ) = {0,[abc],[bcd],[abdc]} = Z2 1 1 2 f (0) = 0, f ([abc]) = [abc] \u2217 \u2217 f ([bcd]) = 0, f ([abdc]) = [abc] \u2217 \u2217 42 Introduction to TDA 3.2. Homology Exercise 3.44. Let K = {\u2205,a,b,c,d,e,ab,ac,bc,bd,cd,ce,de,abc} 1 and K = {\u2205,w,x,y,z,wx,wy,xy,xz,yz}. 2 Consider the map f : K \u2192 K induced by the vertex map 1 2 a (cid:55)\u2192 y,b (cid:55)\u2192 x,c (cid:55)\u2192 y,d (cid:55)\u2192 z,e (cid:55)\u2192 z. You can verify easily that f is simplicial. Compute f : H (K ) \u2192 H (K ) for \u2217 p 1 p 2 0 \u2a7d p \u2a7d 2. Exercise 3.45. Which of the following four statements is true for every simplicial map f? \u201cIf f is {injective, surjective}, then f is {injective, surjective}.\u201d \u2217 The following fact has some very powerful consequences, as we will see. Fact 3.46. If f,g : K \u2192 K are contiguous, f = g . 1 2 \u2217 \u2217 Note that the definition of induced homology extends from simplicial maps to maps between any topological spaces. We will not state the exact definitions, but the following fact is the continuous analogue (remember that two simplicial maps being contiguous is analogous to two maps being homotopic) of Fact 3.46. Fact 3.47. If f,g : X \u2192 Y are homotopic, f = g . \u2217 \u2217 Thanks to this fact we get the following corollary,"}
{"node_id": "tdanotes:3.2.8", "pdf_id": "tdanotes", "section_id": "3.2.8", "chunk_id": "3.2.8-2", "text": "any topological spaces. We will not state the exact definitions, but the following fact is the continuous analogue (remember that two simplicial maps being contiguous is analogous to two maps being homotopic) of Fact 3.46. Fact 3.47. If f,g : X \u2192 Y are homotopic, f = g . \u2217 \u2217 Thanks to this fact we get the following corollary, which shows that homology is indeed an invariant under homeomorphisms, and even under homotopy equivalence. This also gives us the option to compute the homology of a space by computing the homology of a potentially simpler homotopy equivalent space. Corollary 3.48. If f : X \u2192 Y is a homotopy equivalence (i.e., there exists g : Y \u2192 X such that f \u25e6 g is homotopic to id and g \u25e6 f is homotopic to id ), then f is an Y X \u2217 isomorphism. Proof. Thanks to Fact 3.43 we have (g\u25e6f) = g \u25e6f . By Fact 3.47, (g\u25e6f) = (id ) , \u2217 \u2217 \u2217 \u2217 X \u2217 whichisanisomorphism. Sincewethusknowthatg \u25e6f isanisomorphism,weknowthat \u2217 \u2217 f must be injective and g must be surjective. By a symmetric argument considering \u2217 \u2217 f \u25e6 g we also get that f is surjective and g is injective, and thus both f and g are \u2217 \u2217 \u2217 \u2217 isomorphisms. Exercise 3.49. Consider the space you get when you glue together two points of a torus. What is the homology of this space? 43"}
{"node_id": "tdanotes:3.2.9", "pdf_id": "tdanotes", "section_id": "3.2.9", "chunk_id": "3.2.9-0", "text": "Chapter 3. Homology Introduction to TDA Consider the space you get when you simultaneously pierce a balloon at n distinct locations. What is the homology of this space? Exercise 3.50. Let f,g : S1 \u2192 S1 be continuous maps such that f(\u2212x) = f(x) and g(\u2212x) = \u2212g(x) for all x \u2208 S1. a) Convince yourself that f : H (S1) \u2192 H (S1) is trivial (maps everything to 0) \u2217 1 1 and that g is an isomorphism. \u2217 b) Show that f and g are not homotopic. c) Show that there is no map h : S2 \u2192 S1 such that h(\u2212x) = \u2212h(x). d) Conclude that every map \u03d5 : S2 \u2192 R2 with \u03d5(\u2212x) = \u2212\u03d5(x) has a zero. The statement you have proven in d) is equivalent to the 2-dimensional case of the famous Borsuk-Ulam theorem, which implies statements such as \u201cat any time, there are two antipodal points on the earth with both the same temperature and atmospheric pressure\u201d. 3.2.9 Application: Brouwer Fixed Point Theorem In this section we finally collect the fruits of our hard work by using homology to give a relatively short proof of the famous fixed point theorem by Brouwer. Here, Bd denotes the unit ball of dimension d. Theorem 3.51 (Brouwer fixed point theorem). Let f : Bd \u2192 Bd be continuous. Then, f has a fixed point, that is, \u2203x \u2208 Bd such that f(x) = x. This theorem has many fascinating implications: \u2022 Take two sheets of paper lying on top of each other. Crumple the top sheet and set it back onto the other sheet. No matter how you crumpled the sheet, at least one point of the crumpled sheet lies exactly above its corresponding point in the bottom sheet. \u2022 If you open a map of Switzerland in Switzerland, there is at least one point on the map which is at its exact position.2 \u2022 If you take a cup of liquid and stir or slosh it, at least one atom ends up at its original position (but if you shake you might break continuity). \u2022 The theorem also has many applications in mathematics and computer science, such as in fair divisions or for proving existence of Nash equilibria. 2The theorem only applies when ignoring the Italian and German exclaves of Campione d\u2019Italia and B\u00fcsingen am Hochrhein. 44 Introduction to TDA 3.2. Homology ToproveTheorem3.51,wefirstintroducethefollowingdefinitionandahelperlemma, which we only prove after proving Theorem 3.51 itself. Definition 3.52. A map r : X \u2192 A \u2286 X is a retraction if r(a) = a, \u2200a \u2208 A. Lemma 3.53. There is no retraction r : Bd \u2192 Sd\u22121. Proof of Theorem 3.51. We prove the theorem by contradiction. For an illustration of the argument see Figure 3.11. Assume f : Bd \u2192 Bd has no fixed point. For each \u2212\u2212\u2212\u2192 x, consider the ray f(x)x and let r(x) be the intersection of this ray with Sd\u22121. Then, r : Bd \u2192 Sd\u22121 is continuous (which we do not prove here) and r(s) = s \u2200s \u2208 Sd\u22121, since \u2212\u2212\u2192 no matter where f(s) lies, f(s)s first intersects Sd\u22121 in s. Thus, r is a retraction, which does not exist by Lemma 3.53. f(x) x r(x) Figure 3.11: If f has no fixed point, we get a retraction to the boundary. It remains to prove the helper lemma. Proof of Lemma 3.53. Consider the inclusion map i : Sd\u22121 (cid:44)\u2192 Bd, and a retraction r : Bd \u2192 Sd\u22121. By definition, we have r \u25e6 i = id. Let us look at the induced maps \u223c of r and"}
{"node_id": "tdanotes:3.2.9", "pdf_id": "tdanotes", "section_id": "3.2.9", "chunk_id": "3.2.9-1", "text": "f has no fixed point, we get a retraction to the boundary. It remains to prove the helper lemma. Proof of Lemma 3.53. Consider the inclusion map i : Sd\u22121 (cid:44)\u2192 Bd, and a retraction r : Bd \u2192 Sd\u22121. By definition, we have r \u25e6 i = id. Let us look at the induced maps \u223c of r and i in the (d \u2212 1)-th homology of Sd\u22121 and Bd. Recall that H (Sd\u22121) = Z d\u22121 2 \u223c and H (Bd) = 0. We thus view i as a homomorphism from Z to 0, and r as a d\u22121 \u2217 2 \u2217 homomorphism from 0 to Z . But since r \u25e6 i = id, we also have r \u25e6 i = id. We can 2 \u2217 \u2217 combine this to reach a contradiction: 1 = id(1) = (r \u25e6i )(1) = r (i (1)) = r (0) = 0 \u2217 \u2217 \u2217 \u2217 \u2217 Thus, either i or r cannot exist, but since i exists, r cannot. 45 Chapter 3. Homology Introduction to TDA Questions 5. What is a simplicial complex? Define geometric and abstract simplicial com- plexes and state and prove the realization theorem (Theorem 3.5). 6. What are simplicial and contiguous maps? State the definitions and discuss the connection to their counterparts in continuous topology. 7. Is every contractible simplicial complex collapsible? Define the notion of col- lapsibility and describe Bing\u2019s house with two rooms. 8. What is simplicial homology? Explain the intuition and give the formal defini- tions of chains, boundaries and cycles. 9. Why is the homology of a triangulable space independent of the chosen trian- gulation? Explain the idea of singular homology. 10. What are the homology groups of a sphere? State and prove the corresponding theorem (Theorem 3.39). 11. How does a simplicial map between two simplicial complexes induce maps between their homology groups? Define induced homomorphisms. 12. What is the Brouwer fixed point theorem? State, illustrate and prove the Brouwer fixed point theorem (Theorem 3.51). References [1] Kenneth Baker, Sketches of topology - Bing\u2019s house. https://sketchesoftopology. wordpress.com/2010/03/25/bings-house/, accessed: 2023-04-27. [2] Allen Hatcher, Algebraic topology, Cambridge Univ. Press, Cambridge, 2000. 46"}
{"node_id": "tdanotes:4.1", "pdf_id": "tdanotes", "section_id": "4.1", "chunk_id": "4.1-0", "text": "Chapter 4 Persistence In the previous chapter, we have studied the homology of fixed simplicial complexes. In this chapter, we will look at simplicial complexes that grow over time. Let us start with a small example. Consider the following process of building up a triangle abc. At time t , we add the vertices a and b together with the edge ab. This gives birth to a single 1 connectedcomponent. Attimet weaddthevertexc, givingbirthtoasecondconnected 2 component. At time t we add the edge ac, connecting the two components. We can 3 interpret this as the younger of the components being absorbed by the older component. In more crude language, we say that the younger component dies. At time t we add the 4 final edge bc, which gives birth to a hole, that is, an element of the homology group H . 1 Finally, at time t we add the interior of the triangle, killing the hole born at t . We 5 4 can summarize this process as follows: we have a connected component that was born at t and survived the entire process, and a connected component that was born at t 1 2 that died again at t . Finally, we have a hole born at t dying at t . Capturing this 3 4 5 information of holes with their birth and death is the goal of persistent homology. Persistent homology can be applied to data analysis by defining (in a way that we will seesoon)aprocesstobuildupasimplicialcomplexfrompointclouddataandcomputing the birth and death times of holes. Subtracting the birth time from the death time we get the lifespan of a hole; the underlying idea is that holes with a short lifetime are a byproduct of the process (noise), whereas holes with a long lifespan convey information about the shape of the underlying data. 4.1 Filtrations We start by a mathematical formulation of the process of growing a simplicial complex or, more general, a topological space. A filtration is a nested sequence of subspaces F : X \u2286 X \u2286 X \u2286 ... \u2286 X = X. 0 1 2 n For each i \u2a7d j, we have the inclusion map \u03b9 : X (cid:44)\u2192 X . Given these functions \u03b9, i,j i j we get induced maps in homology: hi,j = \u03b9 : H (X ) \u2192 H (X ). Filtrations are a very p \u2217 p i p j 47"}
{"node_id": "tdanotes:4.2", "pdf_id": "tdanotes", "section_id": "4.2", "chunk_id": "4.2-0", "text": "Chapter 4. Persistence Introduction to TDA general object that appear naturally in many settings. Let us look at some important examples of filtrations. \u2022 Given a function f : X \u2192 R , we can define the (uncountably infinite) sublevel set filtration X = f\u22121(\u2212\u221e,a]. a \u2022 A simplicial filtration is a nested sequence of subcomplexes F : K \u2286 K \u2286 ... \u2286 K = K. 0 1 n We call a simplicial filtration simplex-wise, if K \\ K is a single simplex (or i i\u22121 empty). \u2022 We call a function f : K \u2192 R simplex-wise monotone if for every \u03c3 \u2286 \u03c4 we have f(\u03c3) \u2a7d f(\u03c4). A simplex-wise monotone function guarantees us that the sublevel set filtration by f gives a proper simplicial filtration. Note that it does not necessarily guaranteeusthatthesublevelsetfiltrationissimplex-wise(e.g., considerafunction f that is not injective). \u2022 We can also define a simplicial filtration by ordering our vertices v ,v ,...,v . 0 1 n Then, let K be the simplicial complex induced by the vertices v ,...,v . We call i 0 i the simplices K \\K added when adding v the lower star of v . Thus, this type i i\u22121 i i of filtration is also called the lower star filtration. \u2022 Given some data points in Rd, we can define a filtration based on our intuition of growing balls: We consider the nerve of all balls B(p,r); with growing r we get more and more faces in this nerve. We will later formalize this into the so-called \u010cech complex. 4.2 Persistent Homology As we have seen, from a filtration X \u2286 X \u2286 ... \u2286 X we get a sequence of homology 0 1 n groups with homomorphisms between them: H (F) : H (X ) \u2192 H (X ) \u2192 H (X ) \u2192 ... \u2192 H (X ). p p 0 p 1 p 2 p n Such an object is called a persistence module. Given a persistence module, we can now define groups that capture all the holes that are alive during a certain period. Definition 4.1. The p-th persistent homology group Hi,j is defined by p Hi,j := imhi,j = Z (K )/(B (K )\u2229Z (K )). p p p i p j p i This definition characterizes the cycles that that are present already in K and that i are not boundaries even in K . j 48 Introduction to TDA 4.2. Persistent Homology [c] \u00b7\u00b7\u00b7 H (K ) H (K ) H (K ) H (K ) p i\u22121 p i p j\u22121 p j Figure 4.1: An illustration of a class [c] being born at K and dying entering K . i j Definition 4.2. The p-th persistent Betti numbers \u03b2i,j are the dimensions of the p-th p persistent homology groups: \u03b2i,j = dimHi,j. p p Exercise 4.3. Let p \u2a7e 1. For every n \u2a7e 1, construct a filtration X \u2286 X \u2286 ... \u2286 X 1 2 n such that \u2022 H (X ) \u0338= 0 for all k \u2208 {1,...,n} and p k \u2022 Hi,j = 0 for all i < j. p We say that a p-homology class [c] (a p-hole) is born at K if [c] \u2208 H (K ) but i p i [c] \u0338\u2208 Hi\u22121,i. Similarly, [c] dies entering K , if [c] \u0338= 0 in H (K ) but hj\u22121,j([c]) = 0. p j p j\u22121 p It is not always obvious which homology class dies. Consider the following filtration: X consists of two points a and b, and in X the two points are"}
{"node_id": "tdanotes:4.2", "pdf_id": "tdanotes", "section_id": "4.2", "chunk_id": "4.2-1", "text": "(K ) but i p i [c] \u0338\u2208 Hi\u22121,i. Similarly, [c] dies entering K , if [c] \u0338= 0 in H (K ) but hj\u22121,j([c]) = 0. p j p j\u22121 p It is not always obvious which homology class dies. Consider the following filtration: X consists of two points a and b, and in X the two points are connected by an edge. 1 2 Let us look at H , that is, the connected components. We have that H (X ) \u2243 Z2, with 0 0 1 2 the natural basis {[a],[b]}. On the other hand, in X there is only a single connected 2 component, and [a] = [b]. So a homology class is dying, but both our basis elements [a] and [b] survive. What is happening? It turns out that we were not careful with our choice of basis: H (X ) can also be 0 1 viewed as being generated by [a] and [a+b], and the class [a+b] indeed dies going into X . In general, if two homology classes merge, they both do not die, but their sum does. 2 There is a consistent choice of basis which allows us to only look at persistent homology in terms of basis elements, but we do not go into this at this point. If we have a simplex-wise filtration, we can circumvent the above issue by sorting homology classes by the time where they were born (recall the solution to Exercise 3.33 to see why this gives a total order). When two classes merge, we just say the \u201cyounger one\u201d dies. This can be seen as adapting the considered basis along the way. Persistence pairings are another way around this issue. We add some final complex K which has trivial homology (i.e., by adding all simplices that are not yet present). n+1 Then, we aim to figure out how many holes get born at K and die entering K . For this, i j 49 Chapter 4. Persistence Introduction to TDA F: t t t t t 1 2 3 4 5 H 0 H 1 \u221e \u221e t t 5 5 t t 4 4 t t 3 3 t t 2 2 Dgm (F) Dgm (F) 0 1 t t 1 1 t t t t t t t t t t 1 2 3 4 5 1 2 3 4 5 Figure 4.2: An example of a filtration with the corresponding barcodes and persistence diagrams. we define \u00b5i,j := (\u03b2i,j\u22121 \u2212\u03b2i,j)\u2212(\u03b2i\u22121,j\u22121 \u2212\u03b2i\u22121,j), for i < j \u2a7d n+1. p p p p p Here, the content of the left parenthesis denotes the number of holes born at or before K , which die entering K . Conversely, the right parenthesis denotes the number of holes i j born strictly before K , and die entering K . Thus, subtracting the two, gives the number i j of holes born exactly at K and die entering K . Note that this conveys the information i j that we are interested in, but does not require choosing any basis. The persistence diagram Dgm (F) is a birth-death diagram which contains a point p for every pair i,j for which \u00b5i,j > 0. If we give each K a timestamp a , the point is drawn p i i at the coordinates (a ,a ). We give each point multiplicity \u00b5i,j. On the diagonal we add i j p points with infinite multiplicity, for some technical reasons that will become apparent later. We can also represent the same information by barcodes: For every i,j, we draw"}
{"node_id": "tdanotes:4.2", "pdf_id": "tdanotes", "section_id": "4.2", "chunk_id": "4.2-2", "text": "each K a timestamp a , the point is drawn p i i at the coordinates (a ,a ). We give each point multiplicity \u00b5i,j. On the diagonal we add i j p points with infinite multiplicity, for some technical reasons that will become apparent later. We can also represent the same information by barcodes: For every i,j, we draw \u00b5i,j intervals [a ,a ]. This is then called the p-th persistence barcode. p i j 50"}
{"node_id": "tdanotes:4.3.1", "pdf_id": "tdanotes", "section_id": "4.3.1", "chunk_id": "4.3.1-0", "text": "Introduction to TDA 4.3. Algorithms for Persistent Homology Exercise 4.4. Consider the simplex-wise filtration induced by the order \u03c3 ,...,\u03c3 on 1 N the simplices of a complex K. When does the order \u03c3 ,...,\u03c3 ,\u03c3 ,\u03c3 ,\u03c3 ,...,\u03c3 1 k\u22121 k+1 k k+2 N induce a simplex-wise filtration too? When it does, describe the relation between the corresponding persistence diagrams. Exercise 4.5. Give two filtrations X \u2286 ... \u2286 X and Y \u2286 ... \u2286 Y that have the 1 n 1 n same persistence diagrams but for which for any i \u2208 {1,...,n}, X is not homotopy- i equivalent to Y . i 4.3 Algorithms for Persistent Homology So far we have considered homology and persistent homology only on a mathematical level. However, for practical applications we are interested in actually computing homo- logical information. In this section we discuss how we can compute persistence pairings given simplicial filtrations. This will of course also allow us to compute persistence diagrams and persistence barcodes. 4.3.1 Persistence Pairing Algorithm The first algorithm we consider is the so-called persistence pairing algorithm. It only works on simplex-wise filtrations, we thus restrict our attention to such filtrations. In any time step j, we add a single simplex \u03c3 := K \\K . Let p be its dimension. There j j j\u22121 are only two things that can happen to the homology when adding \u03c3 : Either, a new j non-boundary p-cycle c (i.e., a hole) is born, or a (p\u22121)-cycle becomes a boundary (i.e., a hole dies). In the first case we say that \u03c3 is a creator. Otherwise, we say that \u03c3 j j is a destructor. The fact that in every step exactly one of the two events happens is a consequence of the Euler characteristic, as discussed in Exercise 3.33. When a new simplex \u03c3 destroys a hole, this corresponds to an interval of the persis- j tence barcode ending. The beginning of that interval is at the time step when this hole was born, which corresponds to a unique simplex (recall, we are considering simplex-wise filtrations only). This unique simplex must be a creator, since when it was inserted a hole was born. The idea of the persistence pairing algorithm is to form pairings between destructors and creators. To do this, the algorithm assumes the newly added simplex \u03c3 j to be a destructor, and tries to find the corresponding unpaired creator using a simple heuristic. If no such creator can be found by the procedure, we know that \u03c3 must j actually be a creator itself. The heuristic is quite simple to describe. We have to look for an unpaired creator only within a cycle c that becomes a boundary due to the insertion of \u03c3 . Among this j cycle c, we wish to pair \u03c3 with the youngest unpaired creator. Any such cycle c must j be homologous to \u03b4\u03c3 , which is the simplest candidate for such a cycle c. This is thus j 51 Chapter 4. Persistence Introduction to TDA where the search begins. We first try to pair \u03c3 with the youngest (p\u22121)-simplex \u03c1 of j its boundary. If \u03c1 is unpaired, we pair it to \u03c3 and we are done. Otherwise, \u03c1 is already j paired with some (p-simplex) \u03c4. In this case we replace c by c+\u03b4\u03c4. This is now a new candidate cycle, in which we can try pairing \u03c3 to the youngest simplex. We repeat this j process until we found an unpaired creator we can pair \u03c3 to, or until we cannot continue j because c = 0."}
{"node_id": "tdanotes:4.3.1", "pdf_id": "tdanotes", "section_id": "4.3.1", "chunk_id": "4.3.1-1", "text": "is already j paired with some (p-simplex) \u03c4. In this case we replace c by c+\u03b4\u03c4. This is now a new candidate cycle, in which we can try pairing \u03c3 to the youngest simplex. We repeat this j process until we found an unpaired creator we can pair \u03c3 to, or until we cannot continue j because c = 0. In this case we label \u03c3 as a new creator. At the end of the algorithm j (after processing all steps of the filtration), all remaining unpaired creators correspond to holes present at the last step of the filtration, and we pair them with the element \u221e. We refrain from giving a complete proof of this algorithm\u2019s correctness. Such a proof can be found in [1], however the algorithm presented there is slightly more complex and more efficient. We would only like to note that when we label a simplex a creator that this is correct to do so: If we reach c = 0 we know that the boundary of \u03c3 is homologous j to 0 (we obtained 0 by adding boundaries to \u03b4\u03c3 ). Thus, \u03c3 cannot be a destructor. We j j can thus safely label \u03c3 as a new creator. j We summarize this algorithm in the following pseudocode: Algorithm 1: The persistence pairing algorithm. Input: A simplex-wise filtration of K given by an order of simplices \u03c3 ,...,\u03c3 1 N for j = 1 to n do c := \u03b4\u03c3 ; j while c \u0338= 0 do i := largest integer such that \u03c3 \u2208 c and \u03c3 is creator; i i \u03c1 := \u03c3 ; i if \u03c1 is unpaired then Label \u03c3 as destructor and pair \u03c1 and \u03c3 ; j j c := 0 else \u03c4 := simplex \u03c1 is paired to; c := c+\u03b4\u03c4; end end if \u03c3 has not been labelled a destructor then j Label \u03c3 a constructor; j end end Pair all unpaired constructors with \u221e; Exercise4.6. Let G be a weighted connected graph, where all edge weights are pairwise distinct. Consider a filtration that first inserts all vertices (in some arbitrary order) and then inserts the edges one by one, ordered by increasing weight. What is the set of destructors? 52"}
{"node_id": "tdanotes:4.3.2", "pdf_id": "tdanotes", "section_id": "4.3.2", "chunk_id": "4.3.2-0", "text": "Introduction to TDA 4.3. Algorithms for Persistent Homology 4.3.2 Matrix Reduction Algorithm In practice, a different algorithm is used, the Matrix Reduction Algorithm. This algo- rithm implements the same intuition as the persistence pairing algorithm. It has a few advantages: First off, it is more efficient (it avoids the need to add the same boundaries multiple times, similarly to the version of the persistence pairing algorithm provided in [1]). Second, it is phrased in the language of matrices, which allows us to implement it more efficiently using matrix-multiplication techniques. Lastly, the way we describe it in the following it also works with non-simplex-wise filtrations. In the matrix reduction algorithm, we first find a total order on our simplices. If the input filtration is simplex-wise, this is just the insertion order. Otherwise, we order the simplices primarily by insertion order, and within each set of simultaneously added simplices, we order the simplices by increasing dimension, and then lexicographically. Then, we construct an N\u00d7N matrix, which is the so-called boundary matrix. Each row and column is labelled by a simplex, ordered by the order we defined above. We then insert a 1 at row \u03c3 and column \u03c4, if \u03c3 is part of the boundary of \u03c4. We now modify this boundary matrix to obtain the reduced boundary matrix, from which the persistence pairings can then be read off. We process the columns from left to right. For each column c, we look at the lowest 1 in the column. We call this 1 the pivot element of the column. If there is a column c\u2032 < c to the left that also has a pivot element in the same row, we add c\u2032 to c (in Z ). This is repeated until no such column 2 c\u2032 < c exists. Afterprocessingallthecolumns, thematrixisinareducedform: Foreveryrow, there is at most one column whose lowest 1 (its pivot element) lies in that row. From this we can now read the persistence pairings: Empty columns correspond to creators (births). To find the death of a creator, look at its corresponding row, and search for a column that has a pivot element in that row. This column is the destructor corresponding to the creator. If there is no such column, this creator never dies, i.e., is unpaired or paired with \u221e. We again summarize this algorithm in the pseudocode below. Let us now analyze at the runtime of this algorithm. For each column (O(N)), we might have to add O(N) times a column, and each addition takes O(N). So, by this very rough analysis we have a runtime of O(N3). But, since the reduction process is very similar to Gaussian elimination, we can actually perform the reduction using techniques that yield a runtime of O(N\u03c9), where \u03c9 is the matrix-multiplication exponent. However, in practice this is notveryusefulsinceefficientmatrix-multiplicationalgorithmsareverycomplexandhave large constants, while the naive implementation runs in essentially O(N) time anyways since the involved matrices are so sparse. Exercise 4.7. Consider the following simplicial complex, and the simplex-wise filtra- tion which first inserts the vertices in the order a,b,c,d,e, and the rest of the simplices as specified by the numbering in Figure 4.3. Execute both the persistence pairing algorithm and matrix reduction algorithm on this filtration. What are the similarities and differences in the algorithms? To 53 Chapter 4. Persistence Introduction to TDA Algorithm 2: The matrix reduction algorithm. Input: A filtration of K. Find an ordering \u03c3 ,...,\u03c3 corresponding to a simplex-wise filtration of K 1 N consistent with the given filtration; M := 0N\u00d7N; for 1 \u2a7d i,j \u2a7d N do if \u03c3 \u2208 \u03b4\u03c3 then i"}
{"node_id": "tdanotes:4.3.2", "pdf_id": "tdanotes", "section_id": "4.3.2", "chunk_id": "4.3.2-1", "text": "similarities and differences in the algorithms? To 53 Chapter 4. Persistence Introduction to TDA Algorithm 2: The matrix reduction algorithm. Input: A filtration of K. Find an ordering \u03c3 ,...,\u03c3 corresponding to a simplex-wise filtration of K 1 N consistent with the given filtration; M := 0N\u00d7N; for 1 \u2a7d i,j \u2a7d N do if \u03c3 \u2208 \u03b4\u03c3 then i j M := 1; ij end end for j = 1 to n do \u2113 := max({\u22121}\u222a{i | M = 1}); ij while \u2113 \u0338= \u22121 and \u2203j\u2032 < j such that \u2113 = max({\u22121}\u222a{i | M = 1}) do ij\u2032 M := M +M ; \u00b7j \u00b7j \u00b7j\u2032 \u2113 := max({\u22121}\u222a{i | M = 1}); ij end end for j = 1 to n do if M = 0N then \u00b7j Label \u03c3 a constructor; j for j\u2032 = 1 to n do if j = max({\u22121}\u222a{i | M = 1}) then ij\u2032 Pair \u03c3 to \u03c3 ; j j\u2032 Label \u03c3 a destructor; j\u2032 end end end end Pair all unpaired constructors with \u221e; 54 Introduction to TDA 4.3. Algorithms for Persistent Homology better see what happens, label the columns in the matrix by the sum of columns they currently represent. Represent the results you obtained by a persistence diagram, and also by the persistence barcodes. d 8 c 7 9 13 10 14 12 e 6 a 11 b Figure 4.3: The filtration for Exercise 4.7. Exercise 4.8. A Union-Find data structure is a data structure that maintains disjoint sets dynamically. Given a ground set X, such a data structure maintains a family S of disjoint subsets of X, where each subset is represented by the smallest element contained in it. It supports three operations: MakeSet(x) creates a new set {x}. FindSet(x) returns the representative (minimum) of the set in S which contains x (or \u201cno\u201d if x is not contained in any set). Union(x,y) merges the sets containing x and y into a single one. All of these operations can be implemented in amortized \u0398(\u03b1(n)) time, where \u03b1 is the extremely slowly growing inverse Ackermann function and can be considered a constant for any real world application. Consider a simplicial complex K with its vertices ordered v ,...,v , and consider 0 n its lower star filtration. Find an algorithm to compute the 0-dimensional persistence diagram (i.e., the persistence pairings) of K which makes use of a Union-Find data structure. How many Union-Find operations do you need to perform? Questions 13. What is a filtration? State the definition and describe different ways how filtra- tions appear in topology and data analysis. 14. What is persistent homology? State the formal definitions and give examples. 15. How can persistent homology be computed? Discuss the two algorithms de- scribed in Section 4.3. References [1] Tamal Krishna Dey and Yusu Wang, Computational topology for data analysis, Cambridge University Press, 2022. 55"}
{"node_id": "tdanotes:5.1", "pdf_id": "tdanotes", "section_id": "5.1", "chunk_id": "5.1-0", "text": "Chapter 5 Simplicial Complexes on Point Clouds In general, the data we wish to analyze will not come in the form of a simplicial filtration, so in order to use persistent homology we need to transform our data into one. Ideally, the way we do this should retain the underlying shape of the data we want to analyze. In this section we discuss several ways of constructing simplicial complexes from point cloud data, and more generally, from finite metric spaces (i.e., a finite set of data points with given pairwise distances). 5.1 \u010cech and Vietoris-Rips complexes Definition 5.1. Given a metric space (M,d), a finite point set P \u2286 M, and a real number radius r > 0, the \u010cech complex Cr(P) is defined as the nerve of the set of balls B(p,r) = {x \u2208 M | d(p,x) \u2a7d r} for all p \u2208 P. The \u010cech complex has the nice property that (at least for some metric spaces M including Euclidean space Rd) by the Nerve theorem, it is homotopy equivalent to the union of the balls B(p,r). In particular, for nice radii, it will capture the underlying shape. Sadly, checking whether a large number of balls have a common intersection can be computationally expensive. Further, the definition requires that the data points are embedded in a metric space. These two issues motivate the next definition. Definition 5.2. Given a finite metric space (P,d) and a real number radius r > 0, the Vietoris-Rips complex VR r(P) is defined as the simplicial complex containing a simplex \u03c3 if and only if d(p,q) \u2a7d 2r for every pair p,q \u2208 \u03c3. Clearly, for finite subsets of metric spaces, by definition, the \u010cech complex and the Vietoris-Rips complex for the same radius and the same point set have the same set of 1-simplices (the same 1-skeleton). While the \u010cech complex then contains additional information about the common intersections of balls, the Vietoris-Rips complex is simply the clique complex of this 1-skeleton. This makes the Vietoris-Rips complex easier to compute. Furthermore, we make the following simple observation, showing that the Vietoris-Rips complex still approximately captures shapes in the data: 56"}
{"node_id": "tdanotes:5.2", "pdf_id": "tdanotes", "section_id": "5.2", "chunk_id": "5.2-0", "text": "Introduction to TDA 5.2. Delaunay and Alpha complexes Observation 5.3. Cr(P) \u2286 VR r(P) \u2286 C2r(P). Exercise 5.4. Prove Observation 5.3. Exercise 5.5. Find a point set P \u2282 R2 and a radius r such that its Vietoris-Rips \u223c complex has non-trivial 2-homology, i.e., such that H (VR r(P)) \u0338= 0. 2 Furthermore, is there a dimension k such that H (VR r(Q)) = 0 for all k\u2032 \u2a7e k, all k\u2032 r > 0, and all point sets Q \u2282 R2? 5.2 Delaunay and Alpha complexes Recall that computing persistent homology takes O(N3) time, where N is the size of the simplicial complex in the filtration. For large enough radii, both the \u010cech and the Vietoris-Rips complex become complete, and thus contain 2n simplices. Computing persistent homology using those complexes is therefore computationally very expensive, which is why in many applications we would like to have sparser complexes. For data in Rd we can look at the so-called Delaunay triangulation, which only has complexity O(n\u2308d/2\u2309). Definition 5.6. Given a finite point set P \u2282 Rd, a Delaunay simplex is a geometric simplex whose vertices are in P and lie on the boundary of a ball whose interior contains no points of P. A Delaunay triangulation Del(P) of P is a geometric simplicial complex with the vertex set P where every simplex is a Delaunay simplex and whose underlying space covers the convex hull of P. Given a finite point set P \u2282 Rd, the extended Delaunay complex is the simplicial complex where for every face \u03c3, for d\u2032 \u2a7d d, every d\u2032-face of \u03c3 is a Delaunay simplex. It is a well-known fact that for a point set in general position (no d+2 points lie on a common sphere), there is a unique Delaunay triangulation. Furthermore, in this case the extended Delaunay complex and this unique Delaunay triangulation coincide. Definition 5.7. Given a finite point set P \u2282 Rd, the Voronoi diagram is the tessellation of Rd into the Voronoi cells V = {x \u2208 Rd | d(x,p) \u2a7d d(x,q)\u2200q \u2208 P} p for all p \u2208 P. Fact 5.8. The nerve of the Voronoi cells of P is the extended Delaunay complex of P. Exercise 5.9. Convince yourself that for a point set in R2, the nerve of the Voronoi diagram is the extended Delaunay complex. Furthermore, convince yourself that if the points are in general position (there are no three points that are collinear, and no four points that are cocircular), then there is a unique Delaunay triangulation. 57"}
{"node_id": "tdanotes:5.3", "pdf_id": "tdanotes", "section_id": "5.3", "chunk_id": "5.3-0", "text": "Chapter 5. Simplicial Complexes on Point Clouds Introduction to TDA BasedontheDelaunaytriangulation, wedefinetheAlpha complex byparameterizing using a radius as follows: Definition 5.10. Given a finite point set P \u2282 Rd in general position as well as a real number radius r > 0, the Alpha complex Delr(P) consists of all simplices \u03c3 \u2208 Del(P) for which the circumscribing ball of \u03c3 has radius at most r. The following fact provides us with an alternative definition of the Alpha complex: Fact 5.11. The Alpha complex Delr(P) is the nerve of the sets B(p,r) \u2229 V for all p p \u2208 P. Since the Alpha complex is a subset of the Delaunay triangulation (and for large enough radius is equal to the Delaunay triangulation), it also has complexity O(n\u2308d/2\u2309). Further, the above fact together with the Nerve theorem implies that the Alpha complex Delr(P) is homotopy equivalent to the \u010cech complex Cr(P). Exercise 5.12. Is the following true or false? Consider a point set P \u2282 R2 in gen- eral position and a radius r > 0. Then the Alpha complex (with radius r) is the intersection of the \u010cech complex (with radius r) with the Delaunay triangulation. 5.3 Subsample Complexes For many applications, the Alpha complex is still too large. It is further expensive to compute, as computing a Delaunay triangulation in Rd takes O(n\u2308d/2\u2309) time. Sparser complexes can be constructed by looking at subsamples of the data, and relating the rest of the data to these subsamples. In the following, we will discuss two examples of complexes based on this idea. Definition5.13. Given a finite point set Q and a point set P \u2283 Q in some metric space, we say that a simplex \u03c3 \u2286 Q is weakly witnessed by x \u2208 P \\ Q, if d(q,x) \u2a7d d(p,x) for every q \u2208 \u03c3 and p \u2208 Q\\\u03c3. Note that the set of weakly witnessed simplices is not downwards closed. We thus define a simplicial complex by requiring that all faces are weakly witnessed: Definition 5.14. The Witness complex W(Q,P) is the collection of simplices on Q for which every face is weakly witnessed by some point in P\\Q. Notethatifwetakethemetricspace Rd andweletP bethewhole Rd,then W(Q,P) = Del(Q), and by definition we thus get in general that W(Q,P) \u2286 Del(Q). To arrive at a filtration, we again have to introduce a parameter r > 0: Definition 5.15. Given a finite point set Q and a point set P \u2283 Q in some metric space as well as a real number radius r > 0, the parameterized Witness complex Wr(Q,P) is a simplicial complex on Q defined as follows: Every point p \u2208 Q defines a vertex in Wr(Q,P). Further, an edge pq is in Wr(Q,P) if it is weakly witnessed by x \u2208 P \\ Q and d(p,x) \u2a7d r and d(q,x) \u2a7d r. A simplex \u03c3 \u2286 Q is in Wr(Q,P) if all its edges are. 58 Introduction to TDA 5.3. Subsample Complexes Note that from this definition it is not guaranteed that the parameterized Witness complex is a subcomplex of the Witness complex. The idea of the parameterized Witness complex is that it should approximate the Vietoris-Rips complex on P. There are theoretical guarantees about this approximation for manifolds of dimension at most 2, but the parameterized witness complex may fail to capture the topology of manifolds in dimension 3 and above. Exercise 5.16. Show that W(Q,P) \u2286 W(Q,P\u2032) for P \u2286 P\u2032. On the other hand, give an example of point sets Q \u2286 Q\u2032 and P for which W(Q,P) \u0338\u2286 W(Q\u2032,P). Let us now consider a second"}
{"node_id": "tdanotes:5.3", "pdf_id": "tdanotes", "section_id": "5.3", "chunk_id": "5.3-1", "text": "of dimension at most 2, but the parameterized witness complex may fail to capture the topology of manifolds in dimension 3 and above. Exercise 5.16. Show that W(Q,P) \u2286 W(Q,P\u2032) for P \u2286 P\u2032. On the other hand, give an example of point sets Q \u2286 Q\u2032 and P for which W(Q,P) \u0338\u2286 W(Q\u2032,P). Let us now consider a second subsample complex, the graph induced complex. Definition 5.17. Given two finite point sets Q,P in Rd, as well as a graph G(P) with vertices in P, we define v : P \u2192 Q by sending each point in P to its closest point in Q. The graph induced complex G(Q,G(P)) contains a simplex \u03c3 = {q ,...,q } \u2282 Q 0 k if and only if there is a clique {p ,...,p } in G(P) for which v(p ) = q . 0 k i i We again parameterize this: Definition5.18. Let Gr(P) be the graph on P where pq is an edge if and only if d(p,q) \u2a7d 2r. The parameterized graph induced complex Gr(Q,P) is defined as G(Q,Gr(P)). This complex again has theoretical guarantees of approximating the Vietoris-Rips complex on P\u222aQ. Exercise 5.19. Let P,Q be point sets and G(P) a graph with P as its vertex set. Let v : P \u2192 Q be the map sending each point of P to its closest point of Q (assume that this closest point is always unique). Let C be the clique complex of G(P) (the complex which includes a simplex iff its corresponding vertices in G(P) form a clique). Show that v extends to a simplicial map \u00afv : C \u2192 G(Q,G(P)). Also show that any simplicial complex K with V(K) = Q for which v has a simplicial extension must contain G(Q,G(P)). Questions 16. What are the \u010cech and Vietoris-Rips complexes? Give the definitions, discuss their size and theoretical guarantees, and how they are related. 17. What are the Delaunay and Alpha complexes? Give the definitions, discuss their size and theoretical guarantees, and how they are related. 18. What is the Witness complex? State the Definition and describe how it relates to the non-sparse complexes. 19. What is the Graph induced complex? State the Definition and describe how it relates to the non-sparse complexes. 59"}
{"node_id": "tdanotes:6.1.1", "pdf_id": "tdanotes", "section_id": "6.1.1", "chunk_id": "6.1.1-0", "text": "Chapter 6 Distances and Stability 6.1 Distance Metrics on Persistence Diagrams As we have seen in the previous sections, persistent homology of simplicial filtrations, for example in the form of persistence diagrams or persistence barcodes, can give us a lot of insight into a given point cloud. However, so far we have always been analyzing this information manually. In this section we will show how this can be done on a more mathematical level, by defining some distance metrics that can be used to compare different persistence diagrams, and thus to assess the similarity of point clouds. 6.1.1 Bottleneck Distance Let F,G be two filtrations giving rise to persistence modules H (F),H (G), and let p p Dgm (F) and Dgm (G) be their corresponding persistence diagrams. How can we now p p compare these two filtrations F and G by using only the information stored in these diagrams? The general idea of the bottleneck distance is to find a matching between the points of the two persistence diagrams, i.e., we consider bijections between the points of Dgm (F) p and those of Dgm (G). Since we can only find bijections between sets of the same p cardinality, we need the two diagrams to have the same number of points. Recall that the way we defined it, a persistence diagram includes every possible point on the diagonal with infinite multiplicity. This peculiar definition now finally pays off; since both sets of points have the same (infinite) cardinality, and bijections between these sets are thus well-defined. We do not want to consider any arbitrary bijection, but only the best possible. To measure the \u201cquality\u201d or \u201cdistance\u201d of such a bijection, we use the L -norm: \u221e Definition 6.1. Let x = (x ,x ),y = (y ,y ) be two points in R2. Then, 1 2 1 2 ||x\u2212y|| := max(|x \u2212y |,|x \u2212y |), \u221e 1 1 2 2 where we say that \u221e\u2212\u221e = 0 for points with coordinates that are \u221e (i.e., points in persistence diagrams that correspond to holes that did not die). 60 Introduction to TDA 6.1. Distance Metrics on Persistence Diagrams Definition 6.2. Let \u03a0 = {\u03c0 : Dgm (F) \u2192 Dgm (G) | \u03c0 is bijective} be the set of all p p bijections between Dgm (F) and Dgm (G). Then, the Bottleneck distance is defined p p as d (Dgm (F),Dgm (G)) := inf sup ||x\u2212\u03c0(x)|| . b p p \u221e \u03c0\u2208\u03a0x\u2208Dgmp(F) The Bottleneck distance thus minimizes the maximum L -norm of any pairing, over \u221e all pairings of points. Figure 6.1: An illustration of the idea of bottleneck distance. Observation 6.3. The Bottleneck distance is a metric on the space of persistence dia- grams with finitely many off-diagonal points. Proof. We check the three properties of metrics: 1. d (X,Y) = 0 if and only if X = Y: This is simple to see, since if X = Y, every point b can be matched to its copy, and if X \u0338= Y, there exists some point p \u2208 X\\Y\u222aY\\X which must be matched to some point with positive L -distance to p. \u221e 2. d (X,Y) = d (Y,X): This is clear by definition. b b 3. d (X,Y) \u2a7d d (X,Z) + d (Z,Y): Take a bijection \u03c0 witnessing1 d (X,Z) and b b b 1 b a bijection \u03c0 witnessing d (Z,Y), and concatenate the two: \u03c0 := \u03c0 \u25e6 \u03c0 is a 2 b 2 1 bijection X \u2192 Y where for every x \u2208 X we can use the triangle equality of ||\u00b7|| to \u221e bound ||x\u2212\u03c0(x)||"}
{"node_id": "tdanotes:6.1.1", "pdf_id": "tdanotes", "section_id": "6.1.1", "chunk_id": "6.1.1-1", "text": "(X,Z) + d (Z,Y): Take a bijection \u03c0 witnessing1 d (X,Z) and b b b 1 b a bijection \u03c0 witnessing d (Z,Y), and concatenate the two: \u03c0 := \u03c0 \u25e6 \u03c0 is a 2 b 2 1 bijection X \u2192 Y where for every x \u2208 X we can use the triangle equality of ||\u00b7|| to \u221e bound ||x\u2212\u03c0(x)|| \u2a7d ||x\u2212\u03c0 (x)|| +||\u03c0 (x)\u2212\u03c0 (\u03c0 (x))|| . \u221e 1 \u221e 1 2 1 \u221e 1Note that since d is an infimum and not a minimum, there may not be \u03c0 and \u03c0 witnessing d . In b 1 2 b this case, the same argument can be applied to the converging sequences of bijections witnessing d . b 61 Chapter 6. Distances and Stability Introduction to TDA Exercise 6.4. Give an algorithm to compute the Bottleneck distance between two per- sistence diagrams. Your algorithm should be polynomial in n, where n is the total number of off-diagonal points in the two persistence diagrams. Exercise 6.5. Let D ,...,D be k persistence diagrams. Assume that for any two of 1 k them we have d (D ,D ) \u2a7d 2. Prove or disprove: there exists a persistence diagram b i j D such that d (D ,D ) \u2a7d 1 for all i \u2208 {1,...,k}. 0 b 0 i TheBottleneckdistancecanbeusedtocompareany twofiltrations, ofpossiblywildly different spaces. What if we consider two filtrations of the same simplicial complex? Recall that simplex-wise monotone functions f,g : K \u2192 R give rise to simplicial sublevel set filtrations F ,F . While these two filtrations can be compared using the Bottleneck f g distance, we can also define a metric that directly compares the two functions f,g: Definition 6.6 (infinity norm). Let f,g : X \u2192 R. Then, the infinity norm of f \u2212 g is defined as ||f\u2212g|| := sup|f(x)\u2212g(x)|. \u221e x\u2208X The following theorem tells us that this infinity norm and the Bottleneck distance are closely related: Theorem 6.7 (Stability for simplicial filtrations). Let f,g : K \u2192 R be simplex-wise mono- tone functions. Then, \u2200p \u2a7e 0 we have d (Dgm (F ),Dgm (F )) \u2a7d ||f\u2212g|| . b p f p g \u221e Proof. We consider the linear interpolation f := (1 \u2212 t)f + tg for t \u2208 [0,1] between f t and g. Note that f = f,f = g. 0 1 We first show that each f is a simplex-wise monotone function: Let \u03c3 \u2286 \u03c4. Since f t and g are monotone, we have f(\u03c3) \u2a7d f(\u03c4) and g(\u03c3) \u2a7d g(\u03c4). Thus, f (\u03c3) = (1\u2212t)f(\u03c3)+tg(\u03c3) \u2a7d (1\u2212t)f(\u03c4)+tg(\u03c4) = f (\u03c4). t t Let p \u2a7e 0 be fixed. We now draw the family of persistence diagrams Dgm (F ) p ft as a multiset in R2 \u00d7[0,1]. Each off-diagonal point of X := Dgm (F ) is of the form t p ft x(t) = (f (\u03c3),f (\u03c4),t) for \u03c3 being the creator and \u03c4 being the destructor. Note that the t t persistence pairings (\u03c3,\u03c4) may only change when the order of simplex insertion changes, which only happens finitely many times when going from t = 0 to t = 1. Let us call these values 0 = t < t < t < ... < t < t = 1. For simplicity, we assume that at 0 1 2 n n+1 each of these values t exactly two simplices have the same value f . i t i Within each open interval (t ,t ) the pairings stay constant. Furthermore, every i i+1 off-diagonal point x(t) is a linear function of t in all three"}
{"node_id": "tdanotes:6.1.1", "pdf_id": "tdanotes", "section_id": "6.1.1", "chunk_id": "6.1.1-2", "text": "t < t = 1. For simplicity, we assume that at 0 1 2 n n+1 each of these values t exactly two simplices have the same value f . i t i Within each open interval (t ,t ) the pairings stay constant. Furthermore, every i i+1 off-diagonal point x(t) is a linear function of t in all three coordinates, meaning that it defines a line segment. Let us first assume that at some value t , x(t ) is an off-diagonal point whose i+1 i+1 creator and destructor are still paired after t . In this case, x(t) continues in the same i+1 direction after t . i+1 62 Introduction to TDA 6.1. Distance Metrics on Persistence Diagrams If on the other hand x(t ) is an off-diagonal point whose creator and destructor i+1 get paired differently, recalling Exercise 4.4, there are exactly two pairs that swap their creators or destructors, and these creators or destructors that are swapped must have the same value in f . In the persistence diagram, this means that two points vertically t i+1 or horizontally of each other swap creators/destructors. However, this just means that for both of these line segments going into t , there is a unique continuing line segment. i+1 Note that for t = 0 or t = 1 we can also have that x(t) lies on the diagonal. This means that its past/future creator and destructor have the same value in f . t Every point thus moves along a polygonal path monotone in t. Every such path is called a vine, and the multiset of all vines is called a vineyard, see Figure 6.2 for an illustration. Based on this vineyard, we now wish to find a good matching giving an upper bound on the Bottleneck distance. We simply take the matching where we match the start point of every vine with its endpoint. To get a bound on the Bottleneck distance, we simply need to get a bound for the distance of each matched pair. h at e d birth emit t i+1 Figure 6.2: The vineyards in the proof of Theorem 6.7. Between any t and t , a point x(t) moves at the rate \u03b4x(t), which we can compute i i+1 \u03b4t to be \u03b4 (cid:0) (cid:1) (1\u2212t)\u00b7(f(\u03c3),f(\u03c4),t) +t\u00b7(g(\u03c3),g(\u03c4),t)) = (g(\u03c3)\u2212f(\u03c3),g(\u03c4)\u2212f(\u03c4),1). \u03b4t Projecting x(t ) and x(t ) to R2 we thus get two points y ,y for which we can see i+1 i i+1 i 63"}
{"node_id": "tdanotes:6.1.2", "pdf_id": "tdanotes", "section_id": "6.1.2", "chunk_id": "6.1.2-0", "text": "Chapter 6. Distances and Stability Introduction to TDA that ||y \u2212y || = (t \u2212t )\u00b7max(cid:0)|g(\u03c3)\u2212f(\u03c3)|,|g(\u03c4)\u2212f(\u03c4)|(cid:1) \u2a7d (t \u2212t )\u00b7||f\u2212g|| . i+1 i \u221e i+1 i i+1 i \u221e Thus, since ||\u00b7|| is a norm and fulfills the triangle inequality, we also have that from \u221e t = 0 to t = 1, the point can move at most ||f\u2212g|| . We thus have the desired bound \u221e on the Bottleneck distance. Exercise 6.8. Show that Theorem 6.7 above can be tight for all p \u2a7e 0 and all values of ||f\u2212g|| . \u221e Exercise 6.9. Let P and Q be subsets of a metric space. We say that P \u222aQ is in \u03b4- separated position if for any p \u2208 P and q ,q \u2208 Q we have that |d(p,q )\u2212d(p,q )| > 1 2 1 2 \u03b4. Assume that P \u222aQ is in \u03b4-separated position and let Q\u2032 be an \u03b5-perturbation of Q, that is, there is a bijection between Q and Q\u2032 such that for every original point q \u2208 Q and its image q\u2032 \u2208 Q\u2032 we have d(q,q\u2032) \u2a7d \u03b5. Let D and D\u2032 be the persistence p p diagrams for the p-dimensional persistent homology of the filtration induced by the parameterized witness complexes Wr(Q,P) and Wr(Q\u2032,P), respectively. Show that if \u03b5 < \u03b4/2 then d (D ,D\u2032) \u2a7d \u03b5. b p p Further, show an example where this fails for \u03b5 > \u03b4/2. Wewishtogeneralizethestabilityresultabovefromsimplicialfiltrationstofiltrations of general topological spaces. To this end we consider some topological space X and a function f : X \u2192 R , which induces a sublevel set filtration for every r \u2208 R . We only want to consider tame functions: A function f is tame if all homology groups of sublevel sets have finite dimension, and the homology groups only change at finitely many values, called critical values. Theorem 6.10. Let X be a triangulable topological space, and f,g : X \u2192 R be two tame functions. Then \u2200p \u2a7e 0, we have d (Dgm (F ),Dgm (F )) \u2a7d ||f\u2212g|| . b p f p g \u221e We do not prove this theorem at this point, but with additional tools that we will develop in Section 6.2, the proof of this (and of Theorem 6.7) will follow quite easily. 6.1.2 Wasserstein Distance Consider the following three diagrams: Which of Y and Y is X closer to? Intuitively, one clearly says Y : There are simply 1 2 1 fewer features in Y that are not present in X. In terms of Bottleneck distance, there is 1 only one reasonable matching between X and Y , and also only one between X and Y : 1 2 We simply match each off-diagonal point with its closest point on the diagonal. Since 64 Introduction to TDA 6.1. Distance Metrics on Persistence Diagrams X Y Y 1 2 we only look at the longest edge in this matching, the Bottleneck distance is actually the same for both pairs of diagrams, i.e., d (X,Y ) = d (X,Y ). b 1 b 2 We can get rid of this counter-intuitive behavior of the Bottleneck distance by using the Wasserstein distance. Definition 6.11 (Wasserstein distance). For p \u2a7e 0, and q \u2a7e 1, the q-Wasserstein dis- tance is defined as (cid:34) (cid:88) (cid:35)1/q (cid:16) (cid:17) d (Dgm (F),Dgm (G)) := inf (||x\u2212\u03c0(x)|| )q W,q p p \u221e \u03c0\u2208\u03a0 x\u2208Dgmp(F) Intuitively, we now consider the length of all edges in the matching induced by the bijection, as opposed to just the longest one, but the longer ones get more weight. Note that for q"}
{"node_id": "tdanotes:6.1.2", "pdf_id": "tdanotes", "section_id": "6.1.2", "chunk_id": "6.1.2-1", "text": "the q-Wasserstein dis- tance is defined as (cid:34) (cid:88) (cid:35)1/q (cid:16) (cid:17) d (Dgm (F),Dgm (G)) := inf (||x\u2212\u03c0(x)|| )q W,q p p \u221e \u03c0\u2208\u03a0 x\u2208Dgmp(F) Intuitively, we now consider the length of all edges in the matching induced by the bijection, as opposed to just the longest one, but the longer ones get more weight. Note that for q = \u221e, we retrieve the bottleneck distance, that is, d = d . W,\u221e b We can see that the stability theorem we proved for Bottleneck distance does not hold for Wasserstein distance: consider two simplex-wise monotone functions f and g on a path, as illustrated in Figure 6.3. In both f and g the first vertex on the path is mapped to 1 and the edges along the path are mapped to increasing odd numbers. In f the remaining vertices along the path get mapped to increasing even numbers, and in g to increasing odd numbers. In particular, ||f \u2212 g|| = 1. In the filtration defined by \u221e f, at every even step we add a vertex, creating a new connected component, which gets connected to the rest of the path at the next step. Thus, each vertex of the path will give an off-diagonal point in the 0-persistence diagram, where all of them except the first one have a lifespan of 1. On the other hand, in the filtration defined by g, we always add the new vertices and their connecting edge in the same step, thus the 0-persistence diagram only has a single off-diagonal point with infinite lifespan. In particular, we have that for arbitrarily long paths we get arbitrarily large Wasserstein distances between the diagrams for all q < \u221e. A similar counterexample can also be found for topological spaces. Consider the topological space [0,1] and the two functions depicted by the curves in Figure 6.4. Here we again have that ||f\u2212g|| \u2a7d \u03f5, but the Wasserstein distance between the two diagrams \u221e can be made arbitrarily big. 65 Chapter 6. Distances and Stability Introduction to TDA 0 1 3 5 0 1 3 5 \u00b7\u00b7\u00b7 \u00b7\u00b7\u00b7 2 4 6 1 3 5 Figure 6.3: Two simplex-wise monotone functions with bounded infinity norm whose persistence diagrams have unbounded Wasserstein distance. To avoid these types of counterexamples, we want to consider even nicer functions: Definition 6.12 (Lipschitz). Let (X,d) be a metric space. A function f : X \u2192 R is Lipschitz if there exists a constant C such that |f(x) \u2212 f(y)| \u2a7d c \u00b7 d(x,y) for all x,y \u2208 X. Exercise 6.13. For each \u2113 \u2208 R, give two continuous functions f,g : [0,1] \u2192 R such that \u2225f \u2212 g\u2225 \u2a7d 1, but the Wasserstein distance between the diagrams of the sublevel \u221e set filtrations of f,g is at least \u2113. What happens to the Lipschitz constant of your functions as \u2113 \u2192 \u221e? For Lipschitz-functions we again get stability theorems, however we will not prove these here. Theorem6.14. Let X be a triangulable, compact metric space. Let f,g : X \u2192 R be tame Lipschitz functions. Then there exist constants C and k (that may only depend on X and on the Lipschitz constants of f,g) such that for every p \u2a7e 0 and every q \u2a7e k, d (Dgm (F ),Dgm (F )) \u2a7d C\u00b7||f\u2212g||1\u2212k/q. W,q p f p g \u221e Theorem 6.15. Let f,g : K \u2192 R be simplex-wise monotone functions. Then for all p \u2a7e 0 and all q \u2a7e 1, (cid:88) (cid:16) (cid:17)1/q d (Dgm (F ),Dgm (F )) \u2a7d ||f\u2212g|| = |f(\u03c3)\u2212g(\u03c3)|q . W,q p f"}
{"node_id": "tdanotes:6.1.2", "pdf_id": "tdanotes", "section_id": "6.1.2", "chunk_id": "6.1.2-2", "text": "0 and every q \u2a7e k, d (Dgm (F ),Dgm (F )) \u2a7d C\u00b7||f\u2212g||1\u2212k/q. W,q p f p g \u221e Theorem 6.15. Let f,g : K \u2192 R be simplex-wise monotone functions. Then for all p \u2a7e 0 and all q \u2a7e 1, (cid:88) (cid:16) (cid:17)1/q d (Dgm (F ),Dgm (F )) \u2a7d ||f\u2212g|| = |f(\u03c3)\u2212g(\u03c3)|q . W,q p f p g q \u03c3\u2208K 66"}
{"node_id": "tdanotes:6.2.1", "pdf_id": "tdanotes", "section_id": "6.2.1", "chunk_id": "6.2.1-0", "text": "Introduction to TDA 6.2. Interleaving of Persistence Modules X = [0,1] f : g : Figure 6.4: Two functions [0,1] \u2192 R with bounded infinity norm whose persistence diagrams have unbounded Wasserstein distance. 6.2 Interleaving of Persistence Modules 6.2.1 Interleaving Distance Until now, we only compared persistence diagrams. We will now introduce the interleav- ing distance, which instead compares persistence modules directly. Let us begin with a formal definition of persistence modules. Definition 6.16. A persistence module V over R is a collection V = {V a } a\u2208R of vector spaces V together with linear maps v : V \u2192 V for a \u2a7d a\u2032, such that v = id a a,a\u2032 a a\u2032 a,a and v \u25e6v = v for all a \u2a7d b \u2a7d c. b,c a,b a,c You already know a few examples of persistence modules, e.g., the persistent homol- ogy of sublevel set filtrations or of \u010cech or Vietoris-Rips complexes (here one simply defines V = 0 for a < 0). a To be able to define distances between persistence modules, we first need to figure out when we want to call two persistence modules \u201cthe same\u201d, or more formally speaking, we want to define a notion of isomorphism. Definition 6.17. We say that two persistence modules U and V are isomorphic if there are isomorphisms f : U \u2192 V for all a \u2208 R such that a a a U u a,a\u2032 U a a\u2032 fa f a\u2032 V v a,a\u2032 V a a\u2032 67 Chapter 6. Distances and Stability Introduction to TDA commutes both ways, i.e., f \u25e6u = v \u25e6f , and u \u25e6f\u22121 = f\u22121 \u25e6v . a\u2032 a,a\u2032 a,a\u2032 a a,a\u2032 a a\u2032 a,a\u2032 The basic idea of interleaving distance is to measure how close two persistence mod- ules are to being isomorphic. For this, we allow ourselves some slack, in the sense that U does not need to map to V , but it can instead map to V , as long as all the a a a+\u03f5 relevant maps still behave like they would for an isomorphism. We make this formal in the next definition. Definition6.18(\u03f5-interleavingpersistencemodules). Let U and V be persistence modules over R and let \u03f5 \u2a7e 0. We say that U and V are \u03f5-interleaved if there exist two families of linear maps, \u03c6 : U \u2192 V and \u03c8 : V \u2192 U such that the a a a+\u03f5 a a a+\u03f5 following four diagrams are commutative: U u a,a\u2032 U U u a+\u03f5,a\u2032+\u03f5 U a a\u2032 a+\u03f5 a\u2032+\u03f5 \u03c6a \u03c6 a\u2032 and \u03c8a \u03c8 a\u2032 V v a+\u03f5,a\u2032+\u03f5 V V v a,a\u2032 V a+\u03f5 a\u2032+\u03f5 a a\u2032 u U a,a+2\u03f5 U U a a+2\u03f5 a+\u03f5 \u03c6a \u03c8a+\u03f5 and \u03c8a \u03c6a+\u03f5 v V V a,a+2\u03f5 V a+\u03f5 a a+2\u03f5 Note that if U and V are isomorphic, then they are 0-interleaved: the first type of diagrams (the square diagrams) are the commutative diagrams in the definition of isomorphic persistence modules and the the second type of diagrams (the triangular diagrams) collapse to two arrows that say that the maps \u03c6 are isomorphisms with a inverses \u03c8 . a Theorem 6.19. Assume U and V are \u03f5-interleaved. Let \u03b4 > \u03f5. Then U and V are also \u03b4-interleaved. Proof. Given \u03c6\u2032 : U \u2192 V we define \u03c6 : U \u2192 V simply as \u03c6 := v \u25e6\u03c6\u2032. a a a+\u03f5 a a a+\u03b4 a a+\u03f5,a+\u03b4 a Symmetrically, we define \u03c8 := u \u25e6 \u03c8\u2032. To check that the correct diagrams a a+\u03f5,a+\u03b4 a commute, we only check the right diagram of every pair"}
{"node_id": "tdanotes:6.2.1", "pdf_id": "tdanotes", "section_id": "6.2.1", "chunk_id": "6.2.1-1", "text": "V are also \u03b4-interleaved. Proof. Given \u03c6\u2032 : U \u2192 V we define \u03c6 : U \u2192 V simply as \u03c6 := v \u25e6\u03c6\u2032. a a a+\u03f5 a a a+\u03b4 a a+\u03f5,a+\u03b4 a Symmetrically, we define \u03c8 := u \u25e6 \u03c8\u2032. To check that the correct diagrams a a+\u03f5,a+\u03b4 a commute, we only check the right diagram of every pair of symmetric diagrams shown above. We have to distinguish two cases for the first diagram, a + \u03b4 < a\u2032 + \u03f5 and a+\u03b4 > a\u2032 +\u03f5. For the first case, we get the following diagram: U U a a\u2032 V V V V a+\u03f5 a+\u03b4 a\u2032+\u03f5 a\u2032+\u03b4 68 Introduction to TDA 6.2. Interleaving of Persistence Modules For the second case we get the diagram: U U a a\u2032 V V V V a+\u03f5 a\u2032+\u03f5 a+\u03b4 a\u2032+\u03b4 And finally, for the triangular diagram we get: U U U U a a+2\u03f5 a+\u03b4+\u03f5 a+2\u03b4 V V a+\u03f5 a+\u03b4 One can now verify that in all of these diagrams the correct paths commute. Thus, the following definition makes sense: Definition 6.20 (Interleaving distance). d (U,V) := inf{\u03f5 | U and V are \u03f5-interleaved }. I Exercise6.21. Show that interleaving distance is a pseudo-metric for persistence mod- ules (up to isomorphism), i.e., prove that (i) the interleaving distance between iso- morphic persistence modules is 0, (ii) the interleaving distance is non-negative, and (iii) the interleaving distance fulfills the triangle inequality. Also show that it is not a metric by showing that there exist non-isomorphic persistence modules with interleaving distance 0. Exercise 6.22. Let W and W be two arbitrary vector spaces. Let U be the persistence 1 2 module such that U = W for a \u2208 [w,x), and U = 0, otherwise. For a,a\u2032 \u2208 [w,x) a 1 a we have u being the identity map. For a < w or a\u2032 \u2a7e x (or both), we have u a,a\u2032 a,a\u2032 being the zero map. Similarly, we define the persistence module V which is W in 2 a \u2208 [y,z) and 0 otherwise. Show that d (U,V) \u2a7d max(w\u2212x, z\u2212y). I 2 2 The underlying ideas that allowed us to define the interleaving distance of persistence modules can also be applied to filtrations. Definition 6.23 (Interleaving for Filtrations). Let F,G be filtrations over R. F and G are \u03f5-interleaved if there exist maps \u03c6 : F \u2192 G and \u03c8 : G \u2192 F such a a a+\u03f5 a a a+\u03f5 that the same type of diagrams commute up to homotopy, that is, for example \u03c6 \u25e6\u03b9F \u2243 \u03b9G \u25e6\u03c6 are homotopic (contiguous). a\u2032 a,a\u2032 a+\u03f5,a\u2032+\u03f5 a We again define the interleaving distance (now between filtrations): d (F,G) = inf{\u03f5 | F and G are \u03f5-interleaved }. I From induced homology, we immediately get the following observation: 69"}
{"node_id": "tdanotes:6.2.2", "pdf_id": "tdanotes", "section_id": "6.2.2", "chunk_id": "6.2.2-0", "text": "Chapter 6. Distances and Stability Introduction to TDA Observation 6.24. For all p \u2a7e 0, d (H F,H G) \u2a7d d (F,G). I p p I As a first application of interleaving distance, we can quantify how different the \u010cech and Vietoris-Rips filtrations are. Recall that for a point cloud P and a radius r, we have the relationship between the \u010cech and Vietoris-Rips complexes as follows: Cr(P) \u2286 VR r(P) \u2286 C2r(P). Since this factor 2 is multiplicative, and we need an additive \u03f5 for interleaving, let us just take the logarithmic scale (base 2) for the radius, i.e., we define Cr = C2r and similarly VR r = VR 2r. Since 2(r+1) = 2\u00b72r, we have Cr (P) \u2286 log log log VR r (P) \u2286 Cr+1(P). log log We thus have the following inclusions: Cr Cr+1 Cr+2 log log log r r+1 r+2 VR VR VR log log log Since these are all inclusions, all relevant diagrams must commute, and thus we get that d (C ,VR ) \u2a7d 1. I log log 6.2.2 Stability with Respect to Interleaving Distance The main motivation for interleaving distance is that it can be used to prove stability results, at least under some tameness conditions. Definition 6.25. A persistence module V is q-tame if the linear maps have finite di- mension. Note that in this definition, the q is not a parameter, just a name. All persistence modules that show up in the context of persistent homology on point clouds are q-tame, so this condition is not restrictive. Theorem 6.26. If U,V are q-tame persistence modules over R, then d (DgmU,DgmV) = d (U,V). b I Thus, for every interleaving one can find between two persistence modules or between filtrations, one immediately gets an upper bound on the Bottleneck distance. This is a very powerful result, and the proof of it is out of scope for these lecture notes. One direction of the proof however follows from a decomposition result of persistence modules that we will discuss in Section 6.3. But first, we will consider some examples of how Theorem 6.26 can be used to prove stability theorems. Exercise 6.27. Prove Theorem 6.10. 70"}
{"node_id": "tdanotes:6.2.3", "pdf_id": "tdanotes", "section_id": "6.2.3", "chunk_id": "6.2.3-0", "text": "Introduction to TDA 6.2. Interleaving of Persistence Modules 6.2.3 Stability for \u010cech Complexes So far, we have only seen stability results comparing filtrations induced by different func- tions on a fixed space. However, in applications in data analysis, we consider complexes on point clouds, and two different point clouds might not have the same size. Thus, the simplicial complexes on which we get filtrations are generally different. Using interleav- ing distance, we can however still give stability results. In this section, we will do this for \u010cech complexes. Consider two point clouds P,Q in the same metric space X. Let us first consider the really simple case, where P = {p}, and Q = {q} with d(p,q) = d. Then, B(p,r) \u2286 B(q,r+d). Now, how does this generalize to larger point sets? To get the same kind of behavior, we need that for every point in P, there exists some point in Q with distance at most d. This motivates the following distance measure: Definition 6.28 (Hausdorff distance). Let A,B \u2286 X be compact sets. Then the Hausdorff distance between A and B is defined as d (A,B) := max{maxd(a,B),maxd(b,A)}. H a\u2208A b\u2208B Exercise 6.29. Show that Hausdorff distance is a metric. We can now see that if d (P,Q) = d, then (cid:83) B(p,r) \u2286 (cid:83) B(q,r+d). From H p\u2208P q\u2208Q this, we get the following lemma: Lemma6.30. For P,Q with d (P,Q) = d, the (filtrations given by) the \u010cech complexes H of P and Q are d-interleaved. Proof. Consider the following diagram: Cr(P) Cr+d(P) Cr+2d(P) \u2243 \u2243 \u2243 (cid:83) (cid:83) (cid:83) B(p,r) B(p,r+d) B(p,r+2d) p\u2208P p\u2208P p\u2208P (cid:83) (cid:83) (cid:83) B(q,r) B(q,r+d) B(q,r+2d) q\u2208Q q\u2208Q q\u2208Q \u2243 \u2243 \u2243 Cr(Q) Cr+d(Q) Cr+2d(Q) The relevant sub-diagrams commute up to homotopy, since we only chain together ho- motopies and inclusion maps. Note that for the trapezoidal diagrams we would need to consider the horizontal inclusions between the \u010cech complexes in the diagram above for arbitrary distances and not just d. 71"}
{"node_id": "tdanotes:6.3", "pdf_id": "tdanotes", "section_id": "6.3", "chunk_id": "6.3-0", "text": "Chapter 6. Distances and Stability Introduction to TDA We can conclude the following Theorem 6.31. d (Dgm (C(P)),Dgm (C(Q))) \u2a7d d (P,Q) for all p \u2a7e 0. b p p H Proof. By Theorem 6.26, Observation 6.24, and finally Lemma 6.30, we have d (...) = d (H C(P),H C(Q)) \u2a7d d (C(P),C(Q)) \u2a7d d (P,Q). b I p p I H 6.3 Interval Decomposition of Persistence Modules In this section, we again look at persistence modules, this time as algebraic structures. We consider persistence modules over of vector spaces over some field . We start by R F looking at some special persistence modules, called interval modules. Definition 6.32. An interval module I[b,d] is a persistence module (cid:14) (cid:14) F if a \u2208 [b,d], id b \u2a7d a \u2a7d a\u2032 \u2a7d d, V = and v = a a,a\u2032 0 otherwise. 0 otherwise. Similarly, we can define interval modules on open and clopen intervals, denoted by I(b,d), I(b,d], and I[b,d). We write I\u27e8b,d\u27e9 to include all four of these types. Foranintervalmodulewecaneasilytalkaboutbirthanddeathaswedidinpersistent homology. If we have a persistent homology module that is (isomorphic to) an interval module, the birth and death correspond to the boundaries b,d of the interval. Definition 6.33. A persistence module U is called pointwise finite dimensional (p.f.d.) if for all a \u2208 R, U has finite dimension. a Note that all p.f.d. persistence modules are also q-tame. Definition 6.34. Given two persistence modules U,V, we define their direct sum U\u2295V by (U\u2295V) = U \u2295V and (u\u2295v) = u \u2295v . a a a a,a\u2032 a,a\u2032 a,a\u2032 Here, the direct sum of maps just means applying the respective maps component- wise. Proposition6.35. If U ,U are \u03f5-interleaved, and V ,V are \u03b4-interleaved, then U \u2295V 1 2 1 2 1 1 and U \u2295V are max{\u03f5,\u03b4}-interleaved. 2 2 Proof. Without loss of generality, let \u03f5 \u2a7e \u03b4, so we need to show that they are \u03f5- interleaved. Recall that if two persistence modules are \u03b4-interleaved, they are also \u03f5- interleaved. Let \u03c6u,\u03c8u be (series of) functions showing that U ,U are \u03f5-interleaved. 1 2 Similarly, let \u03c6v,\u03c8v be (series of) functions showing that V ,V are \u03f5-interleaved. Then, 1 2 \u03c6u \u2295\u03c6v,\u03c8u \u2295\u03c8v show that U \u2295V and U \u2295V are \u03f5-interleaved. 1 1 2 2 72 Introduction to TDA 6.3. Interval Decomposition of Persistence Modules If we now have a direct sum of interval modules, we can still nicely talk about births and deaths: we just consider each interval module in isolation. The following theorem shows that surprisingly most persistence modules can be expressed as direct sums of interval modules. Theorem6.36(Structure theorem). Any p.f.d. persistence module decomposes uniquely into interval modules, i.e., we have \u223c (cid:77) U = I\u27e8b ,d \u27e9. i i i\u2208I The intervals \u27e8b ,d \u27e9 are exactly the barcodes if U is a persistent homology module. i i Note that unless we have some additional tame-ness condition on U , I is not guaran- teed to be finite. Recall that when we talked about persistent homology, we said that there is some consistent global choice of basis for persistent homology groups. That is a consequence of the structure theorem. The structure theorem also allows us to prove one direction of Theorem 6.26, which we will do in the following. Proposition 6.37. Consider two interval modules I = I\u27e8b ,d \u27e9 and I = I\u27e8b ,d \u27e9. 1 1 1 2 2 2 Then, d (I ,I ) = d (DgmI ,DgmI ). I 1 2 b 1 2 Proof. To prove that d (I ,I ) \u2a7e d (DgmI ,DgmI ),"}
{"node_id": "tdanotes:6.3", "pdf_id": "tdanotes", "section_id": "6.3", "chunk_id": "6.3-1", "text": "6.26, which we will do in the following. Proposition 6.37. Consider two interval modules I = I\u27e8b ,d \u27e9 and I = I\u27e8b ,d \u27e9. 1 1 1 2 2 2 Then, d (I ,I ) = d (DgmI ,DgmI ). I 1 2 b 1 2 Proof. To prove that d (I ,I ) \u2a7e d (DgmI ,DgmI ), we show that every upper bound I 1 2 b 1 2 ond isalsoanupperboundond : assumethatwehavemaps\u03c6,\u03c8showingthatthetwo I b modules are \u03f5-interleaved. Then, consider \u03c8 \u25e6\u03c6 = v1 , equality holding because a+\u03f5 a a,a+2\u03f5 \u03c6,\u03c8 certify \u03f5-interleaving and the triangular diagram commutes. Consider a \u2208 \u27e8b ,d \u27e9. 1 1 Case 1: v1 = 0 for all a \u2208 \u27e8b ,d \u27e9. Then, d \u2212b < 2\u03f5, and the (infinity-norm) a,a+2\u03f5 1 1 1 1 distance of (b ,d ) to the diagonal is less than \u03f5. If this case would also hold for v2 1 1 we would be done, since for both DgmI and DgmI we could match the point to the 1 2 diagonal. Case 2: v1 = id for some a \u2208 \u27e8b ,d \u27e9. Then, d \u2212b \u2a7e 2\u03f5. Furthermore, we have a,a+2\u03f5 1 1 1 1 \u03c6 (F) = F for all a \u2208 \u27e8b ,d \u22122\u03f5\u27e9. So, for these a, we must also have a+\u03f5 \u2208 \u27e8b ,d \u27e9. a 1 1 2 2 Thistellsusthat\u27e8b ,d \u27e9must\u201ccover\u201d alargepartof\u27e8b ,d \u27e9, namelywegetb \u2a7d b +\u03f5, 2 2 1 1 2 1 and d \u2a7e d \u2212\u03f5. We can now see that |b \u2212b | \u2a7d \u03f5 and |d \u2212d | \u2a7d \u03f5: to violate this, 2 1 2 1 2 1 \u27e8b ,d \u27e9 would have to be a larger interval than \u27e8b ,d \u27e9 (in particular, it would be longer 2 2 1 1 than2\u03f5), andwecouldthusexchangetheirrolesandgetthatb \u2a7d b +\u03f5andd \u2a7e d \u2212\u03f5. 1 2 1 2 We thus know that we can just match the off-diagonal points to each other, and since we must have d ((b ,d ),(b ,d )) \u2a7d \u03f5 we get the bound on d . \u221e 1 1 2 2 b We now prove the other direction, d (I ,I ) \u2a7d d (DgmI ,DgmI ). To see this, we I 1 2 b 1 2 show that from every matching whose longest edge is \u03f5, we get an \u03f5-interleaving. 73 Chapter 6. Distances and Stability Introduction to TDA Case 1: The two off-diagonal points are matched to the diagonal. Then, we get that d \u2212b \u2a7d 2\u03f5 for both of them, and thus for all \u03f5\u2032 > \u03f5, I and I are \u03f5\u2032-interleaved with i i 1 2 \u03c6,\u03c8 = 0 (recall Exercise 6.22). Thus, d \u2a7d \u03f5. I Case 2: The points are matched with each other. Then, |b \u2212b | \u2a7d \u03f5 and |d \u2212d | \u2a7d \u03f5. 2 1 2 1 Taking \u03c6,\u03c8 = id we can see that I and I are \u03f5-interleaved. Thus, d \u2a7d \u03f5. 1 2 I We can now use this to show one direction of Theorem 6.26. Corollary 6.38. Let U,V be p.f.d. persistence modules. Then we have that d (U,V) \u2a7d I d (DgmU,DgmV). b Proof. We apply the structure theorem to decompose U,V into direct sums of interval modules, i.e., U = (cid:76) I\u27e8b ,d \u27e9 \u2295 (cid:76) 0 and V = (cid:76) 0 \u2295 (cid:76) I\u27e8b ,d \u27e9. From the i\u2208I i i j\u2208J i\u2208I j\u2208J j j Bottleneck matching we get a matching between parts making up and . Since the U V Bottleneck distance is the maximum length of any edge, we have"}
{"node_id": "tdanotes:6.3", "pdf_id": "tdanotes", "section_id": "6.3", "chunk_id": "6.3-2", "text": "of interval modules, i.e., U = (cid:76) I\u27e8b ,d \u27e9 \u2295 (cid:76) 0 and V = (cid:76) 0 \u2295 (cid:76) I\u27e8b ,d \u27e9. From the i\u2208I i i j\u2208J i\u2208I j\u2208J j j Bottleneck matching we get a matching between parts making up and . Since the U V Bottleneck distance is the maximum length of any edge, we have d (DgmU,DgmV) \u2a7e b d (DgmI ,DgmI ) = d (I ,I ) for every two interval modules that were matched to- b 1 2 I 1 2 gether, where we used Proposition 6.37. Finally, we use Proposition 6.35 to get the desired statement. Questions 20. How can we measure distances between persistence diagrams? Discuss Bottle- neck and Wasserstein distance. 21. How stable are filtrations derived from simplex-wise monotone functions with respect to Bottleneck distance? State, illustrate and prove the stability theorem (Theorem 6.7). 22. How can we measure distances between persistence modules? Define interleav- ing distance and discuss its relation to Bottleneck distance. 23. How stable are \u010cech complexes to perturbations of the underlying point set? DefineHausdorffdistance, stateandprovethestabilitytheoremfor\u010cechcomplexes (Theorem 6.31). 74"}
{"node_id": "tdanotes:7.1", "pdf_id": "tdanotes", "section_id": "7.1", "chunk_id": "7.1-0", "text": "Chapter 7 Reeb Graphs and Mapper In this chapter we look at another tool in topological data analysis, called Mapper. The underlying idea of Mapper has its roots in Morse theory, where Georges Reeb defined a graph to summarize a Morse function on a manifold. We first discuss these graphs, called Reeb graphs, and then how to mimic the ideas for the case where instead of a manifold we have point cloud data. Before we dive into the mathematical details, a short remark about the pronunciation of the word \u201cReeb graph\u201d: Georges Reeb, after whom these graphs are named, was a French mathematician born in the German speaking region Alsace. Thus, he likely pronounced his name the German way, that is, with the \u201cee\u201d spoken similar to the \u201cea\u201d in \u201cbear\u201d (as opposed to \u201cbeer\u201d). 7.1 Reeb Graphs The idea of Reeb graphs is that given some topological space X, and some function f : X \u2192 R , we consider the preimage of f for some fixed value a \u2208 R . We place one point per connected path-component of the preimage. We do this for all values in , R and connect the points corresponding to neighboring connected components in adjacent preimages. More formally, Definition 7.1. Let X be some topological space, and f a function f : X \u2192 R. Two points x,y are called equivalent (x \u223c y), iff f(x) = f(y) = \u03b1 and x and y are in the same path-connected component of f\u22121(\u03b1). The Reeb graph R is the quotient space f X/ \u223c. We assume all of our functions to be levelset tame for the space X: Definition 7.2. A function f : X \u2192 R is levelset tame if \u2022 each levelset f\u22121(\u03b1) has finitely many connected components, all of which are path-connected, and 75 Chapter 7. Reeb Graphs and Mapper Introduction to TDA R f : X \u2192 X R f Figure 7.1: An example of a Reeb graph \u2022 the homology groups of the levelsets only change at finitely many critical val- ues. As we have defined it, the Reeb graph is just a (continuous) topological space. We call it a graph since it is 1-dimensional, but to arrive at a graph as we know it in combinatorics, we will need to discretize it. For this we need to define vertices and edges. There are many different possibilities of defining vertices and edges to discretize the Reeb graph, but we want to define some type of minimal one. Let us look at the neighborhood of some point p in the Reeb graph (as a topological space). We look at how many ways there exist to go from p towards the direction of higher f-value (we call this number the up-degree u), and how many ways to go towards the direction of lower f-value (we call this the down-degree l). Depending on u and l, we classify p as in Table 7.1. Table 7.1: Classifications of points in the Reeb graph. u l Classification 1 1 regular 0 > 0 maximum > 0 0 minimum \u2a7e 2 l up-fork u \u2a7e 2 down-fork Note that a point can fall into multiple of these classes, for example it can be a maxi- mum and a down-fork simultaneously, or an up-fork and a down-fork simultaneously. We 76 Introduction to TDA 7.1. Reeb Graphs call the minima, maxima, up-forks, and down-forks critical points. Our discretization places vertices at the critical points, and all the connections between critical points (that are made up of only regular points) become the edges of our graph. Note"}
{"node_id": "tdanotes:7.1", "pdf_id": "tdanotes", "section_id": "7.1", "chunk_id": "7.1-1", "text": "maxi- mum and a down-fork simultaneously, or an up-fork and a down-fork simultaneously. We 76 Introduction to TDA 7.1. Reeb Graphs call the minima, maxima, up-forks, and down-forks critical points. Our discretization places vertices at the critical points, and all the connections between critical points (that are made up of only regular points) become the edges of our graph. Note that the graph we get through this process is not necessarily simple, we may have multi-edges. Exercise 7.3. Consider a double torus embedded in R3. You can imagine it as the result of taking the figure depicted in Figure 7.2 embedded in the plane x = 0, 3 replacing every point by a 3-dimensional ball with radius r < min{d/2,R/2}, and taking the boundary of the union of these balls. x 2 R R d x 1 Figure 7.2: The space blown up to a double torus in Exercise 7.3. Draw the Reeb graphs for the functions f (x) = x , f (x) = x , and f (x) = x . 1 1 2 2 3 3 We next consider merge trees and split trees, which are variants of the Reeb graph, where instead of levelsets, we look at sub-level sets or super-level sets. Definition 7.4. Let X be some topological space, and f a function f : X \u2192 R. We have x \u223c y for two points x,y, if and only if f(x) = f(y) = \u03b1 and x and y are in M the same connected component of f\u22121((\u2212\u221e,\u03b1]). The merge tree T is the quotient M space X/ \u223c . M Note that in the merge tree, since we only increase the space under consideration, we never have a connected component that splits. We can only have new connected components appearing, and connected components merging. This also tells us that the Merge tree (or its discretization) is always a tree. Definition 7.5. Let X be some topological space, and f a function f : X \u2192 R. We have x \u223c y for two points x,y, if and only if f(x) = f(y) = \u03b1 and x and y are in the same S connected component of f\u22121([\u03b1,\u221e)). The split tree T is the quotient space X/ \u223c . S S To be able to compute Reeb graphs in actual TDA applications, we now look at Reeb graphs in the context of simplicial complexes. We consider a simplicial complex K and a function f : |K| \u2192 R , which is piece-wise linear (linear on each simplex). We observe that 77 Chapter 7. Reeb Graphs and Mapper Introduction to TDA the Reeb graph then only depends on the 2-skeleton of K. This is the case since looking at a levelset is the same as cutting through the simplicial complex. When we cut through a simplex, we generally get a simplex of one dimension lower. In a simplicial complex, connectivity is completely determined by the 1-skeleton. Thus, before cutting, the 2- skeleton suffices. We can also see that the critical points are images of the vertices of K. This happens since a connected component can only appear, disappear, split, or merge at some local maximum or minimum of the connected component. Since the function is linear, the maximum or minimum of every simplex is always attained at some vertex. We define the augmented Reeb graph of a simplicial complex with a PL-function, as the discretization of the Reeb graph by placing a vertex for every connected component in all the levelsets for the values a for which f(v) = a for some vertex of the"}
{"node_id": "tdanotes:7.1", "pdf_id": "tdanotes", "section_id": "7.1", "chunk_id": "7.1-2", "text": "linear, the maximum or minimum of every simplex is always attained at some vertex. We define the augmented Reeb graph of a simplicial complex with a PL-function, as the discretization of the Reeb graph by placing a vertex for every connected component in all the levelsets for the values a for which f(v) = a for some vertex of the simplicial complex. Theorem 7.6. Given a simplicial complex K with m faces and a piece-wise linear function f : |K| \u2192 R on it, we can compute the augmented Reeb graph R of K with f respect to f in time O(mlogm). Proof. We only have to consider the 2-skeleton of K. To compute the augmented Reeb graph, we perform a discrete sweep (or scan) through K in the order given by f, only stopping at values a such that f(v) = a for some vertex v. In this sweep, we want to keep track of the connected components. For any \u03b1 \u2208 R , the levelset f\u22121(\u03b1) of the 2-skeleton of K is just a graph G : vertices \u03b1 andedgesofKinduceverticesofG , trianglesinduceedges. Intheopenintervalbetween \u03b1 any two values a with f(v) = a, G stays the same. In our sweep, we track the graph \u03b1 G . Whenever we enter a vertex v, faces may end: The vertices in G that correspond \u03b1 \u03b1 to edges vw in K with f(v) > f(w) all get merged into a single vertex. Whenever we then exit v, some faces may start. The vertex corresponding to v is split into one vertex per edge vw in K such that f(v) < f(w). Some of these vertices are connected: the vertices corresponding to the edges vw and vx are connected by an edge if vwx is a triangle of K. To build the augmented Reeb graph out of these G graphs, we use a dynamic \u03b1 spanning forest data structure. Such a data structure can update connected components under both insertion and deletions of edges (vertices we only delete when also deleting all their incident edges). There exist such data structures that can do each update in amortized time O(logm), where m is the size of the graph. The size of the graph is bounded by the sum m of vertices, edges, and triangles in K. Each such feature appears at one point, and disappears at one point, and we thus have at most 2m insertions and deletions in total, giving an O(mlogm) algorithm. Exercise 7.7. Consider a simplicial complex K and a PL (piece-wise linear) function f : |K| \u2192 R. What happens to the Reeb graph when you add one additional face to K and extend f accordingly? 78"}
{"node_id": "tdanotes:7.1.1", "pdf_id": "tdanotes", "section_id": "7.1.1", "chunk_id": "7.1.1-0", "text": "Introduction to TDA 7.1. Reeb Graphs 7.1.1 Homology of Reeb Graphs The Reeb graph of a topological space X with respect to a function f can be viewed as a summary of X through the lens of f. The natural question is: how good of a summary is it? It is clear that in general we lose information, for example on the dimension of X, but we can still hope that some topological information is retained. In this section, we thus compare the homology of the Reeb graph to the homology of X. Since the Reeb graph R is a graph (a 1-dimensional object), we have H (R ) = 0 for p \u2a7e 2, so f p f any higher-dimensional homology gets lost. However, a graph can still have non-trivial homology in dimensions 0 and 1. Observation 7.8. For a levelset tame f : X \u2192 R, we have \u03b2 (X) = \u03b2 (R ). 0 0 f In other words, the Reeb graph captures the 0-homology of the input space X per- fectly, no matter which levelset tame function f we use. Sadly, the same does not hold for the 1-homology. Let us consider a torus, as in Figure 7.3. In general, it can be that the choice of function f determines whether we capture a hole or not, consider for example a cylinder. However note that for the torus, it is actually the case that no matter which function f we choose, we cannot capture its 1-homology (this is non-trivial to show). f Figure 7.3: The torus and its Reeb graph. On the other hand, we can see that every cycle in the Reeb graph is indeed also a cycle in the topological space X, and it cannot be filled in, so it is indeed a hole. Thus we also get the following observation: Observation 7.9. For a levelset tame f : X \u2192 R, we have \u03b2 (X) \u2a7e \u03b2 (R ). 1 1 f Canwesomehowformalizewhichholeswelose? Todothis, wesplituphomologyinto \u201chorizontal\u201d and a \u201cvertical\u201d parts. The intuition behind these terms is that we consider f to be a function pointing upwards, and thus roughly, horizontal means \u201cperpendicular to f\u201d and vertical means \u201calong f\u201d. 79 Chapter 7. Reeb Graphs and Mapper Introduction to TDA Definition 7.10. A p-th homology class h \u2208 H (X) is called horizontal if there is a p finite set of values A = {a ,...,a } such that h \u2208 im(\u03b9 ) where \u03b9 is the map 1 k \u2217 \u2217 (cid:83) H ( X ) \u2192 H (X) induced by inclusion, where X = f\u22121(a). p a\u2208A a p a This definition means that we need to be able to find a finite set of levelsets, such that we can find cycles contained in these levelsets, which are in the homology class h in H (X). p One now wonders whether the set of horizontal homology classes forms a group. Let this set be H (X). It turns out that it is indeed a group. p Lemma 7.11. H (X) is a subgroup of H (X). p p Proof. First, we see that the identity element 0 is in H (X). We can take an arbitrary p set A, and we can always map the 0 element of H ( (cid:83) X ) to 0. p a\u2208A a Next, we show that the set is closed under addition. Let p,q \u2208 H (X), and we show p that p+q \u2208 H (X). p has a pre-image in some levelset A , and q has a pre-image in p p some levelset A"}
{"node_id": "tdanotes:7.1.1", "pdf_id": "tdanotes", "section_id": "7.1.1", "chunk_id": "7.1.1-1", "text": "always map the 0 element of H ( (cid:83) X ) to 0. p a\u2208A a Next, we show that the set is closed under addition. Let p,q \u2208 H (X), and we show p that p+q \u2208 H (X). p has a pre-image in some levelset A , and q has a pre-image in p p some levelset A . p+q must have a pre-image in A \u222aA . q p q Finally, we show that the inverse of every element is contained in the group, but since every element is self-inverse in Z -homology, we get that for every element its inverse is 2 also contained in H (X). p Since the horizontal homology is a sub-group, we can now easily define vertical ho- mology by taking quotient groups. \u2228 Definition7.12. The verticalhomologygroup of X with respect to f is the group H (X) := p H (X)/H (X). p p \u2228 Observation 7.13. dim(H (X)) = dim(H (X))+dim(H (X)). p p p The following fact that we do not prove here shows that when we go from a space X to its Reeb graph, we keep the vertical homology classes, and lose the horizontal ones. \u2228 \u2228 Fact 7.14. The surjection \u03d5 : X \u2192 R induces an isomorphism \u03a6 : H (X) \u2192 H (R ). f 1 1 f Corollary 7.15. Given X an orientable connected compact 2-manifold, and a Morse function f : X \u2192 R, then \u03b2 (R ) = \u03b2 (X)/2. 1 f 1 Here, a 2-manifold is a space that locally at every point looks like R2. Orientable means that there is an inside and an outside side. A Morse function is a \u201cnice enough\u201d function defined in terms of some derivatives, which we do not need to specify here. Exercise 7.16. (a) Consider a 2-dimensional geometric simplicial complex K embed- ded in R2. Consider the function f(x) = x . Show that \u03b2 (K) = \u03b2 (R ). 1 1 1 f (b) Find a geometric simplicial complex K embedded in R2 and a map f : K \u2192 R such that \u03b2 (K) > \u03b2 (R ). 1 1 f 80"}
{"node_id": "tdanotes:7.2.1", "pdf_id": "tdanotes", "section_id": "7.2.1", "chunk_id": "7.2.1-0", "text": "Introduction to TDA 7.2. Distances for Reeb Graphs 7.2 Distances for Reeb Graphs InordertocompareReebgraphstoeachother, weagainwanttodefinedistancemeasures between them. We discuss two such measures here. The first one, called interleaving distance, is, not surprisingly, similar to the interleaving distance of persistence mod- ules. The second one, called functional distortion distance is similar to the Gromov- Hausdorff distance for metric spaces. 7.2.1 Interleaving Distance When do we want two Reeb graphs to be considered the same, and thus have distance 0? We definitely need that the graphs are isomorphic in the sense of graph isomorphism. But further than that, we also want that this graph isomorphism is \u201cfunction preserving\u201d. In other words, the critical points should lie on the same function levels. The idea of the interleaving distance is to measure how far away from this we are. Thus, given two Reeb graphs R ,R , \u201chow much\u201d is missing towards a \u201cfunction preserving isomorphism\u201d? f g Towards formalizing this idea, we need a few definitions. Note that when we compare two Reeb graphs R ,R , those can be Reeb graphs of f g different spaces with regards to different functions. Definition 7.17. An \u03f5-thickening X of some topological space X is given by X := \u03f5 \u03f5 X\u00d7[\u2212\u03f5,+\u03f5]. Definition 7.18. For a Reeb graph R consider a function f : (R ) \u2192 R such that f \u03f5 f \u03f5 (x,t) (cid:55)\u2192 f(x)+t. The \u03f5-smoothing of R , denoted by S (R ) is the Reeb graph of (R ) with regards f \u03f5 f f \u03f5 to f . \u03f5 An example of these definitions can be seen in Figure 7.4. Note that when we say (R ) , we meanan\u03f5-thickeningofR , not aReeb graphwith regardsto somefunctionf . f \u03f5 f \u03f5 The \u03f5-smoothing S (R ) is then a Reeb graph with regards to the function f , but of \u03f5 f \u03f5 (R ) , and not of the original space that R is the Reeb graph of. Furthermore, when f \u03f5 f we write f(x) for some x \u2208 R , we mean that we extend f to some function f\u2217 : R \u2192 R , f f simply by mapping x (an element of X/ \u223c, i.e., an equivalence class of \u223c) to f(p) for some point p \u2208 X in the equivalence class x. We will just call this function f as well for simplicity. Definition7.19. The function \u03b9 : R \u2192 S (R ) with x (cid:55)\u2192 [(x,0)] is the quotientedinclusion f \u03f5 f map. Here, [(x,0)] denotes the equivalence class, or the connected component that contains (x,0) in f\u22121(f (x,0)). \u03f5 \u03f5 Consider some function \u00b5 : R \u2192 R which is function preserving, i.e., f(x) = g(\u00b5(x)) f g for all x \u2208 R . A function-preserving map \u00b5 : R \u2192 S (R ) induces a function preserving f f \u03f5 g map \u00b5 : S (R ) \u2192 S (R ) with [(x,t)] (cid:55)\u2192 [(\u00b5(x),t)]. \u03f5 \u03f5 f 2\u03f5 g 81 Chapter 7. Reeb Graphs and Mapper Introduction to TDA R (R ) S (R ) f f (cid:15) (cid:15) f Figure 7.4: A Reeb graph, its \u03f5-thickening, and its \u03f5-smoothing. Definition 7.20 (Reeb graph interleaving). Two Reeb graphs R ,R are \u03f5-interleaved, if f g there exists a pair of function preserving maps \u03c6 : R \u2192 S (R ), \u03c8 : R \u2192 S (R ) f \u03f5 g g \u03f5 f such that the following diagram commutes: R \u03b9 S (R ) \u03b9\u03f5 S (R ) f \u03f5 f 2\u03f5 f \u03c8 \u03c6 \u03c8\u03f5 \u03c6\u03f5 R \u03b9"}
{"node_id": "tdanotes:7.2.1", "pdf_id": "tdanotes", "section_id": "7.2.1", "chunk_id": "7.2.1-1", "text": ",R are \u03f5-interleaved, if f g there exists a pair of function preserving maps \u03c6 : R \u2192 S (R ), \u03c8 : R \u2192 S (R ) f \u03f5 g g \u03f5 f such that the following diagram commutes: R \u03b9 S (R ) \u03b9\u03f5 S (R ) f \u03f5 f 2\u03f5 f \u03c8 \u03c6 \u03c8\u03f5 \u03c6\u03f5 R \u03b9 S (R ) \u03b9\u03f5 S (R ) g \u03f5 g 2\u03f5 g Here, to understand why \u03b9 makes sense, we need the following fact, the proof of \u03f5 which is left as an exercise. \u223c Observation 7.21. S (S (R )) = S (R ). \u03b4 \u03f5 f \u03b4+\u03f5 f Note that by construction of \u03b9,\u03b9 and \u03c6 (or \u03c8 , respectively), the trapezoidal parts \u03f5 \u03f5 \u03f5 of this diagram commute trivially: \u03c6 \u25e6 \u03b9(x) = \u03c6 ([(x,0)]) = [(\u03c6(x),0)] = \u03b9 \u25e6 \u03c6(x). \u03f5 \u03f5 \u03f5 Furthermore, any two compact and connected Reeb graphs are \u03f5-interleaved for some \u03f5. Lastly, if R and R are \u03f5-interleaved, then they are also \u03b4-interleaved for all \u03b4 \u2a7e \u03f5. f g Definition 7.22. d (R ,R ) = inf{\u03f5 | R ,R are \u03f5-interleaved}. I f g f g We once again have a stability theorem, which we will not prove here. Theorem 7.23. For tame functions f,g : X \u2192 R we have d I (R f ,R g ) \u2a7d ||f\u2212g|| \u221e . 82"}
{"node_id": "tdanotes:7.2.2", "pdf_id": "tdanotes", "section_id": "7.2.2", "chunk_id": "7.2.2-0", "text": "Introduction to TDA 7.2. Distances for Reeb Graphs 7.2.2 Functional Distortion Distance As mentioned above, the functional distortion distance is motivated by the Gromov- Hausdorff distance for metric spaces. Thus, the first step is to define a metric on a single Reeb graph. Definition 7.24. Let R be a Reeb graph of a space X, and u,v \u2208 R (in the same f f connected component of R ), and let \u03c0 be a path from u to v. We define the height f of \u03c0 as height(\u03c0) = max f(x)\u2212min f(x). To turn this into a distance metric, x\u2208\u03c0 x\u2208\u03c0 we consider \u03a0(u,v),the set of all paths between u and v. Then, the function induced metric on R is defined as f d (u,v) = min height(\u03c0). f \u03c0\u2208\u03a0(u,v) In a sense, d (u,v) is the \u201cthickness\u201d of the thinnest \u201cslice\u201d of the space X in which u f and v are connected. Definition 7.25 (Functional distortion distance). Let R and R be two Reeb graphs. Let f g \u03a6 : R \u2192 R , \u03a8 : R \u2192 R be continuous functions, but not necessarily function- f g g f preserving. Then, we define correspondence and distortion: C(\u03a6,\u03a8) = {(x,y) \u2208 R \u00d7R | \u03a6(x) = y or x = \u03a8(y)} f g 1 D(\u03a6,\u03a8) = sup |d (x,x\u2032)\u2212d (y,y\u2032)|. f g 2 (x,y),(x\u2032,y\u2032)\u2208C(\u03a6,\u03a8) And finally, we define the functional distortion distance, d (R ,R ) = inf max{D(\u03a6,\u03a8),||f\u2212(g\u25e6\u03a6)|| ,||g\u2212(f\u25e6\u03a8)|| }. FD f g \u221e \u221e \u03a6,\u03a8 Also for this distance measure there is a stability theorem. Theorem 7.26. Let f,g : X \u2192 R be tame functions. Then, d FD (R f ,R g ) \u2a7d ||f\u2212g|| \u221e . We can also quantify the relation between the two discussed distances. Theorem 7.27. d (R ,R ) \u2a7d d (R ,R ) \u2a7d 3d (R ,R ). I f g FD f g I f g Exercise 7.28. Consider a merge tree T with regards to a function f. We define the a-shift xa for any x \u2208 T to be the unique \u201cancestor\u201d of x with function value f(xa) = f(x)+a. We now consider two merge trees; T with regards to f, and T with regards to 1 2 g. We call T and T \u03f5-compatible if there exist maps \u03b1 : T \u2192 T and \u03b2 : T \u2192 T 1 2 1 2 2 1 such that we get the following commutativities: \u2022 g(\u03b1(x)) = f(x)+\u03f5 for all x \u2208 T 1 83"}
{"node_id": "tdanotes:7.3.2", "pdf_id": "tdanotes", "section_id": "7.3.2", "chunk_id": "7.3.2-0", "text": "Chapter 7. Reeb Graphs and Mapper Introduction to TDA \u2022 f(\u03b2(y)) = g(y)+\u03f5 for all y \u2208 T 2 \u2022 \u03b2\u25e6\u03b1(x) = x2\u03f5 for all x \u2208 T 1 \u2022 \u03b1\u25e6\u03b2(y) = y2\u03f5 for all y \u2208 T . 2 The interleaving distance between merge trees d (T ,T ) can now be defined as I 1 2 the infimum of all \u03f5 such that T and T are \u03f5-compatible. Show that d (T ,T ) = 1 2 I 1 2 d (T ,T ). FD 1 2 Note: we technically only defined d for Reeb graphs. You can simply consider a FD merge tree to be the Reeb graph of itself (with regards to the same filter function). 7.3 Mapper Reeb graphs lose a lot of information, since they at most retain some 1-dimensional holes, butnolargerholes. TogeneralizeReebgraphsfurther, westartlookingatneighborhoods instead of levelsets, which will then lead to the Mapper algorithm. 7.3.1 An Approximation of the Reeb Graph To begin, we consider the 1-dimensional case, and try to find an approximation of the Reeb graph. Instead of looking at pre-images of points, we will now look at pre-images of intervals. Let U = {U } be an open cover of R (i.e., a collection of open sets whose \u03b1 \u03b1\u2208A union is R ). As always, we consider a function f : X \u2192 R . For each f\u22121(U ), we consider \u03b1 a partition into path-connected components, i.e., f\u22121(U ) = (cid:83) V . We then look at f\u2217(U) := {V }, the set of all V we get over all \u03b1. Our \u03b1 object \u03b2 of \u2208B in\u03b1ter \u03b2 est is the nerve of \u03b2 \u03b2 this family, i.e., N(f\u2217(U)). If we take sufficiently nice functions, and sufficiently fine covers, then N(f\u2217(U)) is isomorphic to R . f 7.3.2 Topological Mapper We can generalize this idea to maps to arbitrary spaces. Definition 7.29. Let X,Z be topological spaces. Then we call f : X \u2192 Z well-behaved if for all path-connected open sets U \u2286 Z, f\u22121(U) has finitely many path-connected components. Definition 7.30 (Mapper). Let f : X \u2192 Z be well-behaved, and U be a (finite) open cover of Z. Then the Mapper is defined as M(U,f) := N(f\u2217(U)). As an example, we look at X being the boundary of the 3-cube [0,1]3. We then also look at Z = R2 spanned by the x- and y-axis, with f : X \u2192 Z being the projection onto 1 1 1 this plane. Furthermore, we look at Z = R , spanned by just the x-axis, and f : X \u2192 Z 2 2 2 being again the projection. 84"}
{"node_id": "tdanotes:7.3.3", "pdf_id": "tdanotes", "section_id": "7.3.3", "chunk_id": "7.3.3-0", "text": "Introduction to TDA 7.3. Mapper X U f\u2217(U) N(f\u2217(U)) Figure 7.5: A space X, an open cover U of R, the family f\u2217(F), and its nerve. We consider the open cover U of Z : {(\u2212\u221e, 1),(0,1),(2,+\u221e)}. For Z , we consider 2 2 3 3 1 the cover U := U \u00d7U . 1 2 2 Exercise 7.31. (a) Consider spaces X,Z, a filter function f : X \u2192 Z, and an open cover U of Z. Show that if the pullback cover f\u2217(U) is a good cover of X, then M(U,f) is homotopy equivalent to X. (b) Give an example of spaces X,Z, a filter function f : X \u2192 Z, and a good cover U of Z, such that M(U,f) is not homotopy equivalent to X. (c) Give an example of spaces X,Z, a filter function f : X \u2192 Z, and an open cover U of Z such that the pullback cover f\u2217(U) is not a good cover, but M(U,f) is still homotopy equivalent to X. 7.3.3 Mapper for Point Clouds We would like to apply the ideas of the topological Mapper to analyze the shape of data. However, once again we have the issue that data usually does not come in the form of a topological space, but as a set of data points with a notion of distance between them. The Mapper algorithm for point clouds adapts the ideas of the topological Mapper to this setting. Input: In the most general setting, data comes as a finite metric space (P,d ), for ex- P ample as points in Rd or as vertices of a graph. We also require a cover U of a space Z, usually Z = R , as input. Finally, we also need a filter function f : P \u2192 Z and a clustering algorithm (which might also require some input parameters). 85"}
{"node_id": "tdanotes:7.4", "pdf_id": "tdanotes", "section_id": "7.4", "chunk_id": "7.4-0", "text": "Chapter 7. Reeb Graphs and Mapper Introduction to TDA y M(U ,f ) 2 2 M(U ,f ) 1 1 x Figure 7.6: The cover U , and the two Mappers. The Mapper M(U ,f ) consists \u221e 1 1 of an empty octahedron, with additional filled tetrahedra attached at the purple vertices. The whole space thus collapses to an octahedron. Algorithm: Since at the moment we only have a discrete metric space, we do not really have the notion of connected components yet. For every U \u2208 U, we thus cluster the pre- image f\u22121(U) using some clustering algorithm, which we can also consider as an input. Now, we can just consider each cluster C as a vertex of some simplicial complex K, and i add a face {C ,...,C } to K if these clusters (which are just point sets) have a common 1 k point. Output: We output K, or even just its 1-skeleton. As you can see, this algorithm requires a lot of input parameters. While this allows to encode previous knowledge of the data set (e.g. by choosing as filter function the distance to a known center of the data), it also makes the space of possible outputs very large. Picking the correct parameters is currently still an art form on its own, and there is significant research being done towards understanding the interplay between the parameters and statistical guarantees for certain good choices of parameters. 7.4 Multiscale Mapper Motivated by the many tuneable parameters, we discuss here one idea to look at many values at once. The multiscale Mapper is a combination of the ideas of persistence and of Mapper. We here want to look at different covers. Definition 7.32. Let U = {U } and F = {V } be two covers of the same space X. \u03b1 \u03b1\u2208A \u03b2 \u03b2\u2208B A map of covers is a map \u03c6 : A \u2192 B such that for every \u03b1 \u2208 A, we have U \u2286 V . \u03b1 \u03c6(\u03b1) 86 Introduction to TDA 7.4. Multiscale Mapper Proposition 7.33. If \u03c6 : U \u2192 V is a map of covers (with a slight abuse of notation), then the map N(\u03c6) : N(U) \u2192 N(V) given on the vertices by \u03c6 is simplicial. Proof. Let \u03c3 \u2208 N(U). We need to show that the intersection (cid:84) V is non- \u03b2\u2208N(\u03c6)(\u03c3) \u03b2 empty. (cid:92) (cid:92) (cid:92) V = V \u2287 U \u0338= \u2205 \u03b2 \u03c6(\u03b1) \u03b1 \u03b2\u2208N(\u03c6)(\u03c3) \u03b1\u2208\u03c3 \u03b1\u2208\u03c3 Thus, N(\u03c6)(\u03c3) \u2208 N(V). An example of this map between nerves can be seen in Figure 7.7. Proposition 7.34. Let f : X \u2192 Z be some map, and U,V be covers of Z, with \u03c6 : U \u2192 V some map of covers. Then, there exists a map of covers f\u2217(\u03c6) : f\u2217(U) \u2192 f\u2217(V). Recall that f\u2217(U) is the cover of X consisting of the connected components of the pre-images of the sets of U under f. Proof. For every \u03b1, we have U \u2286 V =\u21d2 f\u22121(U ) \u2286 f\u22121(V ). We now need to go \u03b1 \u03c6(\u03b1) \u03b1 \u03c6(\u03b1) from these pre-images to their connected components. Since every connected component of f\u22121(U ) must lie in a unique connected component of f\u22121(V ), our desired map of \u03b1 \u03c6(\u03b1) covers is given by exactly mapping to this connected component. If we have multiple maps of covers, U \u2192 \u03c6 V \u2192 \u03c8 W, we can concatenate the maps, and the f\u2217 function distributes: f\u2217(\u03c8\u25e6\u03c6) = f\u2217(\u03c8)\u25e6f\u2217(\u03c6). Let U = U \u2192 \u03c6 1 U \u2192 \u03c6 2 ... \u03c6 \u2192n\u22121 U be a sequence"}
{"node_id": "tdanotes:7.4", "pdf_id": "tdanotes", "section_id": "7.4", "chunk_id": "7.4-1", "text": "desired map of \u03b1 \u03c6(\u03b1) covers is given by exactly mapping to this connected component. If we have multiple maps of covers, U \u2192 \u03c6 V \u2192 \u03c8 W, we can concatenate the maps, and the f\u2217 function distributes: f\u2217(\u03c8\u25e6\u03c6) = f\u2217(\u03c8)\u25e6f\u2217(\u03c6). Let U = U \u2192 \u03c6 1 U \u2192 \u03c6 2 ... \u03c6 \u2192n\u22121 U be a sequence of covers of Z with maps between 1 2 n them, which we call a cover tower. By applying f\u2217 we get a cover tower f\u2217(U) of X. Definition 7.35 (Multiscale Mapper). Let f : X \u2192 Z, U a cover tower of Z. Then, the Multiscale Mapper MM(U,f) is MM(U,f) := N(f\u2217(U)) = {N(f\u2217(U )) | U \u2208 U}) i i together with the induced simplicial maps N(f\u2217(\u03c6 )) : N(f\u2217(U )) \u2192 N(f\u2217(U )). i i i+1 Applying homology, we get the sequence homology groups with induced homo- morphisms between them, i.e., a persistence module: H (N(f\u2217(U ))) N(f \u2212 \u2217( \u2192 \u03c6 1 ))\u2217 ... N(f\u2217 \u2212 (\u03c6 \u2192n\u22121 ))\u2217 H (N(f\u2217(U ))). p 1 p n We can now view Dgm MM(U,f) as a topological summary of f through the lens p of U. As opposed to the normal Mapper, at first glance the Multiscale Mapper adds even more parameters. But a cover tower can be seen as a way of looking at a whole interval of covers. For example, we can get a cover tower by increasing the size of all intervals in an interval cover. The features of the data should show up as a robust feature that persistsforalongertimeoverthisprocess,whilespuriousfeaturesobtainedfromchoosing \u201cwrong\u201d Mapper parameters should disappear quickly. 87 Chapter 7. Reeb Graphs and Mapper Introduction to TDA Figure 7.7: Three pullback covers of a space X (thickened figure \u201c8\u201d), with their nerves and the induced simplicial maps between them. 88 Introduction to TDA 7.4. Multiscale Mapper Questions 24. What is a Reeb graph? State the definition and describe how we get the graph structure. 25. How can we compute the augmented Reeb graph of a piece-wise linear func- tion? Define the augmented Reeb graph and explain the algorithm to compute it. 26. How much of the homology of the underlying topological space is captured by the Reeb graph? Explain vertical and horizontal homology. 27. What is the interleaving distance for Reeb graphs? Give the definitions and state the relevant stability theorems. 28. (Thistopicwasnotcoveredinthisyear\u2019scourseinFS25andthereforethefollowingquestion will not be asked in the exam.)What is the functional distortion distance for Reeb graphs? Give the definitions and state the relevant stability theorems. 29. What is the topological Mapper? State the Definition and give an example. 30. How can we use Mapper on point cloud data? Explain the Mapper algorithm and describe the input parameters. 31. (Thistopicwasnotcoveredinthisyear\u2019scourseinFS25andthereforethefollowingquestion will not be asked in the exam.)How can we use Mapper on several covers at once? Explain the Multiscale Mapper. 89"}
{"node_id": "tdanotes:8.1", "pdf_id": "tdanotes", "section_id": "8.1", "chunk_id": "8.1-0", "text": "Chapter 8 Optimal Generators In some applications, we are not only interested in the number of holes in our data, but we also want to get representations of these holes in the data. In other words, we are interested in finding a \u201crepresentative\u201d basis of the homology group. There are two main challenges to picking such a basis: First off, there are many different choices of homology classes which form a basis of the homology group. Second off, even within a single homology class, there are many homologous cycles. Thus, there are many different choices for cycles as bases of the homology group. How do we find good bases? To specify our optimization target, we define a weight function w : (cid:80) K p \u2192 R\u2a7e0 on the p-simplices, and the weight of a chain is simply the sum, i.e., w(c) = \u03b1 w(\u03c3 ) for (cid:80) i i c = \u03b1 \u03c3 . The weight of a set of cycles C is then the sum of weights of each cycle. i i We are now interested in cycles that have minimal weight in their homology class, or at bases with minimum total weight. We look at this problem in two settings: first we look at the case where we are given a fixed simplicial complex and we want to find an optimal basis for the homology of this complex. This can be applied for example if the persistence diagram of a filtration gives us a range of values in which we expect the complex to nicely capture the shape of the data. We can then compute an optimal basis for the homology of the fixed complex for some value in this range. In some applications, we might also want to take a closer look at single intervals in the persistence barcode, that is, understand a hole that is born at time b and dies at time d (for example, to decide whether it corresponds to a feature in the data or is just a consequence of the process). This brings us to the second setting we look at in this chapter, where we want to find an optimal representative of a persistent homology class. 8.1 Optimal Basis of a Fixed Complex Definition 8.1. A set C of cycles is an optimal basis for H (K) if it is a basis and there p is no other basis C\u2032 with w(C\u2032) < w(C). How can we compute such an optimal basis? 90 Introduction to TDA 8.1. Optimal Basis of a Fixed Complex In a first step, we are going to compute a set of cycles C which contains an optimal basis. Then, we perform a greedy algorithm to find the optimal basis in a similar way to Kruskal\u2019s algorithm for Minimum Spanning Tree: we sort the cycles by increasing weight, and start our basis B with the trivial cycle 0. Then, we simply iterate through our cycles and add a cycle c to our basis if it cannot be written as a linear combination i of our current basis. Finally, we remove 0 again from B. The correctness of this greedy approach, as well as the correctness of many other greedy algorithms including the above-mentioned Kruskal, follows from a more general framework in matroid theory. Exercise 8.2. A matroid is a collection I of subsets of some universe U, such that 1. \u2205 \u2208 I, and if some set L is in I, all L\u2032 \u2286 L are also in I. 2. If some L,L\u2032 are in I, and |L\u2032| = |L|+1, then there exists an element f \u2208 L\u2032\\L,"}
{"node_id": "tdanotes:8.1", "pdf_id": "tdanotes", "section_id": "8.1", "chunk_id": "8.1-1", "text": "general framework in matroid theory. Exercise 8.2. A matroid is a collection I of subsets of some universe U, such that 1. \u2205 \u2208 I, and if some set L is in I, all L\u2032 \u2286 L are also in I. 2. If some L,L\u2032 are in I, and |L\u2032| = |L|+1, then there exists an element f \u2208 L\u2032\\L, such that L\u222a{f} \u2208 I. The sets in I are also called the independent sets of the matroid. The inclusion- maximal sets in I are called bases. (a) Show that for U being any finite set of vectors in some vector space, the family I of subsets of U corresponding to linearly independent vectors forms the family of independent sets of a matroid. (b) Show that for any graph G = (V,E), the family I of subsets of E corresponding to forests in G forms the family of independent sets of a matroid. (c) Consider a matroid on a universe U with a weight function w : U \u2192 R. Consider the following greedy algorithm: begin with L = \u2205, and consecutively add the lowest-weight element e \u0338\u2208 L such that L\u222a{e} remains an independent set, until reaching a basis. Show that this greedy algorithm finds a minimum- weight basis. We now need to show that we can implement all of the pieces of the algorithm we outlined above. For the first step, we need to be able to compute our set C. For the second greedy step, we need to be able to check linear independence of a set of cycles. SincetheproblemofcomputinganoptimalbasisisNP-hardforp > 1, wewillfocuson computing a basis for H (K). Without loss of generality, we say that K is 2-dimensional, 1 with n triangles and O(n) edges and vertices. To compute C, we begin with C = \u2205. For all vertices v, we compute the shortest path tree T rooted at v. We can do this for example with Dijkstra\u2019s algorithm. For every v edge e that is not in T , we add the unique simple cycle in T \u222a {e} to C. This can be v v implemented in O(n2logn), and yields a set of cycles with |C| \u2208 O(n2). But, we need to prove that it is indeed a set which contains an optimal basis. Lemma 8.3. C as computed by the method above contains an optimal basis. 91 Chapter 8. Optimal Generators Introduction to TDA Proof. Let C\u2217 be an optimal basis. Towards a contradiction, let c be a cycle contained in C\u2217\\C. Since we consider Z -homology, c is a simple cycle, i.e., no edge is used multiple 2 times.1 Let v be a vertex in c, and let T be the corresponding shortest path tree. There v must be an edge e = {u,w} in c\\T , since T is a tree. Let \u03a0 and \u03a0 be the shortest v v v,u v,w paths from v to u and w, respectively. These paths must be contained in T . Let us v similarly consider \u03a0\u2032 and \u03a0\u2032 to be the paths from v to u,w in c which do not use v,u v,w the edge e. If we now had \u03a0\u2032 = \u03a0 and \u03a0\u2032 = \u03a0 , c would be the unique simple v,u v,u v,w v,w cycle in T \u222a{e} and thus c would be in C. However, since we assumed this not to be the v case, w.l.o.g. we can assume that \u03a0\u2032 \u0338= \u03a0 . v,u v,u We now define the cycles c = \u03a0\u2032 + {e} + \u03a0 and c = \u03a0 + \u03a0\u2032 . We can"}
{"node_id": "tdanotes:8.1", "pdf_id": "tdanotes", "section_id": "8.1", "chunk_id": "8.1-2", "text": "unique simple v,u v,u v,w v,w cycle in T \u222a{e} and thus c would be in C. However, since we assumed this not to be the v case, w.l.o.g. we can assume that \u03a0\u2032 \u0338= \u03a0 . v,u v,u We now define the cycles c = \u03a0\u2032 + {e} + \u03a0 and c = \u03a0 + \u03a0\u2032 . We can 1 v,w v,u 2 v,u v,u now see that as we work in Z , c +c = \u03a0\u2032 +{e}+\u03a0\u2032 = c. Furthermore, we have 2 1 2 v,u v,w w(c ) \u2a7d w(c), since \u03a0 is a shortest path (in K), while \u03a0\u2032 is not necessarily shortest. 1 v,u v,u The same also holds for c : w(c ) \u2a7d w(c) since {\u03a0\u2032 ,e} can not be shorter than \u03a0 . 2 2 v,w v,u Let us now consider the homology classes of c and c . If both [c ] and [c ] were 1 2 1 2 dependent on C\u2217 \\ {c}, then so would [c], since c = c + c . Then, C\u2217 would not be a 1 2 basis. Thus, at least one of [c ] and [c ] has to be independent of C\u2217\\{c}. Let us consider 1 2 first that c is independent. Then, we could replace c by c in C\u2217 and get a basis which 1 1 is at least as good as C\u2217. If c is independent, we replace c by c in C\u2217. After replacing, 2 2 we use the same argument again on the new cycle. If we replaced c by c , we repeat 1 the argument with v\u2032, the common ancestor of \u03a0 and \u03a0\u2032 and the same edge e. If v,u v,w we replaced c by c , we repeat the argument with v\u2032 the common ancestor of \u03a0 ,\u03a0\u2032 2 v,u v,u and e an edge incident to u. By doing this we have made some \u201cprogress\u201d: In the second iteration of the argument, one of the two paths \u03a0\u2032 must have become equal to \u03a0. After doing the argument twice, we must have replaced c by a cycle c\u2032 that has w(c\u2032) \u2a7d w(c) and c\u2032 is actually in our set C. At the end, we thus get a basis C\u2032 with w(C\u2032) \u2a7d w(C\u2217) with C\u2032 \u2286 C. Therefore C contains an optimal basis. Exercise 8.4. Given a 2-dimensional simplicial complex K in which every pair of vertices u,v has a unique shortest path between them, show that the set C computed by the algorithm will contain all optimal bases of H (K). 1 So, we have finished the first step of our algorithm. It remains to figure out how to check independence. For this, we introduce annotations. Definition 8.5. An annotation of p-simplices is a function a : Kp \u2192 Zg giving each p- 2 simplex a binary vector of size g. This extends to chains by sums. An annotation must fulfill: \u2022 g = \u03b2 (K) p \u2022 a(z ) = a(z ) iff [z ] = [z ]. 1 2 1 2 1In general this would also follow from the weights being non-negative and C\u2217 being optimal. 92"}
{"node_id": "tdanotes:8.2", "pdf_id": "tdanotes", "section_id": "8.2", "chunk_id": "8.2-0", "text": "Introduction to TDA 8.2. Persistent Cycles Given an annotation, we can now clearly check linear independence of cycles by simply checking linear independence of a set of vectors, for which we have existing tools such as Gaussian elimination. Proposition 8.6. In every simplicial complex K and for every p \u2a7e 0, there exists an annotation of p-simplices, and such an annotation can also be computed. Proof. (Sketch for p = 1) We can compute a spanning forest T, and let m be the number of remaining edges. We initialize annotations of length m, and set a(e) = 0 for every edge in the spanning forest T. For every remaining edge e , we set a (e ) = 1 if and only i j i if j = i, and 0 otherwise. For every triangle t \u2208 K, if the annotation of its boundary \u03b4t is not 0, we find a non- zero entry b in a(\u03b4t) and add a(\u03b4t) to every edge with a (e) = 1, and we delete the u u u-th entry from all annotations. One can show that this yields a valid annotation, and it can be implemented in O(n3), and more clever implementations work in O(n\u03c9). To check independence of cycles in our set C more efficiently, we add auxiliary anno- tations also to vertices in a shortest path tree T rooted at v. We give v the annotation v 0, and for a vertex x that is the child of y, we set a(x) := a(y)+a(e ). For every cycle xy defined by the non-tree edge e = uw, we now have a(c ) = a(u)+a(w)+a(e). So, we e never actually have to compute an explicit representation of a cycle by its edges, we only need to store its weight, the shortest path trees with the auxiliary annotations, and the non-tree edge e. Note that the auxiliary annotations can be computed in O(gn) for the whole tree, thus in O(gn2) for all trees. Finally, we have to check independence. Given an (n\u00d7m) matrix M, we can find the lexicographic leftmost set of independent columns in time O(max(n,m)\u03c9). Instead of naively doing this n2 times (once for every cycle), we group our cycles of C into groups A of size g, and compute the leftmost set for [B|A ], and thus we get O(n2g\u03c9\u22121) runtime i i for this step. To summarize, computing C takes O(n2logn), sorting the O(n2) cycles also takes O(n2logn), and for checking linear independence we need O(n\u03c9) for the annotations of the edges, O(gn2) for the auxiliary annotations, and O(n2g\u03c9\u22121) for the block-wise linear independence checking. Overall, we thus get a runtime of O(n\u03c9 +n2g\u03c9\u22121). Theorem 8.7. Given a 2-dimensional simplicial complex K with n triangles and a weight function w on its edges, we can compute an optimal basis of H (K) in time 1 O(n\u03c9 +n2g\u03c9\u22121). 8.2 Persistent Cycles In the persistent setting, given a simplex-wise filtration F and an interval [b,d], can we find an optimal persistent p-cycle c that is born at b and dies at d? Sadly, this problem is already known to be NP-hard for d < \u221e and p \u2a7e 1. However, if we assume that K is a weak (p+1)-pseudomanifold, i.e., a simplicial complex in which 93 Chapter 8. Optimal Generators Introduction to TDA eachp-simplex isa face ofat most2 (p+1)-simplices, then there existsa polynomial-time algorithm, which we will describe in this section. If we consider cycles that live until \u221e, we can solve the problem in polynomial time for p = 1, but it is NP-hard for p \u2a7e 2. Here, the"}
{"node_id": "tdanotes:8.2", "pdf_id": "tdanotes", "section_id": "8.2", "chunk_id": "8.2-1", "text": "simplicial complex in which 93 Chapter 8. Optimal Generators Introduction to TDA eachp-simplex isa face ofat most2 (p+1)-simplices, then there existsa polynomial-time algorithm, which we will describe in this section. If we consider cycles that live until \u221e, we can solve the problem in polynomial time for p = 1, but it is NP-hard for p \u2a7e 2. Here, the assumption of K being a weak (p+1)- pseudomanifold does not save us. However, if we further assume that the complex can be embedded in Rp+1, then it is again polynomial. To solve the problem for d < \u221e in a weak (p + 1)-pseudomanifold, we consider undirected flow networks: We have a graph, where every edge has a capacity in [0,\u221e], some sources, and some sinks, and we want to find the maximum flow we can send from the sources to the sinks without sending too much flow through any edge. Recall that if we consider a cut which separates the sources from the sinks, the capacity of this cut is an upper bound on the value of the maximum flow. Furthermore, if we consider the minimum such cut, its capacity is equal to the value of the maximum flow. This can be solved in polynomial time. We can build a dual graph G, by placing a vertex into every (p + 1)-simplex and adding an edge whenever they share a p-simplex. We furthermore add a dummy vertex which gets connected to all vertices which only have one neighbor. We are going to make the vertex belonging to the (p+1)-simplex which is the destructor of our desired cycle the source. Furthermore, we make the dummy vertex as well as all vertices belonging to (p+1)-simplices added after the destructor into sinks. Edges added at or before the birth are getting the capacity equal to their weight, while all other edges get capacity \u221e. Then, it turns out that the p-simplices belonging to the edges in a minimum cut separating the sources from the sinks are an optimal persistent cycle. Exercise 8.8. Consider a simplex-wise filtration on a simplicial complex that is a weak (p + 1)-pseudomanifold, and consider some interval [b,d] (for d < \u221e) such that there exists a p-cycle born at b and dying at d. We look at the dual graph G with source and sinks defined as in the lecture. Consider a cut with finite capacity that separates the source from the sinks. Let c be the chain corresponding to the p-simplices dual to the edges going over this cut. Show that c is a p-cycle born at b and dying at d, and show that its weight is equal to the capacity of the cut. This exercise proves one direction of the correctness of the algorithm described above. The other direction is similar. We get the following result. Theorem 8.9. Given a a simplex-wise filtration on a simplicial complex that is a weak (p+1)-pseudomanifold and an interval [b,d] (for d < \u221e), we can compute an optimal p-cycle born at b and dying at d in polynomial time. For details, we refer to Chapter 5 in the book of Dey and Wang [1]. Questions 32. (Thistopicwasnotcoveredinthisyear\u2019scourseinFS25andthereforethefollowingquestion will not be asked in the exam.)How can we compute an optimal basis given a set of 94 Introduction to TDA 8.2. Persistent Cycles cycles that contain one? Explain the algorithm described in Section 8.1. Further, explain annotations and how they can be used to check linear independence. 33. (Thistopicwasnotcoveredinthisyear\u2019scourseinFS25andthereforethefollowingquestion willnotbeaskedintheexam.)How can we compute a set of 1-cycles that contain an optimal basis of H ? Describe the algorithm to"}
{"node_id": "tdanotes:8.2", "pdf_id": "tdanotes", "section_id": "8.2", "chunk_id": "8.2-2", "text": "an optimal basis given a set of 94 Introduction to TDA 8.2. Persistent Cycles cycles that contain one? Explain the algorithm described in Section 8.1. Further, explain annotations and how they can be used to check linear independence. 33. (Thistopicwasnotcoveredinthisyear\u2019scourseinFS25andthereforethefollowingquestion willnotbeaskedintheexam.)How can we compute a set of 1-cycles that contain an optimal basis of H ? Describe the algorithm to do this and prove its correctness. 1 34. (Thistopicwasnotcoveredinthisyear\u2019scourseinFS25andthereforethefollowingquestion will not be asked in the exam.)How can we compute an optimal persistent cycle? Explain the algorithm described in Section 8.2. References [1] Tamal Krishna Dey and Yusu Wang, Computational topology for data analysis, Cambridge University Press, 2022. 95"}
{"node_id": "tdanotes:9.1", "pdf_id": "tdanotes", "section_id": "9.1", "chunk_id": "9.1-0", "text": "Chapter 9 Multiparameter persistence This chapter closely follows the introductory paper [2] on multiparameter persis- tence. The interested reader is referred there for a (much) more comprehensive overview of the topic. As we have seen, the persistence modules arising from the \u010cech or Vietoris-Rips com- plexes are stable under small perturbations of the underlying data, but not robust. That is, even a small number of outliers can drastically change the persistence diagram or bar- code. We could try to remedy this problem by making these complexes density-aware in some way. For the Vietoris-Rips complex, a typical way to do this is as follows. For a vertex v in a simplicial complex, its degree deg(v) is the number of edges (1-simplices) in the complex that contain v. Then. for d \u2208 N , the degree-d Vietoris-Rips complex is VRr(X) := {\u03c3 \u2208 VRr(X) : each vertex of \u03c3 has degree at least d}. d Note that vertices corresponding to data points in high-density areas of X will have relatively higher degree, whereas outliers will have relatively lower degree. Thus, for d large enough, we should expect this modification to reduce the impact of outliers. On the other hand, if d is too large, we are \u2018throwing away the baby with the bathwater\u2019. So, the question is: how to choose d? Here, we run into the same issue that originally motivated persistence: there might not be one choice of d that accurately reflects the entire data set. Even if this choice would exist, it might be hard to determine. Instead, we would like to consider all choices of d simultaneously. The solution is to look at persistence w.r.t. both the scale parameter r and the density parameter d at the same time. In this chapter, we formalize such multiparameter persistence, and take a look at the representability and robustness of the resulting multiparameter persistence modules. 9.1 Persistence modules indexed by a poset A persistence module (indexed by R ) consists of a family of vectors spaces U , a \u2208 R , a together with commuting maps U \u2192 U for a \u2a7d b. If we want to define persistence a b 96 Introduction to TDA 9.1. Persistence modules indexed by a poset modules indexed by more exotic sets, we need to first extend the meaning of \u2018\u2a7d\u2019. Definition 9.1. A poset (partially ordered set) is a tuple (P,\u2aaf) consisting of a set P and a binary relation \u2aaf on P satisfying \u2022 a \u2aaf a for all a \u2208 P; \u2022 a \u2aaf b and b \u2aaf a implies a = b for all a,b \u2208 P; \u2022 a \u2aaf b and b \u2aaf c implies a \u2aaf c for all a,b,c \u2208 P; We will sometimes simply write P if the (partial) ordering \u2aaf is clear from context. Note that partial orderings allow for elements to be incomparable, i.e., it can happen for a,b \u2208 P that neither a \u2aaf b nor b \u2aaf a holds. In contrast, under a total ordering all elements in P must be comparable. All the posets we will see in this chapter are constructed from the following examples: \u2022 The reals R = (R,\u2a7d) and natural numbers N = (N,\u2a7d) with their usual ordering are posets. \u2022 If (P,\u2aaf) is a poset, and Q \u2286 P, then (Q,\u2aaf) is a poset; \u2022 For any poset (P,\u2aaf), we have the opposite poset Pop = (P,\u2ab0), where a \u2ab0 b \u21d0\u21d2 b \u2aaf a for all a,b \u2208 P. \u2022 For two posets (P,\u2aaf ) and (Q,\u2aaf ) we have the product poset (P\u00d7Q,\u2aaf), where P"}
{"node_id": "tdanotes:9.1", "pdf_id": "tdanotes", "section_id": "9.1", "chunk_id": "9.1-1", "text": "are posets. \u2022 If (P,\u2aaf) is a poset, and Q \u2286 P, then (Q,\u2aaf) is a poset; \u2022 For any poset (P,\u2aaf), we have the opposite poset Pop = (P,\u2ab0), where a \u2ab0 b \u21d0\u21d2 b \u2aaf a for all a,b \u2208 P. \u2022 For two posets (P,\u2aaf ) and (Q,\u2aaf ) we have the product poset (P\u00d7Q,\u2aaf), where P Q (p,q) \u2aaf (p\u2032,q\u2032) \u21d0\u21d2 p \u2aaf p\u2032 and q \u2aaf q\u2032 for all p,p\u2032 \u2208 P and q,q\u2032 \u2208 Q. P Q We can now define filtrations and persistence modules indexed by an arbitrary poset, generalizing our definitions from earlier chapters. Definition 9.2. Let (P,\u2aaf) be a poset. A family (X ) of topological spaces (or sim- p p\u2208P plicial complexes) is called a P-filtration if X \u2286 X for all p,p\u2032 \u2208 P with p \u2aaf p\u2032. p p\u2032 Definition 9.3. Let (P,\u2aaf) be a poset, and let F be a field. A P-persistence module (over F) consists of \u2022 An F-vector space U for each p \u2208 P; p \u2022 A linear map u : U \u2192 U for each p,p\u2032 \u2208 P with p \u2aaf p\u2032, satisfying p,p\u2032 p p\u2032 u \u25e6u = u for all p ,p ,p \u2208 P with p \u2aaf p \u2aaf p . p ,p p ,p p ,p 1 2 3 1 2 3 2 3 1 2 1 3 Observation9.4. If (X ) is a P-filtration for some poset P, then taking k-dimensional p p\u2208P homology gives us a P-persistence module H (X ) (where, as before, the maps k p u : H (X ) \u2192 H (X ) are induced by the inclusions X (cid:44)\u2192 X ). p,p\u2032 k p k p\u2032 p p\u2032 97"}
{"node_id": "tdanotes:9.2.1", "pdf_id": "tdanotes", "section_id": "9.2.1", "chunk_id": "9.2.1-0", "text": "Chapter 9. Multiparameter persistence Introduction to TDA We can now give two examples of filtrations indexed by P = R\u00d7Nop, each of which induces a P-persistence module via the observation above. The first one formalizes the discussion at the beginning of the chapter. The second one applies a similar idea to the \u010cech complex. Example 9.5. Let X be a finite metric space. Then the family (VRr d (X)) r\u2208R,d\u2208N defined above is a filtration indexed by R\u00d7Nop. It is called the degree-Rips bifiltration. Example 9.6. Let X \u2286 Rn be a finite point cloud. For r \u2208 R and d \u2208 N, define MCr = {x \u2208 Rn : |B(x,r)\u2229X| \u2a7e d} \u2286 Rn. d Note that, for d = 1, this is just the union-of-balls used to define the \u010cech complex. The family (MCr d (X)) r\u2208R,d\u2208N is a filtration (of topological spaces) indexed by R\u00d7Nop. It is called the multicover bifiltration. Both of the filtrations above can also be thought of as indexed over R2 (after a reparameterization). In general, we call an Rn-filtration (resp. Rn-persistence module) an n-parameter filtration (resp. n-parameter persistence module). For n \u2a7e 2, we also say \u2018multiparameter\u2019. For n = 2 the terms bifiltration and bipersistence module are common. 9.2 Representing persistence modules indexed by posets 9.2.1 Barcodes? Recall that a p.f.d. persistence module indexed by can be uniquely represented by U R a barcode. In Chapter 6, we saw that this follows from the fact that any such can be U decomposed into interval modules in a unique way: \u223c (cid:77) U = I . \u27e8a,b\u27e9 i\u2208I Each interval in this decomposition corresponds to a bar in the barcode of . We could U hope a similar statement holds for modules indexed by any poset P. The following definition and theorem should give us some hope: \u223c Definition 9.7. A persistence module U is called indecomposable if U = U \u2295U implies 1 2 that U = 0 or U = 0. 1 2 Exercise 9.8. Show that interval modules (indexed by R) are indecomposable. Theorem 9.9. Let U be a p.f.d. persistence module (indexed by a poset P). Then, there is a unique decomposition: \u223c (cid:77) U = U , i i\u2208I where each persistence module U is indecomposable. i 98 Introduction to TDA 9.2. Representing persistence modules indexed by posets Understanding P-persistence modules thus boils down to understanding indecompos- ables (indexed by P). For P = R , it turns out that indecomposables are precisely interval modules, leading to Theorem 6.36. However, for general P, the situation is much more complicated. Without going into details: It is not possible to parameterize indecompos- ables in terms of some nice family of subsets of P. The decomposition of Theorem 9.9 therefore does not lead to a workable notion of barcode in general. In fact, it is not possible to define any reasonable notion of a barcode for P-persistence modules, in the following sense. Definition 9.10. Let (P,\u2aaf) be a poset and let U be a P-persistence module. We say a multiset B of subsets of P is a reasonable barcode for U if rank(u ) = |{B \u2208 B : p,p\u2032 \u2208 B}| (\u2200p \u2aaf p\u2032). p,p\u2032 That is, the rank of the map u : U \u2192 U can be computed by counting the p,p\u2032 p p\u2032 number of \u2018bars\u2019 that contain both p and p\u2032. Exercise 9.11. Show that the usual barcode for a p.f.d. persistence module indexed by R is reasonable in the above sense. Exercise 9.12. For p \u2208 P, show that dim U is greater than"}
{"node_id": "tdanotes:9.2.1", "pdf_id": "tdanotes", "section_id": "9.2.1", "chunk_id": "9.2.1-1", "text": "of the map u : U \u2192 U can be computed by counting the p,p\u2032 p p\u2032 number of \u2018bars\u2019 that contain both p and p\u2032. Exercise 9.11. Show that the usual barcode for a p.f.d. persistence module indexed by R is reasonable in the above sense. Exercise 9.12. For p \u2208 P, show that dim U is greater than or equal to the number of p bars that contain p in a reasonable barcode for U. Example 9.13. Let P = {0,1,2}\u00d7{0,1,2} and consider the following persistence module indexed by P: F id F 0 f : a (cid:55)\u2192 (a,0) id g g : (a,b) (cid:55)\u2192 a U = F f F2 h F , where h : (a,b) (cid:55)\u2192 a+b j id j : a (cid:55)\u2192 (0,a) 0 F id F We claim U cannot have a reasonable barcode. To see this, suppose B is a reasonable barcode for U. Note that rank(h\u25e6f) = rank(g\u25e6f) = rank(h\u25e6j) = 1. By the reasonability assumption, there thus must be subsets I,J,K \u2208 B with (0,1),(2,1) \u2208 I, (0,1),(1,2) \u2208 J, (1,0),(2,1) \u2208 K. Since dim U = dim U = 1, we know by Exercise 9.12 that (0,1) and (2,1) occur 0,1 2,1 in at most one element of B. But that means that I = J, and I = K, and so in fact I = J = K \u2287 {(0,1),(2,1),(1,2)}. Thus, using reasonability again, we find that rank(g\u25e6j) \u2a7e 1, contradicting the fact that g\u25e6j = 0. 99"}
{"node_id": "tdanotes:9.3", "pdf_id": "tdanotes", "section_id": "9.3", "chunk_id": "9.3-0", "text": "Chapter 9. Multiparameter persistence Introduction to TDA For completeness, we note that it is possible to have reasonable barcodes for mul- tiparameter persistence modules if we allow \u2018bars\u2019 to occur with negative multiplicity. This leads to so-called signed barcodes. Furthermore, there are several special classes of multiparameter persistence modules which do admit an interval decomposition (note that we did not formally define what an interval is in the poset-setting!). This is true in particular for so-called interlevel persistence. We will not discuss this further here. 9.2.2 Other representations and visualizations Even though we cannot hope for a barcode-like representation of multiparameter per- sistence modules, there are still several useful (partial) representations available. We mention just three of them here: \u2022 The Hilbert-function of a p.f.d. persistence module U indexed by P sends p \u2208 P to dim U \u2208 N . It can be thought of as a \u2018homological heatmap\u2019. p \u2022 The rank-invariant of U sends a pair (p,p\u2032), p \u2aaf p\u2032 to the rank rank(u ) of p,p\u2032 \u223c the map between U and U\u2032. Note that any two modules with U = V have the p p same rank invariant. For modules indexed by , this implication also holds in the R other direction. However, for general P, there exist nonisomorphic modules with the same rank-invariant; \u2022 Let L : t (cid:55)\u2192 ta + b be an affine line in R2 with non-negative slope. Then the restriction U of a persistence module U indexed by R2 to the line L can be viewed L as a persistence module indexed by R (with its usual, total ordering). The Fibered Barcode of U sends each such line L to the barcode B(U ). This idea can be L extended to lines in Rn; Exercise 9.14. Show that the rank-invariant of an R2-persistence module can be re- covered from its fibered barcode, and vice versa. The RIVET software package (rivet.readthedocs.io) allows you to compute and visualize each of the invariants above for (among others) the degree-Rips bifiltration. 9.3 Distances and robustness for P-persistence modules As we generally do not have barcodes for P-persistence modules, we cannot rely on the Bottleneck distance to compare them. Instead, we work directly with interleaving distance, which is still well-defined. For simplicity, we only consider P = Rn. Definition 9.15. Write 1 = (1,1,...,1) \u2208 Rn. Two Rn-persistence modules U,V are \u03f5-interleaved if there exist two families of linear maps, \u03c6 : U \u2192 V and a a a+\u03f51 100"}
{"node_id": "tdanotes:9.3.1", "pdf_id": "tdanotes", "section_id": "9.3.1", "chunk_id": "9.3.1-0", "text": "Introduction to TDA 9.3. Distances and robustness for P-persistence modules \u03c8 a : V a \u2192 U a+\u03f51 , a \u2208 Rn, such that the following diagrams (and their symmetric counterparts obtained by exchanging the role of U and V) are commutative: U u a,a\u2032 U U u a,a+2\u03f51 U a a\u2032 a a+2\u03f51 \u03c6a \u03c6 a\u2032 and \u03c6a \u03c8a+\u03f51 V v a+\u03f51,a\u2032+\u03f51 V V a+\u03f51 a\u2032+\u03f51 a+\u03f51 The interleaving distance between U,V is d I (U,V) := inf \u03f5\u2a7e0 { U,V are \u03f5-interleaved}. The definition above agrees with our earlier definition of interleaving when n = 1. Contrary to the 1-dimensional case, computing the interleaving distance for n \u2a7e 2 is an NP-hard problem (even if the persistence modules U,V are given to us in a \u2018nice\u2019 form). For this reason, the following alternative based on the fibered barcode is sometimes used in practice. It is known to be efficiently computable when n = 2. Definition 9.16. The matching distance between p.f.d. Rn-persistence modules U,V is (cid:10) (cid:11) d (U,V) := sup d (cid:0)B(U ), B(V ) (cid:1) , match B L L L where the supremum is taken over all lines L : t (cid:55)\u2192 ta+b with a \u2ab0 1, b \u2208 Rn. Theorem 9.17 (see [3]). For any two p.f.d. Rn-persistence modules, d (U,V) \u2a7d d (U,V). match I Exercise 9.18. Prove that d (cid:0)B(U ), B(V ) (cid:1) \u2a7d d (U,V) for all lines L : t (cid:55)\u2192 t1+b. B L L I 9.3.1 Robustness of some bipersistence modules Finally, we come back to the primary reason for studying multiparameter persistence: achieving robustness w.r.t. outliers in the data. To state formal guarantees of this form, we need to think about point-cloud data in a more probablistic way. For a finite (multi)set X \u2286 Rn, we write \u00b5 for the uniform probability measure on X, meaning the X measure that assigns probability 1/|X| to each x \u2208 X. The following can be thought of as a \u2018probabilistic Hausdorff distance\u2019 between point clouds. Definition 9.19. Let X,Y \u2286 Rn finite. The Prohorov distance1 between \u00b5 ,\u00b5 is X Y d (\u00b5 ,\u00b5 ) := supinf{\u03b4 \u2a7e 0 : \u00b5 (A) \u2a7d \u00b5 (A\u03b4)+\u03b4 and \u00b5 (A) \u2a7d \u00b5 (A\u03b4)+\u03b4}, Pr X Y X Y Y X A where A ranges over all closed subsets of Rn and A\u03b4 := {y \u2208 Rn : dist(y,A) \u2a7d \u03b4}. 1The Prohorov distance can be defined between any two measures \u00b5,\u03bd on (the same) metric space M. 101 Chapter 9. Multiparameter persistence Introduction to TDA While the definition of the Prohorov distance appears a bit complicated, the following observation suggests that it captures \u2018robustness to outliers\u2019 in a meaningful way. Exercise 9.20. Let X ( Y \u2286 Rn, finite, non-empty sets. Show that |Y \\X| d (\u00b5 ,\u00b5 ) \u2a7d . Pr X Y |X| As an example, the normalized multicover persistence module turns out to be stable w.r.t. Prohorov distance (i.e., it is robust to outliers). Definition 9.21. Let X \u2286 Rn be a finite point cloud. For r,\u03c1 \u2208 R, the sets NMCr(X) := {x \u2208 Rn : |B(x,r)\u2229X| \u2a7e \u03c1|X|} = {x \u2208 Rn : \u00b5 (cid:0) B(x,r)\u2229X (cid:1) \u2a7e \u03c1}. \u03c1 X form a bilfiltration over R\u00d7Rop called the normalized multicover bifiltration. Theorem 9.22 (see [1]). Let X,Y \u2286 Rn finite. For all k \u2a7e 0, we have d (cid:0) H (NMC(X)), H (NMC(Y)) (cid:1) \u2a7d d (\u00b5 ,\u00b5 ). I k k Pr X Y Proof. Let \u03f5 = d (\u00b5 ,\u00b5 ). We will show that Pr X Y NMCr(X) \u2286 NMCr+\u03f5(Y) \u2286 NMCr+2\u03f5(X) \u2200r,\u03c1 \u2208"}
{"node_id": "tdanotes:9.3.1", "pdf_id": "tdanotes", "section_id": "9.3.1", "chunk_id": "9.3.1-1", "text": "the normalized multicover bifiltration. Theorem 9.22 (see [1]). Let X,Y \u2286 Rn finite. For all k \u2a7e 0, we have d (cid:0) H (NMC(X)), H (NMC(Y)) (cid:1) \u2a7d d (\u00b5 ,\u00b5 ). I k k Pr X Y Proof. Let \u03f5 = d (\u00b5 ,\u00b5 ). We will show that Pr X Y NMCr(X) \u2286 NMCr+\u03f5(Y) \u2286 NMCr+2\u03f5(X) \u2200r,\u03c1 \u2208 R. \u03c1 \u03c1\u2212\u03f5 \u03c1\u22122\u03f5 These inclusions induce the maps \u03c6 : H (NMCr(X)) \u2192 H (NMCr+\u03f5(Y)), r,\u03c1 k \u03c1 k \u03c1\u2212\u03f5 \u03c8 : H (NMCr+\u03f5(Y)) \u2192 H (NMCr+2\u03f5(X)) r+\u03f5,\u03c1\u2212\u03f5 k \u03c1\u2212\u03f5 k \u03c1\u22122\u03f5 required to show that H (NMC(X)) and H (NMC(Y)) are \u03f5-interleaved. k k So, let r,\u03c1 \u2208 R , and suppose that x \u2208 NMCr(X). By definition, this means that \u03c1 \u00b5 (B(x,r) \u2229 X) \u2a7e \u03c1. Using the definition of the Prohorov distance, and the triangle- X inequality, this implies that \u03c1 \u2a7d \u00b5 (cid:0) B(x,r)\u2229X (cid:1) \u2a7d \u00b5 (cid:0) B(x,r)\u03f5 \u2229Y (cid:1) +\u03f5 \u2a7d \u00b5 (cid:0) B(x,r+\u03f5)\u2229Y (cid:1) +\u03f5. X Y Y That is to say, \u00b5 (B(x,r+\u03f5)\u2229Y) \u2a7e \u03c1\u2212\u03f5, meaning x \u2208 NMCr+\u03f5(Y), giving us the first Y \u03c1\u2212\u03f5 inclusion. The second inclusion follows from an analogous argument, switching the roles of X and Y. There are many similar theorems for other bipersistence modules, including the degree-Rips bifiltration. They are often somewhat hard to state and prove, relying on variants of the Prohorov distance, as well as variants of the interleaving distance [1]. 102 Introduction to TDA 9.3. Distances and robustness for P-persistence modules Questions 35. How can we define persistence modules over multiple parameters? Discuss the technical definitions that are needed. 36. What are some common bipersistence modules? How do they relate to the (1-parameter) persistence modules of earlier chapters? 37. What is a major upside of multiparameter persistence? What is a major downside? Discuss robustness and representability. 38. How can we visualize multiparameter persistence modules? References [1] Andrew J. Blumberg and Michael Lesnick, Stability of 2-parameter persistent homol- ogy. Found. Comput. Math., 24/2, (2024), 385\u2013427. [2] Magnus Bakke Botnan and Michael Lesnick, An Introduction to Multiparameter Persistence. 2023. [3] Claudia Landi, The rank invariant stability via interleavings. In Research in compu- tational topology, vol. 13 of Assoc. Women Math. Ser., pp. 1\u201310, Springer, Cham, 2018. 103"}
{"node_id": "tdanotes:10.1", "pdf_id": "tdanotes", "section_id": "10.1", "chunk_id": "10.1-0", "text": "Chapter 10 Applications In this chapter we highlight some classical and recent applications of topological data analysis. The fields of application are as diverse as image analysis, medicine, analysis of time series and politics. Many of these applications are also described in the book \u201cTopological Data Analysis with Applications\u201d by Gunnar Carlsson and Mikael Vejdemo- Johansson [2]. We also discuss some of the approaches to use persistence diagrams in machine learning. 10.1 The Space of Image Patches We consider a dataset of about 4000 greyscale images taken around Groningen (Nether- lands) by van Hateren and van der Schaaf [8], see Figure 10.1 for some examples. Each such image is described by giving each pixel a number between 0 (white) and 1 (black). Fromeveryimage, theysampled5000patchesof3-by-3pixels. Togetinterestingpatches, they only looked at the top 20% with the highest contrast. Thus, we end up with about 4 million three by three patches, each describable as a vector in R9. They further nor- malize the contrast (such that the darkest and brightest pixel are 1 and 0, respectively) and the overall norm of the vectors. Thus, we end up with points on S7. How does this point cloud look? Is there some interesting structure in this point cloud? Carlsson, Ishkhanov, de Silva and Zomorodian analyzed this point cloud using per- sistent homology [1]. Since there are a lot of points, they at first only sampled from the densest parts of the data. Computing the persistent homology of the Witness complex in dimensions 0, 1, and 2, one gets the barcodes depicted in Figure 10.2. It is thus a reasonable assumption that \u03b2 = 1, \u03b2 = 1, and \u03b2 = 0, suggesting that the data set 0 1 2 looks like a circle. PCA also shows a circular arrangement of the data points, see Figure 10.3. This circle can be interpreted as the possible angles of a detected \u201cedge\u201d in the images, depicted in Figure 10.4. What happens if we additionally also sample some points from parts of the data of intermediate density? Computing the persistent homology we end up with the barcodes in Figure 10.5, suggesting that instead of one 1-cycle, we end up with five. If we again 104 Introduction to TDA 10.1. The Space of Image Patches Figure 10.1: Some examples of images in the data set. Figure 10.2: The barcodes of the densest part of the data. 105 Chapter 10. Applications Introduction to TDA Figure 10.3: Using PCA on the densest part of the data. Figure 10.4: The interpretation of the densest part of the data. 106"}
{"node_id": "tdanotes:10.2", "pdf_id": "tdanotes", "section_id": "10.2", "chunk_id": "10.2-0", "text": "Introduction to TDA 10.2. Mapper for Medical Data Figure 10.5: The barcodes including the medium density part of the data. consider the PCA, depicted in Figure 10.6, we see a cross in the middle of the circle seen previously. However, this only shows four circles! Where is the fifth one? Most likely some cycle is orthogonal to the projection chosen by the PCA. The interpretation picked from this situation is that the dataset consists of three great circles of some S2 that are all orthogonal. We can interpret these three circles as the circle described above, a circle describing different translations of vertical edges, and one circle describing translations of horizontal edges. This is depicted in Figure 10.7. However, if we finally also include points from the lowest density parts of the data, we get the barcodes depicted in Figure 10.8. We start seeing some feature in the persistent 2-homology, and reduce \u03b2 to most likely 2 again. How can this space look? It must 1 somehow include the three circles found before. We can embed the circles as in the Figure 10.9, indicating that the space is a Klein bottle. Clearly, this is not a proof. The persistent homology computed agrees with the Klein bottle, but it would also agree with a torus. To give more evidence, we could for example compute persistent homology over a different field such as , with which we Z 3 can distinguish between a Klein bottle and a torus. It turns out that the space is indeed a Klein bottle, as is shown in the work of Carlsson et al. [1]. 10.2 Mapper for Medical Data The following application comes from the original paper describing the Mapper approach [6]. Thedatacomesfromadiabetesstudyin1979on145participants, withsixquantities 107 Chapter 10. Applications Introduction to TDA Figure 10.6: Using PCA on the high and medium density part of the data. Figure 10.7: The interpretation of the high and medium density part of the data. 108 Introduction to TDA 10.2. Mapper for Medical Data Figure 10.8: The barcodes for the entire data. Figure 10.9: The interpretation of the entire data. 109 Chapter 10. Applications Introduction to TDA Figure 10.10: The classical illustration of the diabetes data set. measured per participant: age, relative weight, fasting plasma glucose, area under the plasma glucose curve for the three hour glucose tolerance test (OGTT), area under the plasma insulin curve for the (OGTT), and steady state plasma glucose response. After applying various classical methods, the original study came up with a picture containing a blob of healthy people, with two strains coming out of this blob, called type 1 and type 2 diabetes [4]. See Figure 10.10 for their illustration. The same behaviour can be automatically detected using Mapper, as showcased in [6]. As the filter function they used a density estimator for each point. They created two different outputs, one for 3 and one for 4 intervals, always with a 50% overlap. In the output of Mapper depicted in Figure 10.11 you also see areas of large density, with 2 flares going out of it. The Mapper approach has later also been applied to genomic data from a breast cancer study [7] by Nicolau, Levine and Carlsson [5]. This data is very high dimensional, each patient defines a data point in R262. As a filter function they used the distance to some baseline healthy tissue. The output presented in their paper is depicted in Figure 10.12. The strain labelled c-MYB+ tumors corresponds to a type of tumor which has previously not been classified, where the other strains confirm the strains of breast cancer known previously."}
{"node_id": "tdanotes:10.2", "pdf_id": "tdanotes", "section_id": "10.2", "chunk_id": "10.2-1", "text": "patient defines a data point in R262. As a filter function they used the distance to some baseline healthy tissue. The output presented in their paper is depicted in Figure 10.12. The strain labelled c-MYB+ tumors corresponds to a type of tumor which has previously not been classified, where the other strains confirm the strains of breast cancer known previously. 110 Introduction to TDA 10.2. Mapper for Medical Data Figure 10.11: The output of Mapper on the diabetes data set. Figure 10.12: The output of Mapper on the breast cancer data set. 111"}
{"node_id": "tdanotes:10.4", "pdf_id": "tdanotes", "section_id": "10.4", "chunk_id": "10.4-0", "text": "Chapter 10. Applications Introduction to TDA Topological data analysis has been used in many studies in medicine. TDA seems to excel in these high-dimensional datasets since many features seem to be the result of higher-order interactions of different coordinates. TDA can also deal with much smaller data sets than other approaches such as deep neural networks, that need tons of data points to train, validate, etc. In medicine, studies often have very few data points due to the large monetary cost, workload, and also ethical questions involved with data gathering. 10.3 Time Series Time series is data given as a sequence of points x in some metric space X, where t is t a (discrete) variable. The goal in analyzing time series is often analyzing and finding periodic behavior in the time series. We can embed time series in some higher-dimensional space, by always considering a sequence of l+1 consecutive points, i.e., I := {(x ,x ,...,x )} \u2282 Xl+1. The idea l t t t i i+1 i+l is that periodicity in the time series translates to loops (1-dimensional holes) in I . As l an example, consider x = sin(\u03c0t), and consider l = 1. Then, we get a loop in R2. If we t 4 however consider x = t, I is just a straight line. t 1 This approach has been used by Vejdemo-Johansson, Pokorny, Skraba and Kragic [9] for analyzing motion capture data, where cameras track the location in 3-space of certain points on a human body marked by physical markers. The data considered are six seconds long recordings of movement such as boxing, see Figure 10.13 for some stills. Every data point in this set is roughly 70-dimensional. Using PCA to project onto 2 dimensions, some loops can be seen but we cannot really distinguish different loops, see Figure 10.14 (left). Computing persistent homology it can be seen that there are six different loops that persist a long time, see Figure 10.14 (right). Looking back at the input data, these six different loops can be mapped to six different boxing movements in the recording. 10.4 Politics The data considered in this application, done in [2], is gathered from the sessions of the US house of representatives through the year 2010. For every vote, we set x = 1 if the i memberisaysYestothevote, \u22121forNo, and0otherwise. Doingthisforeveryofthe447 representatives in all 664 votes this gives 664 data points in R447. Using PCA to project to two dimensions and coloring the data by splitting the members into the two parties we get the picture depicted in Figure 10.15. We can see that there are four main \u201ccorners\u201d in which issues lie: the ones that get bipartisan support, those that get bipartisan rejection, those that are supported by republicans and rejected by democrats, and those where it is the opposite way. We can also see that the corner with bipartisan rejection is very sparsely populated, since such issues rarely make it far enough to be voted on. Further there are few votes that lie in between two of these corners, and almost none that lie 112 Introduction to TDA 10.4. Politics Figure 10.13: Some stills from motion capture data of a boxer. Figure 10.14: Left: PCA of the data set obtained from the boxing recording. Right: the persistent homology of the same data. 113 Chapter 10. Applications Introduction to TDA Figure 10.15: PCA of the voting data from the US house of representatives, colored by parties. Figure 10.16: Persistence diagram in dimension 1, computed on the entire voting data. in the middle of all four corners. There are however"}
{"node_id": "tdanotes:10.4", "pdf_id": "tdanotes", "section_id": "10.4", "chunk_id": "10.4-1", "text": "set obtained from the boxing recording. Right: the persistent homology of the same data. 113 Chapter 10. Applications Introduction to TDA Figure 10.15: PCA of the voting data from the US house of representatives, colored by parties. Figure 10.16: Persistence diagram in dimension 1, computed on the entire voting data. in the middle of all four corners. There are however some: in particular, three of the recordedvoteswhereQuorumcalls, wherebothanswers(Present/NotPresent)arecoded as 0, so there are at least 3 points exactly in the middle of the square. Computing the 1-dimensional persistence diagram, we would hope to recognize the phenomenon of excluded middle by having a 1-dimensional homology class with long persistence, corresponding to the boundary of the square. However, as we can see in the diagram depicted in Figure 10.16, this is not the case. What is going on? If you think about the process of growing balls, it becomes apparent that already a single point in the center of the square is enough to \u201cfill the hole\u201d much faster than we would like. As you can see in Figure 10.15, there are several points in the middle of the square, and it is these points that make the persistence of any 1-dimensional homology class short. This is a general issue of persistent homology: it is very fragile to outliers in the data. 114"}
{"node_id": "tdanotes:10.5", "pdf_id": "tdanotes", "section_id": "10.5", "chunk_id": "10.5-0", "text": "Introduction to TDA 10.5. Shape Segmentation Figure 10.17: Persistence diagram in dimension 1, computed on 99% of the voting data. One general approach to overcome this issue in many application is the following: compute the density for each data point (e.g., using Gaussian kernel density estimation or any other standard method) and only keep the points with highest density, e.g., remove the 1% with lowest density. Then, compute persistent homology only on the remaining, dense points. Doing this on the voting data, we get the diagram depicted in Figure 10.17. Here we can clearly see a single homology class with long persistence, just as we would expect. 10.5 Shape Segmentation Consider a surface in R3 given as a triangular mesh, that is, by points, edges, and triangles. The goal of shape segmentation is to label different parts of the surface according to what part they are. For example, given a model of a human body, we want to segment it into categories such as \u201chead\u201d, \u201ctorso\u201d or \u201cupper arm\u201d. While this is a well-studied problem in computer graphics, here we sketch a topological approach, described in [3]. We can pick some point on the body, and start growing a ball around it, using the geodesic distance (length of the shortest path along the surface). On the resulting filtration, we can perform persistent homology in dimension 1. If we do this for a point on the palm of a hand, for example, we get a 1-dimensional hole for every finger, see Figure 10.18. If we do this for a point on a finger, the persistence diagram looks very different, see Figure 10.19. We can then classify the persistence diagrams to segment the shape. But, how can we do this? We need to be able to insert persistence diagrams into classical ML pipelines. For this there are several approaches, and we discuss some of them in the next section. 115"}
{"node_id": "tdanotes:10.6", "pdf_id": "tdanotes", "section_id": "10.6", "chunk_id": "10.6-0", "text": "Chapter 10. Applications Introduction to TDA Figure 10.18: Persistence diagram for a point on the palm. Figure 10.19: Persistence diagram for a point on a finger. 10.6 TDA in ML Many machine learning pipelines require input points to be in Euclidean space (and not just any metric space, which the persistence diagrams would already fulfill), or in the case of kernel methods, at least in some space that has an inner product, also known as a Hilbert space. Therearemanywaystoturnpersistencediagramsintoelementsofsuchmetricspaces. These methods are also called vectorizations. In this section we introduce three such methods. On https://persistent-homology.streamlit.app you can see more examples and play around with various vectorization methods. Persistence Statistics For the persistence statistics, as the name suggests, we just sum- marize some statistical values of the persistence diagrams. In particular, for the birth times b, the death times d, the interval midpoints b+d and the interval lengths d \u2212 b 2 we record \u2022 the mean, \u2022 the standard deviation, \u2022 the median, \u2022 the interquartile range, 116 Introduction to TDA 10.6. TDA in ML Figure 10.20: The persistence landscape of a persistence diagram. \u2022 the full range and \u2022 four percentiles (10%, 25%, 75%, 90%). Finally we also record the number of bars and the entropy. All in all, we record 38 numerical values, and we thus represent a persistence diagram as a point in R38. PersistenceLandscapes Themainintuitionbehindpersistencelandscapesisthefollowing: for each point in the persistence diagram draw a horizontal and a vertical line segment to the diagonal. Flipping this arrangement of line segments such that the diagonal is horizontal, wegetsomethingthatlookslikeamountainrange, hencethenamelandscape. We can also interpret this as a set of piece-wise linear functions by looking at envelopes: a point on one of the segments is on the k\u2019th envelope of the arrangement if there are k\u22121 segments strictly above it. Each such envelope is now a piece-wise linear function. See Figure 10.20 for an illustration. More formally, let D = {(b ,d ),...,(b ,d )} be a persistence diagram with finitely 1 1 n n many off-diagonal points. Each off-diagonal point (b ,d ) gives rise to a triangle whose i i boundary is defined by the points {(t,min[t\u2212b ,d \u2212t] ) | t \u2208 R }, i i + where min[a,b] := max(0,min(a,b)). + The persistence landscape of D is now a function \u03bb : N\u00d7R \u2192 R defined by D \u03bb (k,t) := k\u2019th largest value of min[t\u2212b ,d \u2212t] for i \u2208 {1,...,n}. D i i + For each k, we have that \u03bb (k,\u00b7) is a piece-wise linear function. Recall that on D functions, we have the following p-norms: (cid:90) (cid:18) (cid:19)1/p \u2225f\u2225 := |f(x)|pdx . p R 117 Chapter 10. Applications Introduction to TDA Figure 10.21: The Betti curve of a persistence diagram. We can extend this to a norm on our set of piece-wise linear functions: \uf8eb \uf8f61/p (cid:88)\u221e \u2225\u03bb D \u2225 p := \uf8ed \u2225\u03bb D (k,\u00b7)\u2225 p\uf8f8 . k=1 In particular, for p = 2 this is a Hilbert space and thus usable for many machine learning pipelines. We can further define the following distance measure on persistence diagrams, called the p-landscape distance \u039b : p \u039b (D ,D ) := \u2225\u03bb \u2212\u03bb \u2225 . p 1 2 D D p 1 2 Taking p = \u221e we get the following Theorem 10.1. Let D and D be persistence diagrams with finitely many off-diagonal 1 2 points. Then \u039b (D ,D ) \u2a7d d (D ,D ). \u221e 1 2 b 1 2 Betti Curves An easier way to get a piece-wise linear (even piece-wise constant) function from a persistence diagram is"}
{"node_id": "tdanotes:10.6", "pdf_id": "tdanotes", "section_id": "10.6", "chunk_id": "10.6-1", "text": "2 Taking p = \u221e we get the following Theorem 10.1. Let D and D be persistence diagrams with finitely many off-diagonal 1 2 points. Then \u039b (D ,D ) \u2a7d d (D ,D ). \u221e 1 2 b 1 2 Betti Curves An easier way to get a piece-wise linear (even piece-wise constant) function from a persistence diagram is through Betti curves: the Betti curve of a persistence diagram is the function \u03b2 : R \u2192 N\u2a7e0 which assigns each time t the current Betti number of the filtration. This is a piece-wise constant function and thus the space of all Betti curves is a Hilbert space with the standard 2-norm. A Betti curve still captures all the births and deaths, but throws away the pairing between them, see Figure 10.21 for an illustration. Questions 39. How can we use TDA to analyze the space of image patches? Discuss the structure of the relevant data set and how persistent homology can be applied. 118 Introduction to TDA 10.6. TDA in ML 40. Why does persistent homology sometimes fail to capture voids in the data? Illustrate the problem with the voting data from the US house of representatives and explain how it can be solved in practice. 41. How can persistence diagrams be used in machine learning pipelines? Explain the following vectorizations: persistence statistics, persistence landscapes and Betti curves. References [1] GunnarCarlsson,TigranIshkhanov,VinDeSilva,andAfraZomorodian,Onthelocal behavior of spaces of natural images. International journal of computer vision, 76, (2008), 1\u201312. [2] Gunnar Carlsson and Mikael Vejdemo-Johansson, Topological Data Analysis with Applications, Cambridge University Press, 2021. [3] Mathieu Carri\u00e8re, Steve Y. Oudot, and Maks Ovsjanikov, Stable Topological Signa- tures for Points on 3D Shapes. Computer Graphics Forum, doi:10.1111/cgf.12692. [4] Rupert G Miller, Discussion: Projection Pursuit. The Annals of Statistics, 13/2, (1985), 510\u2013513. [5] MonicaNicolau,ArnoldJLevine,andGunnarCarlsson,Topologybaseddataanalysis identifies a subgroup of breast cancers with a unique mutational profile and excellent survival. Proceedings of the National Academy of Sciences, 108/17, (2011), 7265\u2013 7270. [6] Gurjeet Singh, Facundo M\u00e9moli, and Gunnar Carlsson, Topological Methods for the Analysis of High Dimensional Data Sets and 3D Object Recognition. [7] Marc J Van De Vijver, Yudong D He, Laura J Van\u2019t Veer, Hongyue Dai, Augusti- nus AM Hart, Dorien W Voskuil, George J Schreiber, Johannes L Peterse, Chris Roberts, Matthew J Marton et al., A gene-expression signature as a predictor of survival in breast cancer. New England Journal of Medicine, 347/25, (2002), 1999\u2013 2009. [8] J Hans Van Hateren and Arjen van der Schaaf, Independent component filters of natural images compared with simple cells in primary visual cortex. Proceedings of the Royal Society of London. Series B: Biological Sciences, 265/1394, (1998), 359\u2013366. [9] Mikael Vejdemo-Johansson, Florian T Pokorny, Primoz Skraba, and Danica Kragic, Cohomologicallearningofperiodicmotion.Applicable algebra in engineering, com- munication and computing, 26/1, (2015), 5\u201326. 119"}
